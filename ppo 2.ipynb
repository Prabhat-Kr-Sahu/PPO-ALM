{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Meta/blob/master/tutorials/1-Introduction/FinRL_PortfolioAllocation_NeurIPS_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv3IDvrobU37"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Portfolio Allocation\n",
        "\n",
        "Tutorials to use OpenAI DRL to perform portfolio allocation in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
        "\n",
        "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
        "* Check out medium blog for detailed explanations: https://towardsdatascience.com/finrl-for-quantitative-finance-tutorial-for-portfolio-allocation-9b417660c7cd\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-Foundation/FinRL/issues\n",
        "\n",
        "ESG-VARIABLES-PENALIZING\n",
        "* **Pytorch Version**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHCfEiTA80V"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUmLTmoQA7_w"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12v1i0jVkg48"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L63HKnWvkirx"
      },
      "source": [
        "This problem is to design an automated trading solution for portfolio alloacation. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A represents the weight of a stock in the porfolio: a ∈ (-1,1). Assume our stock pool includes N stocks, we can use a list [a<sub>1</sub>, a<sub>2</sub>, ... , a<sub>N</sub>] to determine the weight for each stock in the porfotlio, where a<sub>i</sub> ∈ (-1,1), a<sub>1</sub>+ a<sub>2</sub>+...+a<sub>N</sub>=1. For example, \"The weight of AAPL in the portfolio is 10%.\" is [0.1 , ...].\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_emqQCCklVt"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCcCalAknGn"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2568cp5bU38"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNmvYN9YbU4B"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI2jQ9ITiOFS",
        "outputId": "17f5fe0a-eaef-45e5-b486-5a29b400040e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from stockstats) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from stockstats) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->stockstats) (1.17.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: pyfolio in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (2025.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (1.6.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (0.13.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (0.5.5)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.11/dist-packages (from empyrical>=0.5.0->pyfolio) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (66.0.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18.1->pyfolio) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.16.1->pyfolio) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.16.1->pyfolio) (3.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio) (0.8.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (5.3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.32.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->pyfolio) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2025.1.31)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install stockstats\n",
        "!pip install hyperopt\n",
        "!pip install pyfolio\n",
        "import stockstats\n",
        "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
        "import pyfolio\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlIS2abxkwan"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. FinRL Offline Scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsDbM5Ex5Z1f"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4.1. Yahoo Downloader (from finrl.meta.preprocessor.yahoodownloader import YahooDownloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dZ8zDBudTvb4"
      },
      "outputs": [],
      "source": [
        "\"\"\"Contains methods and classes to collect data from\n",
        "Yahoo Finance API\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None, auto_adjust=False) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic,\n",
        "                start=self.start_date,\n",
        "                end=self.end_date,\n",
        "                proxy=proxy,\n",
        "                auto_adjust=auto_adjust,\n",
        "            )\n",
        "            if temp_df.columns.nlevels != 1:\n",
        "                temp_df.columns = temp_df.columns.droplevel(1)\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures += 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "        try:\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(\n",
        "                columns={\n",
        "                    \"Date\": \"date\",\n",
        "                    \"Adj Close\": \"adjcp\",\n",
        "                    \"Close\": \"close\",\n",
        "                    \"High\": \"high\",\n",
        "                    \"Low\": \"low\",\n",
        "                    \"Volume\": \"volume\",\n",
        "                    \"Open\": \"open\",\n",
        "                    \"tic\": \"tic\",\n",
        "                },\n",
        "                inplace=True,\n",
        "            )\n",
        "\n",
        "            # use adjusted close price instead of close price\n",
        "            data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "            # drop the adjusted close price column\n",
        "            data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFQZ_bX25BR_"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4.2. Data Split (from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oo0isHPfbyEQ"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing.sharedctypes import Value\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "def load_dataset(*, file_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    load csv dataset from path\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n",
        "    _data = pd.read_csv(file_name)\n",
        "    return _data\n",
        "\n",
        "\n",
        "def data_split(df, start, end, target_date_col=\"date\"):\n",
        "    \"\"\"\n",
        "    split the dataset into training or testing using date\n",
        "    :param data: (df) pandas dataframe, start, end\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
        "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
        "    data.index = data[target_date_col].factorize()[0]\n",
        "    return data\n",
        "\n",
        "\n",
        "def convert_to_datetime(time):\n",
        "    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n",
        "    if isinstance(time, str):\n",
        "        return datetime.datetime.strptime(time, time_fmt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtvHJlZ6Fqhn"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4.3. Backtesting Functions (from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rJVQA9fudIkf"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import copy\n",
        "import datetime\n",
        "from copy import deepcopy\n",
        "import empyrical as ep\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyfolio\n",
        "from pyfolio import timeseries\n",
        "import itertools\n",
        "\n",
        "# Replacing from pyfolio import timeseries with original codes ##\n",
        "\n",
        "def gross_lev(positions):\n",
        "    \"\"\"\n",
        "    Calculates the gross leverage of a strategy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    positions : pd.DataFrame\n",
        "        Daily net position values.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.Series\n",
        "        Gross leverage.\n",
        "    \"\"\"\n",
        "\n",
        "    exposure = positions.drop('cash', axis=1).abs().sum(axis=1)\n",
        "    return exposure / positions.sum(axis=1)\n",
        "\n",
        "def get_txn_vol(transactions):\n",
        "    \"\"\"\n",
        "    Extract daily transaction data from set of transaction objects.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    transactions : pd.DataFrame\n",
        "        Time series containing one row per symbol (and potentially\n",
        "        duplicate datetime indices) and columns for amount and\n",
        "        price.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Daily transaction volume and number of shares.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "    \"\"\"\n",
        "\n",
        "    txn_norm = transactions.copy()\n",
        "    txn_norm.index = txn_norm.index.normalize()\n",
        "    amounts = txn_norm.amount.abs()\n",
        "    prices = txn_norm.price\n",
        "    values = amounts * prices\n",
        "    daily_amounts = amounts.groupby(amounts.index).sum()\n",
        "    daily_values = values.groupby(values.index).sum()\n",
        "    daily_amounts.name = \"txn_shares\"\n",
        "    daily_values.name = \"txn_volume\"\n",
        "    return pd.concat([daily_values, daily_amounts], axis=1)\n",
        "\n",
        "def get_turnover(positions, transactions, denominator='AGB'):\n",
        "    \"\"\"\n",
        "     - Value of purchases and sales divided\n",
        "    by either the actual gross book or the portfolio value\n",
        "    for the time step.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    positions : pd.DataFrame\n",
        "        Contains daily position values including cash.\n",
        "        - See full explanation in tears.create_full_tear_sheet\n",
        "    transactions : pd.DataFrame\n",
        "        Prices and amounts of executed trades. One row per trade.\n",
        "        - See full explanation in tears.create_full_tear_sheet\n",
        "    denominator : str, optional\n",
        "        Either 'AGB' or 'portfolio_value', default AGB.\n",
        "        - AGB (Actual gross book) is the gross market\n",
        "        value (GMV) of the specific algo being analyzed.\n",
        "        Swapping out an entire portfolio of stocks for\n",
        "        another will yield 200% turnover, not 100%, since\n",
        "        transactions are being made for both sides.\n",
        "        - We use average of the previous and the current end-of-period\n",
        "        AGB to avoid singularities when trading only into or\n",
        "        out of an entire book in one trading period.\n",
        "        - portfolio_value is the total value of the algo's\n",
        "        positions end-of-period, including cash.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    turnover_rate : pd.Series\n",
        "        timeseries of portfolio turnover rates.\n",
        "    \"\"\"\n",
        "\n",
        "    txn_vol = get_txn_vol(transactions)\n",
        "    traded_value = txn_vol.txn_volume\n",
        "\n",
        "    if denominator == 'AGB':\n",
        "        # Actual gross book is the same thing as the algo's GMV\n",
        "        # We want our denom to be avg(AGB previous, AGB current)\n",
        "        AGB = positions.drop('cash', axis=1).abs().sum(axis=1)\n",
        "        denom = AGB.rolling(2).mean()\n",
        "\n",
        "        # Since the first value of pd.rolling returns NaN, we\n",
        "        # set our \"day 0\" AGB to 0.\n",
        "        denom.iloc[0] = AGB.iloc[0] / 2\n",
        "    elif denominator == 'portfolio_value':\n",
        "        denom = positions.sum(axis=1)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Unexpected value for denominator '{}'. The \"\n",
        "            \"denominator parameter must be either 'AGB'\"\n",
        "            \" or 'portfolio_value'.\".format(denominator)\n",
        "        )\n",
        "\n",
        "    denom.index = denom.index.normalize()\n",
        "    turnover = traded_value.div(denom, axis='index')\n",
        "    turnover = turnover.fillna(0)\n",
        "    return turnover\n",
        "\n",
        "SIMPLE_STAT_FUNCS = [\n",
        "    ep.annual_return,\n",
        "    ep.cum_returns_final,\n",
        "    ep.annual_volatility,\n",
        "    ep.sharpe_ratio,\n",
        "    ep.calmar_ratio,\n",
        "    ep.stability_of_timeseries,\n",
        "    # ep.max_drawdown,\n",
        "    ep.omega_ratio,\n",
        "    # ep.sortino_ratio,\n",
        "    # stats.skew,\n",
        "    # stats.kurtosis,\n",
        "    # ep.tail_ratio,\n",
        "    # value_at_risk\n",
        "]\n",
        "\n",
        "FACTOR_STAT_FUNCS = [\n",
        "    # ep.alpha,\n",
        "    # ep.beta,\n",
        "]\n",
        "\n",
        "STAT_FUNC_NAMES = {\n",
        "    'annual_return': 'Annual return',\n",
        "    'cum_returns_final': 'Cumulative returns',\n",
        "    'annual_volatility': 'Annual volatility',\n",
        "    'sharpe_ratio': 'Sharpe ratio',\n",
        "    'calmar_ratio': 'Calmar ratio',\n",
        "    'stability_of_timeseries': 'Stability',\n",
        "    # 'max_drawdown': 'Max drawdown',\n",
        "    'omega_ratio': 'Omega ratio',\n",
        "    # 'sortino_ratio': 'Sortino ratio',\n",
        "    # 'skew': 'Skew',\n",
        "    # 'kurtosis': 'Kurtosis',\n",
        "    # 'tail_ratio': 'Tail ratio',\n",
        "    # 'common_sense_ratio': 'Common sense ratio',\n",
        "    # 'value_at_risk': 'Daily value at risk',\n",
        "    # 'alpha': 'Alpha',\n",
        "    # 'beta': 'Beta',\n",
        "}\n",
        "\n",
        "\n",
        "def perf_stats(returns, factor_returns=None, positions=None,\n",
        "               transactions=None, turnover_denom='AGB'):\n",
        "    \"\"\"\n",
        "    Calculates various performance metrics of a strategy, for use in\n",
        "    plotting.show_perf_stats.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    returns : pd.Series\n",
        "        Daily returns of the strategy, noncumulative.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "    factor_returns : pd.Series, optional\n",
        "        Daily noncumulative returns of the benchmark factor to which betas are\n",
        "        computed. Usually a benchmark such as market returns.\n",
        "         - This is in the same style as returns.\n",
        "         - If None, do not compute alpha, beta, and information ratio.\n",
        "    positions : pd.DataFrame\n",
        "        Daily net position values.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "    transactions : pd.DataFrame\n",
        "        Prices and amounts of executed trades. One row per trade.\n",
        "        - See full explanation in tears.create_full_tear_sheet.\n",
        "    turnover_denom : str\n",
        "        Either AGB or portfolio_value, default AGB.\n",
        "        - See full explanation in txn.get_turnover.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.Series\n",
        "        Performance metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    stats = pd.Series()\n",
        "    for stat_func in SIMPLE_STAT_FUNCS:\n",
        "        stats[STAT_FUNC_NAMES[stat_func.__name__]] = stat_func(returns)\n",
        "\n",
        "    if positions is not None:\n",
        "        stats['Gross leverage'] = gross_lev(positions).mean()\n",
        "        if transactions is not None:\n",
        "            stats['Daily turnover'] = get_turnover(positions,\n",
        "                                                   transactions,\n",
        "                                                   turnover_denom).mean()\n",
        "    if factor_returns is not None:\n",
        "        for stat_func in FACTOR_STAT_FUNCS:\n",
        "            res = stat_func(returns, factor_returns)\n",
        "            stats[STAT_FUNC_NAMES[stat_func.__name__]] = res\n",
        "\n",
        "    return stats\n",
        "#######################\n",
        "def date2str(dat: datetime.date) -> str:\n",
        "    return datetime.date.strftime(dat, \"%Y-%m-%d\")\n",
        "\n",
        "def str2date(dat: str) -> datetime.date:\n",
        "    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n",
        "\n",
        "def get_daily_return(df, value_col_name=\"account_value\"):\n",
        "    df = deepcopy(df)\n",
        "    df[\"daily_return\"] = df[value_col_name].pct_change(1)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    df.set_index(\"date\", inplace=True, drop=True)\n",
        "    df.index = df.index.tz_localize(\"UTC\")\n",
        "    return pd.Series(df[\"daily_return\"], index=df.index)\n",
        "\n",
        "\n",
        "def convert_daily_return_to_pyfolio_ts(df):\n",
        "    strategy_ret = df.copy()\n",
        "    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n",
        "    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n",
        "    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n",
        "    del strategy_ret[\"date\"]\n",
        "    return pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)\n",
        "\n",
        "\n",
        "# def backtest_stats(account_value, value_col_name=\"account_value\"):\n",
        "#     dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n",
        "#     perf_stats_all = timeseries.perf_stats(\n",
        "#         returns=dr_test,\n",
        "#         positions=None,\n",
        "#         transactions=None,\n",
        "#         turnover_denom=\"AGB\",\n",
        "#     )\n",
        "#     print(perf_stats_all)\n",
        "#     return perf_stats_all\n",
        "\n",
        "def backtest_stats(account_value, value_col_name=\"account_value\"):\n",
        "    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n",
        "    perf_stats_all = perf_stats(\n",
        "        returns=dr_test,\n",
        "        positions=None,\n",
        "        transactions=None,\n",
        "        turnover_denom=\"AGB\",\n",
        "    )\n",
        "    print(perf_stats_all)\n",
        "    return perf_stats_all\n",
        "\n",
        "\n",
        "# def backtest_plot(\n",
        "#     account_value,\n",
        "#     baseline_start=TRADE_START_DATE,\n",
        "#     baseline_end=TRADE_END_DATE,\n",
        "#     baseline_ticker=\"^DJI\",\n",
        "#     value_col_name=\"account_value\",\n",
        "# ):\n",
        "#     df = deepcopy(account_value)\n",
        "#     df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "#     test_returns = get_daily_return(df, value_col_name=value_col_name)\n",
        "\n",
        "#     baseline_df = get_baseline(\n",
        "#         ticker=baseline_ticker, start=baseline_start, end=baseline_end\n",
        "#     )\n",
        "\n",
        "#     baseline_df[\"date\"] = pd.to_datetime(baseline_df[\"date\"], format=\"%Y-%m-%d\")\n",
        "#     baseline_df = pd.merge(df[[\"date\"]], baseline_df, how=\"left\", on=\"date\")\n",
        "#     baseline_df = baseline_df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "#     baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "#     with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
        "#         pyfolio.create_full_tear_sheet(\n",
        "#             returns=test_returns, benchmark_rets=baseline_returns, set_context=False\n",
        "#         )\n",
        "\n",
        "\n",
        "def get_baseline(ticker, start, end):\n",
        "    return YahooDownloader(\n",
        "        start_date=start, end_date=end, ticker_list=[ticker]\n",
        "    ).fetch_data()\n",
        "\n",
        "\n",
        "def trx_plot(df_trade, df_actions, ticker_list):\n",
        "    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n",
        "    df_trx.columns = ticker_list\n",
        "    df_trx.index = df_actions[\"date\"]\n",
        "    df_trx.index.name = \"\"\n",
        "\n",
        "    for i in range(df_trx.shape[1]):\n",
        "        df_trx_temp = df_trx.iloc[:, i]\n",
        "        df_trx_temp_sign = np.sign(df_trx_temp)\n",
        "        buying_signal = df_trx_temp_sign.apply(lambda x: x > 0)\n",
        "        selling_signal = df_trx_temp_sign.apply(lambda x: x < 0)\n",
        "\n",
        "        tic_plot = df_trade[\n",
        "            (df_trade[\"tic\"] == df_trx_temp.name)\n",
        "            & (df_trade[\"date\"].isin(df_trx.index))\n",
        "        ][\"close\"]\n",
        "        tic_plot.index = df_trx_temp.index\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(tic_plot, color=\"g\", lw=2.0)\n",
        "        plt.plot(\n",
        "            tic_plot,\n",
        "            \"^\",\n",
        "            markersize=10,\n",
        "            color=\"m\",\n",
        "            label=\"buying signal\",\n",
        "            markevery=buying_signal,\n",
        "        )\n",
        "        plt.plot(\n",
        "            tic_plot,\n",
        "            \"v\",\n",
        "            markersize=10,\n",
        "            color=\"k\",\n",
        "            label=\"selling signal\",\n",
        "            markevery=selling_signal,\n",
        "        )\n",
        "        plt.title(\n",
        "            f\"{df_trx_temp.name} Num Transactions: {len(buying_signal[buying_signal == True]) + len(selling_signal[selling_signal == True])}\"\n",
        "        )\n",
        "        plt.legend()\n",
        "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=25))\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# 2022-01-15 -> 01/15/2022\n",
        "def transfer_date(str_dat):\n",
        "    return datetime.datetime.strptime(str_dat, \"%Y-%m-%d\").date().strftime(\"%m/%d/%Y\")\n",
        "\n",
        "\n",
        "def plot_result_from_csv(\n",
        "    csv_file: str,\n",
        "    column_as_x: str,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Result\",\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    result = pd.read_csv(csv_file)\n",
        "    plot_result(\n",
        "        result,\n",
        "        column_as_x,\n",
        "        savefig_filename,\n",
        "        xlabel,\n",
        "        ylabel,\n",
        "        num_days_xticks,\n",
        "        xrotation,\n",
        "    )\n",
        "\n",
        "\n",
        "# select_start_date: included\n",
        "# select_end_date: included\n",
        "# is if_need_calc_return is True, it is account_value, and then transfer it to return\n",
        "# it is better that column_as_x is the first column, and the other columns are strategies\n",
        "# xrotation: the rotation of xlabel, may be used in dates. Default=0 (adaptive adjustment)\n",
        "def plot_result(\n",
        "    result: pd.DataFrame(),\n",
        "    column_as_x: str,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Result\",\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    columns = result.columns\n",
        "    columns_strtegy = []\n",
        "    for i in range(len(columns)):\n",
        "        col = columns[i]\n",
        "        if \"Unnamed\" not in col and col != column_as_x:\n",
        "            columns_strtegy.append(col)\n",
        "\n",
        "    result.reindex()\n",
        "\n",
        "    x = result[column_as_x].values.tolist()\n",
        "    plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
        "    # plt.figure()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    colors = [\n",
        "        \"black\",\n",
        "        \"red\",\n",
        "        \"green\",\n",
        "        \"blue\",\n",
        "        \"cyan\",\n",
        "        \"magenta\",\n",
        "        \"yellow\",\n",
        "        \"aliceblue\",\n",
        "        \"coral\",\n",
        "        \"darksalmon\",\n",
        "        \"firebrick\",\n",
        "        \"honeydew\",\n",
        "    ]\n",
        "    for i in range(len(columns_strtegy)):\n",
        "        col = columns_strtegy[i]\n",
        "        ax.plot(\n",
        "            x,\n",
        "            result[col],\n",
        "            color=colors[i],\n",
        "            linewidth=1,\n",
        "            linestyle=\"-\",\n",
        "        )\n",
        "\n",
        "    plt.title(\"\", fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(ylabel, fontsize=20)\n",
        "\n",
        "    plt.legend(labels=columns_strtegy, loc=\"best\", fontsize=16)\n",
        "\n",
        "    # set grid\n",
        "    plt.grid()\n",
        "\n",
        "    plt.xticks(size=22)  # 设置刻度大小\n",
        "    plt.yticks(size=22)  # 设置刻度大小\n",
        "\n",
        "    # #设置每隔多少距离⼀个刻度\n",
        "    # plt.xticks(x[::60])\n",
        "\n",
        "    # # 设置每月定位符\n",
        "    # if if_set_x_monthlocator:\n",
        "    #     ax.xaxis.set_major_locator(mdates.MonthLocator())  # interval = 1\n",
        "\n",
        "    # 设置每隔多少距离⼀个刻度\n",
        "    plt.xticks(x[::num_days_xticks])\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=xrotation, horizontalalignment=\"center\")\n",
        "\n",
        "    # 为防止x轴label重叠，自动调整label旋转角度\n",
        "    if xrotation == 0:\n",
        "        if_overlap = get_if_overlap(fig, ax)\n",
        "\n",
        "        if if_overlap == True:\n",
        "            plt.gcf().autofmt_xdate(ha=\"right\")  # ⾃动旋转⽇期标记\n",
        "\n",
        "    plt.tight_layout()  # 自动调整子图间距\n",
        "\n",
        "    plt.savefig(savefig_filename)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_if_overlap(fig, ax):\n",
        "    fig.canvas.draw()\n",
        "    # 获取日期标签的边界框\n",
        "    bboxes = [label.get_window_extent() for label in ax.get_xticklabels()]\n",
        "    # 计算日期标签之间的距离\n",
        "    distances = [bboxes[i + 1].x0 - bboxes[i].x1 for i in range(len(bboxes) - 1)]\n",
        "    # 如果有任何距离小于0，说明有重叠\n",
        "    if any(distance < 0 for distance in distances):\n",
        "        if_overlap = True\n",
        "    else:\n",
        "        if_overlap = False\n",
        "\n",
        "    return if_overlap\n",
        "\n",
        "\n",
        "def plot_return(\n",
        "    result: pd.DataFrame(),\n",
        "    column_as_x: str,\n",
        "    if_need_calc_return: bool,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Return\",\n",
        "    if_transfer_date: bool = True,\n",
        "    select_start_date: str = None,\n",
        "    select_end_date: str = None,\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    if select_start_date is None:\n",
        "        select_start_date: str = result[column_as_x].iloc[0]\n",
        "        select_end_date: str = result[column_as_x].iloc[-1]\n",
        "    # calc returns if if_need_calc_return is True, so that result stores returns\n",
        "    select_start_date_index = result[column_as_x].tolist().index(select_start_date)\n",
        "    columns = result.columns\n",
        "    columns_strtegy = []\n",
        "    column_as_x_index = None\n",
        "    for i in range(len(columns)):\n",
        "        col = columns[i]\n",
        "        if col == column_as_x:\n",
        "            column_as_x_index = i\n",
        "        elif \"Unnamed\" not in col:\n",
        "            columns_strtegy.append(col)\n",
        "            if if_need_calc_return:\n",
        "                result[col] = result[col] / result[col][select_start_date_index] - 1\n",
        "\n",
        "    # select the result between select_start_date and select_end_date\n",
        "    # if date is 2020-01-15, transfer it to 01/15/2020\n",
        "    num_rows, num_cols = result.shape\n",
        "    tmp_result = copy.deepcopy(result)\n",
        "    result = pd.DataFrame()\n",
        "    if_first_row = True\n",
        "    columns = []\n",
        "    for i in range(num_rows):\n",
        "        if (\n",
        "            str2date(select_start_date)\n",
        "            <= str2date(tmp_result[column_as_x][i])\n",
        "            <= str2date(select_end_date)\n",
        "        ):\n",
        "            if \"-\" in tmp_result.iloc[i][column_as_x] and if_transfer_date:\n",
        "                new_date = transfer_date(tmp_result.iloc[i][column_as_x])\n",
        "            else:\n",
        "                new_date = tmp_result.iloc[i][column_as_x]\n",
        "            tmp_result.iloc[i, column_as_x_index] = new_date\n",
        "            # print(\"tmp_result.iloc[i]: \", tmp_result.iloc[i])\n",
        "            # result = result.append(tmp_result.iloc[i])\n",
        "            if if_first_row:\n",
        "                columns = tmp_result.iloc[i].index.tolist()\n",
        "                result = pd.DataFrame(columns=columns)\n",
        "                # result = pd.concat([result, tmp_result.iloc[i]], axis=1)\n",
        "                # result = pd.DataFrame(tmp_result.iloc[i])\n",
        "                # result.columns = tmp_result.iloc[i].index.tolist()\n",
        "                if_first_row = False\n",
        "            row = pd.DataFrame([tmp_result.iloc[i].tolist()], columns=columns)\n",
        "            result = pd.concat([result, row], axis=0)\n",
        "\n",
        "    # print final return of each strategy\n",
        "    final_return = {}\n",
        "    for col in columns_strtegy:\n",
        "        final_return[col] = result.iloc[-1][col]\n",
        "    print(\"final return: \", final_return)\n",
        "\n",
        "    result.reindex()\n",
        "\n",
        "    plot_result(\n",
        "        result=result,\n",
        "        column_as_x=column_as_x,\n",
        "        savefig_filename=savefig_filename,\n",
        "        xlabel=xlabel,\n",
        "        ylabel=ylabel,\n",
        "        num_days_xticks=num_days_xticks,\n",
        "        xrotation=xrotation,\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_return_from_csv(\n",
        "    csv_file: str,\n",
        "    column_as_x: str,\n",
        "    if_need_calc_return: bool,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Return\",\n",
        "    if_transfer_date: bool = True,\n",
        "    select_start_date: str = None,\n",
        "    select_end_date: str = None,\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    result = pd.read_csv(csv_file)\n",
        "    plot_return(\n",
        "        result,\n",
        "        column_as_x,\n",
        "        if_need_calc_return,\n",
        "        savefig_filename,\n",
        "        xlabel,\n",
        "        ylabel,\n",
        "        if_transfer_date,\n",
        "        select_start_date,\n",
        "        select_end_date,\n",
        "        num_days_xticks,\n",
        "        xrotation,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_vwG5axWdu7S"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime\n",
        "import os\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slBria_QbU4F"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vAxVlL6wwooM"
      },
      "outputs": [],
      "source": [
        "# Indian Sensex 33\n",
        "sensex_ticker = [\"ASIANPAINT.NS\", \"AXISBANK.NS\", \"BAJFINANCE.NS\", \"BAJAJFINSV.NS\", \"BHARTIARTL.NS\", \"HCLTECH.NS\", \"HDFCBANK.NS\",\n",
        "                 \"HINDUNILVR.NS\", \"ICICIBANK.NS\", \"INDUSINDBK.NS\", \"INFY.NS\", \"ITC.NS\", \"JSWSTEEL.NS\", \"KOTAKBANK.NS\", \"LT.NS\",\n",
        "                 \"M&M.NS\", \"MARUTI.NS\", \"NESTLEIND.NS\", \"NTPC.NS\", \"POWERGRID.NS\", \"RELIANCE.NS\", \"SBIN.NS\", \"SUNPHARMA.NS\",\n",
        "                 \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TCS.NS\", \"TECHM.NS\", \"TITAN.NS\", \"ULTRACEMCO.NS\", \"WIPRO.NS\"]\n",
        "\n",
        "Nifty_50 = ['ADANIENT.NS', 'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS',\n",
        "       'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJAJFINSV.NS', 'BAJFINANCE.NS',\n",
        "       'BHARTIARTL.NS', 'BPCL.NS', 'BRITANNIA.NS', 'CIPLA.NS', 'COALINDIA.NS',\n",
        "       'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS', 'GRASIM.NS', 'HCLTECH.NS',\n",
        "       'HDFCBANK.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS',\n",
        "       'ICICIBANK.NS', 'INDUSINDBK.NS', 'ITC.NS', 'JSWSTEEL.NS',\n",
        "       'KOTAKBANK.NS', 'LT.NS', 'M&M.NS', 'MARUTI.NS', 'NESTLEIND.NS',\n",
        "       'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBIN.NS',\n",
        "       'SUNPHARMA.NS', 'TATACONSUM.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS',\n",
        "       'TCS.NS', 'TECHM.NS', 'TITAN.NS', 'UPL.NS', 'WIPRO.NS', \"INFY.NS\", \"ULTRACEMCO.NS\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install setuptools==66\n",
        "!pip install stockstats\n",
        "!pip install hyperopt\n",
        "# !pip install pyfolio\n",
        "import stockstats\n",
        "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
        "# import pyfolio\n",
        "from collections import deque"
      ],
      "metadata": {
        "id": "maq0L3gcXvFO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19ea5360-98e4-4688-e340-4bd875fcb36f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools==66 in /usr/local/lib/python3.11/dist-packages (66.0.0)\n",
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from stockstats) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from stockstats) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->stockstats) (1.17.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Contains methods and classes to collect data from\n",
        "Yahoo Finance API\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None, auto_adjust=False) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic,\n",
        "                start=self.start_date,\n",
        "                end=self.end_date,\n",
        "                proxy=proxy,\n",
        "                auto_adjust=auto_adjust,\n",
        "            )\n",
        "            if temp_df.columns.nlevels != 1:\n",
        "                temp_df.columns = temp_df.columns.droplevel(1)\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures = num_failures+ 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "        try:\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(\n",
        "                columns={\n",
        "                    \"Date\": \"date\",\n",
        "                    \"Adj Close\": \"adjcp\",\n",
        "                    \"Close\": \"close\",\n",
        "                    \"High\": \"high\",\n",
        "                    \"Low\": \"low\",\n",
        "                    \"Volume\": \"volume\",\n",
        "                    \"Open\": \"open\",\n",
        "                    \"tic\": \"tic\",\n",
        "                },\n",
        "                inplace=True,\n",
        "            )\n",
        "\n",
        "            # use adjusted close price instead of close price\n",
        "            data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "            # drop the adjusted close price column\n",
        "            data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df"
      ],
      "metadata": {
        "id": "J-9xQFbkX0D9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing.sharedctypes import Value\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "def load_dataset(*, file_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    load csv dataset from path\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n",
        "    _data = pd.read_csv(file_name)\n",
        "    return _data\n",
        "\n",
        "\n",
        "def data_split(df, start, end, target_date_col=\"date\"):\n",
        "    \"\"\"\n",
        "    split the dataset into training or testing using date\n",
        "    :param data: (df) pandas dataframe, start, end\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
        "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
        "    data.index = data[target_date_col].factorize()[0]\n",
        "    return data\n",
        "\n",
        "\n",
        "def convert_to_datetime(time):\n",
        "    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n",
        "    if isinstance(time, str):\n",
        "        return datetime.datetime.strptime(time, time_fmt)"
      ],
      "metadata": {
        "id": "vqYU4J64X3G-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import datetime\n",
        "import os\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "6aiSeCMfX5p7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mnKtEacCSiZ"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hyperopt\n",
        "from hyperopt import fmin, tpe, hp, Trials, space_eval"
      ],
      "metadata": {
        "id": "Y97Nv8RbX7xa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990ee7d0-f62b-4678-b607-65521ec0124c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afbOK2ImYLIr"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "jgD9YxMjy4gb"
      },
      "outputs": [],
      "source": [
        "Market = 'Nifty_50'\n",
        "Reward = 'LSTM'\n",
        "BL = '^NSEI'\n",
        "#BL = '^CNX100'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQT27rmvV0BG",
        "outputId": "4600671f-2bd5-44b7-fa0c-6f942a8e3c26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (104760, 8)\n"
          ]
        }
      ],
      "source": [
        "# Download and save the data in a pandas DataFrame:\n",
        "df = YahooDownloader(start_date = '2011-01-01',\n",
        "                     end_date = '2025-02-28',\n",
        "                     ticker_list = sensex_ticker).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mS1-nxRzbU4i",
        "outputId": "ad268ec9-5f57-4364-ccb5-4a6e29e343cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Price         date         close          high           low          open  \\\n",
              "0       2011-01-03    256.154327    293.739990    286.005005    289.799988   \n",
              "1       2011-01-03    251.461975    274.399994    268.459991    273.000000   \n",
              "2       2011-01-03     45.565235     46.357517     45.478214     45.497864   \n",
              "3       2011-01-03     63.335735     69.832405     68.341026     69.832405   \n",
              "4       2011-01-03    301.886902    328.958893    319.721008    325.263733   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "104755  2025-02-27   3612.550049   3638.000000   3600.699951   3611.699951   \n",
              "104756  2025-02-27   1588.250000   1595.699951   1569.900024   1575.000000   \n",
              "104757  2025-02-27   3223.100098   3228.000000   3176.949951   3198.800049   \n",
              "104758  2025-02-27  10447.650391  10800.000000  10264.400391  10800.000000   \n",
              "104759  2025-02-27    294.500000    295.799988    291.350006    294.000000   \n",
              "\n",
              "Price     volume            tic  day  \n",
              "0         454300  ASIANPAINT.NS    0  \n",
              "1        5266100    AXISBANK.NS    0  \n",
              "2         120767  BAJAJFINSV.NS    0  \n",
              "3         129932  BAJFINANCE.NS    0  \n",
              "4        3283719  BHARTIARTL.NS    0  \n",
              "...          ...            ...  ...  \n",
              "104755   3823856         TCS.NS    3  \n",
              "104756   2208643       TECHM.NS    3  \n",
              "104757    604023       TITAN.NS    3  \n",
              "104758   1722295  ULTRACEMCO.NS    3  \n",
              "104759  15555649       WIPRO.NS    3  \n",
              "\n",
              "[104760 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6912bd80-0eeb-4f4e-9b73-3f309ab6ae47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Price</th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>256.154327</td>\n",
              "      <td>293.739990</td>\n",
              "      <td>286.005005</td>\n",
              "      <td>289.799988</td>\n",
              "      <td>454300</td>\n",
              "      <td>ASIANPAINT.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>251.461975</td>\n",
              "      <td>274.399994</td>\n",
              "      <td>268.459991</td>\n",
              "      <td>273.000000</td>\n",
              "      <td>5266100</td>\n",
              "      <td>AXISBANK.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>45.565235</td>\n",
              "      <td>46.357517</td>\n",
              "      <td>45.478214</td>\n",
              "      <td>45.497864</td>\n",
              "      <td>120767</td>\n",
              "      <td>BAJAJFINSV.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>63.335735</td>\n",
              "      <td>69.832405</td>\n",
              "      <td>68.341026</td>\n",
              "      <td>69.832405</td>\n",
              "      <td>129932</td>\n",
              "      <td>BAJFINANCE.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>301.886902</td>\n",
              "      <td>328.958893</td>\n",
              "      <td>319.721008</td>\n",
              "      <td>325.263733</td>\n",
              "      <td>3283719</td>\n",
              "      <td>BHARTIARTL.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104755</th>\n",
              "      <td>2025-02-27</td>\n",
              "      <td>3612.550049</td>\n",
              "      <td>3638.000000</td>\n",
              "      <td>3600.699951</td>\n",
              "      <td>3611.699951</td>\n",
              "      <td>3823856</td>\n",
              "      <td>TCS.NS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104756</th>\n",
              "      <td>2025-02-27</td>\n",
              "      <td>1588.250000</td>\n",
              "      <td>1595.699951</td>\n",
              "      <td>1569.900024</td>\n",
              "      <td>1575.000000</td>\n",
              "      <td>2208643</td>\n",
              "      <td>TECHM.NS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104757</th>\n",
              "      <td>2025-02-27</td>\n",
              "      <td>3223.100098</td>\n",
              "      <td>3228.000000</td>\n",
              "      <td>3176.949951</td>\n",
              "      <td>3198.800049</td>\n",
              "      <td>604023</td>\n",
              "      <td>TITAN.NS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104758</th>\n",
              "      <td>2025-02-27</td>\n",
              "      <td>10447.650391</td>\n",
              "      <td>10800.000000</td>\n",
              "      <td>10264.400391</td>\n",
              "      <td>10800.000000</td>\n",
              "      <td>1722295</td>\n",
              "      <td>ULTRACEMCO.NS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104759</th>\n",
              "      <td>2025-02-27</td>\n",
              "      <td>294.500000</td>\n",
              "      <td>295.799988</td>\n",
              "      <td>291.350006</td>\n",
              "      <td>294.000000</td>\n",
              "      <td>15555649</td>\n",
              "      <td>WIPRO.NS</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>104760 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6912bd80-0eeb-4f4e-9b73-3f309ab6ae47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6912bd80-0eeb-4f4e-9b73-3f309ab6ae47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6912bd80-0eeb-4f4e-9b73-3f309ab6ae47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9be7af5f-9d4f-4d12-8109-d52d22ff0d13\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9be7af5f-9d4f-4d12-8109-d52d22ff0d13')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9be7af5f-9d4f-4d12-8109-d52d22ff0d13 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_590a599c-2790-48c2-9c65-3ece215417bc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_590a599c-2790-48c2-9c65-3ece215417bc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "df.shape\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srkOBy5nY9Hv"
      },
      "source": [
        "## Our Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JQKygIHcuWsN"
      },
      "outputs": [],
      "source": [
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "def add_tech(data, INDICATORS):\n",
        "  df = data.copy()\n",
        "  df = df.sort_values(by=[\"tic\", \"date\"])\n",
        "  stock = Sdf.retype(df.copy())\n",
        "  unique_ticker = stock.tic.unique()\n",
        "\n",
        "  for indicator in INDICATORS:\n",
        "      indicator_df = pd.DataFrame()\n",
        "      for i in range(len(unique_ticker)):\n",
        "          try:\n",
        "              temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]\n",
        "              temp_indicator = pd.DataFrame(temp_indicator)\n",
        "              temp_indicator[\"tic\"] = unique_ticker[i]\n",
        "              temp_indicator[\"date\"] = df[df.tic == unique_ticker[i]][\n",
        "                  \"date\"\n",
        "              ].to_list()\n",
        "              # indicator_df = indicator_df.append(\n",
        "              #     temp_indicator, ignore_index=True\n",
        "              # )\n",
        "              indicator_df = pd.concat(\n",
        "                  [indicator_df, temp_indicator], axis=0, ignore_index=True\n",
        "              )\n",
        "          except Exception as e:\n",
        "              print(e)\n",
        "      df = df.merge(\n",
        "          indicator_df[[\"tic\", \"date\", indicator]], on=[\"tic\", \"date\"], how=\"left\"\n",
        "      )\n",
        "\n",
        "  df = df.sort_values(by=[\"date\", \"tic\"])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "noCZD8Ysudjp"
      },
      "outputs": [],
      "source": [
        "INDICATORS = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
        "df = add_tech(df, INDICATORS)\n",
        "df = df.ffill().bfill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HRhdUmpRukT0"
      },
      "outputs": [],
      "source": [
        "# add covariance matrix as states\n",
        "df=df.sort_values(['date','tic'],ignore_index=True)\n",
        "df.index = df.date.factorize()[0]\n",
        "\n",
        "cov_list = []\n",
        "return_list = []\n",
        "\n",
        "# look back is one year\n",
        "lookback=252\n",
        "for i in range(lookback,len(df.index.unique())):\n",
        "  data_lookback = df.loc[i-lookback:i,:]\n",
        "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
        "  return_lookback = price_lookback.pct_change().dropna()\n",
        "  return_list.append(return_lookback)\n",
        "\n",
        "  covs = return_lookback.cov().values\n",
        "  cov_list.append(covs)\n",
        "\n",
        "\n",
        "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "df = df.merge(df_cov, on='date')\n",
        "df = df.sort_values(['date','tic']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "kdeVQHXrun6t",
        "outputId": "f4a32d4e-08da-41cb-df33-1063526f3898"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       close        high         low        open   volume  \\\n",
              "0  2012-01-10  239.222229  269.500000  264.500000  268.855011   338040   \n",
              "1  2012-01-10  166.384064  179.399994  173.220001  173.800003  9827090   \n",
              "2  2012-01-10   42.398281   43.130127   42.245911   42.589771   295237   \n",
              "3  2012-01-10   57.317436   61.403934   59.315037   60.223461    35673   \n",
              "4  2012-01-10  278.227142  300.479187  289.348633  289.348633  9865514   \n",
              "\n",
              "             tic  day      macd     boll_ub     boll_lb     rsi_30     cci_30  \\\n",
              "0  ASIANPAINT.NS    1 -4.970681  250.422288  230.752879  40.195530 -53.408665   \n",
              "1    AXISBANK.NS    1 -5.285489  175.857186  144.370963  44.932214 -19.455704   \n",
              "2  BAJAJFINSV.NS    1 -0.579626   43.435289   38.436666  45.362703  43.496386   \n",
              "3  BAJFINANCE.NS    1 -0.950270   60.000609   53.893185  47.765405 -37.039048   \n",
              "4  BHARTIARTL.NS    1 -7.057571  300.710533  270.360450  42.690374 -94.654349   \n",
              "\n",
              "       dx_30  close_30_sma  close_60_sma  \\\n",
              "0  30.113608    245.870742    261.232407   \n",
              "1  18.677290    168.103825    183.434647   \n",
              "2   7.443321     41.387002     45.780653   \n",
              "3  19.916950     57.761540     59.338969   \n",
              "4  18.773105    294.552144    310.406216   \n",
              "\n",
              "                                            cov_list  \\\n",
              "0  [[0.00021241521299421515, 8.694848997675289e-0...   \n",
              "1  [[0.00021241521299421515, 8.694848997675289e-0...   \n",
              "2  [[0.00021241521299421515, 8.694848997675289e-0...   \n",
              "3  [[0.00021241521299421515, 8.694848997675289e-0...   \n",
              "4  [[0.00021241521299421515, 8.694848997675289e-0...   \n",
              "\n",
              "                                         return_list  \n",
              "0  tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...  \n",
              "1  tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...  \n",
              "2  tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...  \n",
              "3  tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...  \n",
              "4  tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70cae201-fba3-4dbf-90eb-2371acc533ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>239.222229</td>\n",
              "      <td>269.500000</td>\n",
              "      <td>264.500000</td>\n",
              "      <td>268.855011</td>\n",
              "      <td>338040</td>\n",
              "      <td>ASIANPAINT.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-4.970681</td>\n",
              "      <td>250.422288</td>\n",
              "      <td>230.752879</td>\n",
              "      <td>40.195530</td>\n",
              "      <td>-53.408665</td>\n",
              "      <td>30.113608</td>\n",
              "      <td>245.870742</td>\n",
              "      <td>261.232407</td>\n",
              "      <td>[[0.00021241521299421515, 8.694848997675289e-0...</td>\n",
              "      <td>tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>166.384064</td>\n",
              "      <td>179.399994</td>\n",
              "      <td>173.220001</td>\n",
              "      <td>173.800003</td>\n",
              "      <td>9827090</td>\n",
              "      <td>AXISBANK.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.285489</td>\n",
              "      <td>175.857186</td>\n",
              "      <td>144.370963</td>\n",
              "      <td>44.932214</td>\n",
              "      <td>-19.455704</td>\n",
              "      <td>18.677290</td>\n",
              "      <td>168.103825</td>\n",
              "      <td>183.434647</td>\n",
              "      <td>[[0.00021241521299421515, 8.694848997675289e-0...</td>\n",
              "      <td>tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>42.398281</td>\n",
              "      <td>43.130127</td>\n",
              "      <td>42.245911</td>\n",
              "      <td>42.589771</td>\n",
              "      <td>295237</td>\n",
              "      <td>BAJAJFINSV.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.579626</td>\n",
              "      <td>43.435289</td>\n",
              "      <td>38.436666</td>\n",
              "      <td>45.362703</td>\n",
              "      <td>43.496386</td>\n",
              "      <td>7.443321</td>\n",
              "      <td>41.387002</td>\n",
              "      <td>45.780653</td>\n",
              "      <td>[[0.00021241521299421515, 8.694848997675289e-0...</td>\n",
              "      <td>tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>57.317436</td>\n",
              "      <td>61.403934</td>\n",
              "      <td>59.315037</td>\n",
              "      <td>60.223461</td>\n",
              "      <td>35673</td>\n",
              "      <td>BAJFINANCE.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.950270</td>\n",
              "      <td>60.000609</td>\n",
              "      <td>53.893185</td>\n",
              "      <td>47.765405</td>\n",
              "      <td>-37.039048</td>\n",
              "      <td>19.916950</td>\n",
              "      <td>57.761540</td>\n",
              "      <td>59.338969</td>\n",
              "      <td>[[0.00021241521299421515, 8.694848997675289e-0...</td>\n",
              "      <td>tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>278.227142</td>\n",
              "      <td>300.479187</td>\n",
              "      <td>289.348633</td>\n",
              "      <td>289.348633</td>\n",
              "      <td>9865514</td>\n",
              "      <td>BHARTIARTL.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-7.057571</td>\n",
              "      <td>300.710533</td>\n",
              "      <td>270.360450</td>\n",
              "      <td>42.690374</td>\n",
              "      <td>-94.654349</td>\n",
              "      <td>18.773105</td>\n",
              "      <td>294.552144</td>\n",
              "      <td>310.406216</td>\n",
              "      <td>[[0.00021241521299421515, 8.694848997675289e-0...</td>\n",
              "      <td>tic         ASIANPAINT.NS  AXISBANK.NS  BAJAJF...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70cae201-fba3-4dbf-90eb-2371acc533ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70cae201-fba3-4dbf-90eb-2371acc533ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70cae201-fba3-4dbf-90eb-2371acc533ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d06b8a6e-7271-4711-b1dd-cb703aaa0b23\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d06b8a6e-7271-4711-b1dd-cb703aaa0b23')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d06b8a6e-7271-4711-b1dd-cb703aaa0b23 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 97200,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 3240,\n        \"samples\": [\n          \"2021-06-28\",\n          \"2017-03-23\",\n          \"2022-03-31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1669.3808642679512,\n        \"min\": 6.655767440795898,\n        \"max\": 13495.599609375,\n        \"num_unique_values\": 93658,\n        \"samples\": [\n          862.6978759765625,\n          105.41072845458984,\n          1013.8413696289062\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"high\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1717.6527875409197,\n        \"min\": 19.626373291015625,\n        \"max\": 13680.0,\n        \"num_unique_values\": 54744,\n        \"samples\": [\n          2096.949951171875,\n          204.875,\n          3418.89990234375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"low\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1680.8959314917668,\n        \"min\": 18.60694694519043,\n        \"max\": 13274.4501953125,\n        \"num_unique_values\": 56736,\n        \"samples\": [\n          566.2222290039062,\n          1150.1729736328125,\n          155.5749969482422\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"open\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1700.2215897316253,\n        \"min\": 18.816547393798828,\n        \"max\": 13393.0,\n        \"num_unique_values\": 47760,\n        \"samples\": [\n          3286.050048828125,\n          2821.699951171875,\n          6988.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20306960,\n        \"min\": 0,\n        \"max\": 642845990,\n        \"num_unique_values\": 96585,\n        \"samples\": [\n          8820568,\n          4117044,\n          8507992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"TITAN.NS\",\n          \"M&M.NS\",\n          \"TATAMOTORS.NS\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"macd\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 36.62030062553436,\n        \"min\": -567.5377155234155,\n        \"max\": 425.92344533899995,\n        \"num_unique_values\": 97200,\n        \"samples\": [\n          2.856425699912961,\n          -112.1924815046309,\n          0.5520088080409096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"boll_ub\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1747.5646645080524,\n        \"min\": 8.542145771605082,\n        \"max\": 13559.607017953826,\n        \"num_unique_values\": 97167,\n        \"samples\": [\n          245.10809373902336,\n          839.1242000999603,\n          633.4956919052664\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"boll_lb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1573.998919248718,\n        \"min\": 6.059739230696337,\n        \"max\": 12225.462215770185,\n        \"num_unique_values\": 97167,\n        \"samples\": [\n          216.71161603880867,\n          755.4805362281647,\n          596.8089040419992\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rsi_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.351515988634667,\n        \"min\": 15.821380361550865,\n        \"max\": 83.66965506147376,\n        \"num_unique_values\": 96962,\n        \"samples\": [\n          42.032457344592395,\n          49.551866980248136,\n          60.64481532879553\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cci_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 113.3904182644932,\n        \"min\": -675.2968068383591,\n        \"max\": 622.1596857335917,\n        \"num_unique_values\": 97200,\n        \"samples\": [\n          -81.15578918272755,\n          -66.47033459097798,\n          -57.402906414466536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dx_30\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.09409430062593,\n        \"min\": 0.0001281134625121401,\n        \"max\": 80.1149596631061,\n        \"num_unique_values\": 94618,\n        \"samples\": [\n          0.8128631225946706,\n          41.45844911280247,\n          28.060312215035367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_30_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1654.615771615988,\n        \"min\": 7.821102142333984,\n        \"max\": 12585.35322265625,\n        \"num_unique_values\": 97151,\n        \"samples\": [\n          6737.664013671875,\n          424.3361104329427,\n          2108.229069010417\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"close_60_sma\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1640.2956397680512,\n        \"min\": 8.13818162282308,\n        \"max\": 12496.714306640624,\n        \"num_unique_values\": 97178,\n        \"samples\": [\n          495.34632110595703,\n          1868.496720377604,\n          230.9967046101888\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cov_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"return_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "\n",
        "hist_vol=[]\n",
        "for i in range(len(df['return_list'])):\n",
        "x  returns = df['return_list'].values[i].std()\n",
        "  hist_vol.append(returns)\n",
        "print(len(hist_vol))\n",
        "\n",
        "hist_vol= np.array(hist_vol)\n",
        "# print(hist_vol.shape)\n",
        "# print(hist_vol)\n",
        "hist_vol= pd.DataFrame(hist_vol, df['date'])\n",
        "# print(hist_vol.shape)\n",
        "# print(df)"
      ],
      "metadata": {
        "id": "LPkxeRDRYrKO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11b9af2c-851a-4a5a-cc75-de9e9d0197cd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(97200, 18)\n",
            "97200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UooHj1OgbU4v"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "O6LcOPKtkquK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c8c4df-ef43-4545-c3a8-3522d279711d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shimmy\n",
            "  Downloading Shimmy-2.0.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy) (2.0.2)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.13.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Downloading Shimmy-2.0.0-py3-none-any.whl (30 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-2.0.0\n",
            "Collecting stable_baselines3\n",
            "  Downloading stable_baselines3-2.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.0.2)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (4.13.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0,>=2.3->stable_baselines3)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Downloading stable_baselines3-2.6.0-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.5/184.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m71.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m847.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, stable_baselines3\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 stable_baselines3-2.6.0\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (2.0.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip install shimmy\n",
        "!pip install stable_baselines3\n",
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xlfE-VERbU40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQnmN1qdk88I"
      },
      "source": [
        "## Training data split: 2009-01-01 to 2020-07-01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1b8woqs1gQy4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fe21483-6e2b-40f2-81d4-9a36ba836b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(81210, 18)\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2011-01-01'\n",
        "TRAIN_END_DATE = '2021-12-31'\n",
        "\n",
        "# TRAIN_END_DATE = '2012-12-01'\n",
        "\n",
        "Val_START_DATE = '2022-01-01'\n",
        "VAL_END_DATE =  '2022-12-31'\n",
        "TRADE_START_DATE = '2023-01-01'\n",
        "TRADE_END_DATE = '2025-02-28'\n",
        "# print(df[30:])\n",
        "# hist_vol = hist_vol.reset_index(drop=True)\n",
        "\n",
        "train = data_split(df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "hist_vol_train = hist_vol[TRAIN_START_DATE : TRAIN_END_DATE]\n",
        "\n",
        "val = data_split(df, Val_START_DATE, VAL_END_DATE)\n",
        "hist_vol_val=hist_vol[Val_START_DATE :VAL_END_DATE]\n",
        "\n",
        "full_train = data_split(df, TRAIN_START_DATE, VAL_END_DATE)\n",
        "hist_vol_full_train= hist_vol[TRAIN_START_DATE :VAL_END_DATE]\n",
        "\n",
        "\n",
        "# full_train = data_split(df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "# hist_vol_full_train= hist_vol[TRAIN_START_DATE :TRAIN_END_DATE]\n",
        "\n",
        "trade = data_split(df, TRADE_START_DATE,TRADE_END_DATE)\n",
        "hist_vol_trade= hist_vol[TRADE_START_DATE  : TRADE_END_DATE]\n",
        "\n",
        "print(full_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az9fR5itsMj1",
        "outputId": "be308308-580d-4c0e-d564-a9cce80d6fc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{30}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "values = val.index\n",
        "set(Counter(values).values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO2-gdFopwqd",
        "outputId": "660e378f-9fc2-46a7-8a5b-90e3d15085b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ASIANPAINT.NS', 'AXISBANK.NS', 'BAJAJFINSV.NS', 'BAJFINANCE.NS',\n",
              "       'BHARTIARTL.NS', 'HCLTECH.NS', 'HDFCBANK.NS', 'HINDUNILVR.NS',\n",
              "       'ICICIBANK.NS', 'INDUSINDBK.NS', 'INFY.NS', 'ITC.NS', 'JSWSTEEL.NS',\n",
              "       'KOTAKBANK.NS', 'LT.NS', 'M&M.NS', 'MARUTI.NS', 'NESTLEIND.NS',\n",
              "       'NTPC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBIN.NS', 'SUNPHARMA.NS',\n",
              "       'TATAMOTORS.NS', 'TATASTEEL.NS', 'TCS.NS', 'TECHM.NS', 'TITAN.NS',\n",
              "       'ULTRACEMCO.NS', 'WIPRO.NS'],\n",
              "      dtype='object', name='tic')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Working Stocks\n",
        "train.loc[0,:]['return_list'].values[0].columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Hs-Qzzpzv_",
        "outputId": "3a7af16a-26e1-4c43-8bbe-6caeeb5d0533"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(train.loc[0,:]['return_list'].values[0].columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RYE3YvyfVMb"
      },
      "source": [
        "Here is the definition of the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "lo5O9o1dUu5C"
      },
      "outputs": [],
      "source": [
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A single stock trading environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then\n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self,\n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                Rebalance=False,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0, hist_vol = None ):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct = transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.rebalance = Rebalance\n",
        "        self.DSR_A = 0.0\n",
        "        self.DSR_B = 0.0\n",
        "        self.Return_queue = deque([0]*50, maxlen=50)\n",
        "        self.hist_vol= hist_vol\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
        "        # Shape = (34, 30)\n",
        "        # covariance matrix + technical indicators + ESG (4). Ojo, no funciona meter aqui el shape bueno. Esto puede causar problemas.\n",
        "\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space + 1 +len(self.tech_indicator_list), self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "\n",
        "        self.state = np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        hist_vollll= self.hist_vol.values[self.day,:]\n",
        "        self.state = np.concatenate([self.state, hist_vollll.reshape(1,-1) ], axis=0)\n",
        "\n",
        "\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        print(f\" the len of the df is  {len(self.df.index.unique())}  and the current day is :  {self.day } and  if  terminal is  : { self.day >= len(self.df.index.unique()) - 1 }\")\n",
        "\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            # plt.plot(df.daily_return.cumsum(),'r')\n",
        "            # plt.savefig('results/cumulative_reward.png')\n",
        "            # plt.close()\n",
        "\n",
        "            # plt.plot(self.portfolio_return_memory,'r')\n",
        "            # plt.savefig('results/rewards.png')\n",
        "            # plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() !=0:\n",
        "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                       df_daily_return['daily_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            #print(\"Model actions: \",actions)\n",
        "            # actions are the portfolio weight\n",
        "            # normalize to sum of 1\n",
        "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
        "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
        "            #else:\n",
        "            #  norm_actions = actions\n",
        "            # weights = self.softmax_normalization(actions)\n",
        "\n",
        "            ## Repair Mechanism\n",
        "            weights = self.repair_portfolio(actions, 15, 0.01, 1)\n",
        "            # print('Weights', weights)\n",
        "            # print('Weights',np.sum(weights))\n",
        "            # ## Rebalancing of the Portfolio Weights\n",
        "            # print('Actions', actions)\n",
        "            # weights = self.softmax_normalization(actions)\n",
        "            # print('Weights',weights)\n",
        "            # if self.rebalance == True:\n",
        "            #   if self.actions_memory:\n",
        "            #       w_old = self.actions_memory[-1]\n",
        "            #   else:\n",
        "            #       w_old = np.zeros(self.stock_dim)\n",
        "\n",
        "            #   rebalance_threshold = 0.01\n",
        "            #   del_w = weights - w_old\n",
        "            #   del_w[np.abs(del_w) < rebalance_threshold] = 0\n",
        "            #   new_w = w_old + del_w\n",
        "\n",
        "            #   different_mask = w_old != new_w\n",
        "            #   sum_same = np.sum(new_w[~different_mask])\n",
        "            #   rem_balance = 1 - sum_same\n",
        "\n",
        "            #   different_entries = new_w[different_mask]\n",
        "            #   sum_diff = np.sum(different_entries)\n",
        "            #   if sum_diff != 0:\n",
        "            #       normalized_diff = different_entries / sum_diff\n",
        "            #   else:\n",
        "            #       normalized_diff = different_entries\n",
        "\n",
        "            #   new_w[different_mask] = normalized_diff*rem_balance\n",
        "\n",
        "            #   weights = new_w\n",
        "\n",
        "            #print(\"Weights: \",weights)\n",
        "\n",
        "            #print(\"Weights: \",weights\n",
        "            #print(\"Normalized actions: \", weights)\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day = self.day +  1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            #print(self.state)\n",
        "            hist_volll = self.hist_vol.values[self.day,:]\n",
        "            self.state = np.concatenate([self.state, hist_volll.reshape(1,-1) ], axis=0)\n",
        "\n",
        "            #print(self.state)\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            self.Return_queue.appendleft(portfolio_return)\n",
        "\n",
        "            #...Weights tbc by investor´s preference\n",
        "            # portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            # update portfolio value\n",
        "            if self.rebalance == True:\n",
        "              new_portfolio_value = self.portfolio_value*(1+portfolio_return) - np.sum(self.transaction_cost_pct*self.portfolio_value*del_w)\n",
        "            else:\n",
        "              new_portfolio_value = self.portfolio_value*(1+portfolio_return) - np.sum(self.transaction_cost_pct*self.portfolio_value*weights)\n",
        "\n",
        "            rew = 0\n",
        "            for i in range(self.covs.shape[0]):\n",
        "              for j in range(self.covs.shape[1]):\n",
        "                rew = rew + weights[i]*weights[j]*self.covs[i][j]\n",
        "\n",
        "            #Aqui es donde hay que ponderar el ESG.\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "            old_portfolio_value = self.asset_memory[-1]\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "            # Calculate Transaction Fee\n",
        "            # phi = 0.0025  # 0.25% transaction cost\n",
        "            # # Reshape portfolio_value to match dimensions of other arrays\n",
        "            # portfolio_value_reshaped = np.repeat(self.portfolio_value, len(weights))\n",
        "            # transaction_fee = phi * sum(\n",
        "            #     abs(weights * new_portfolio_value * last_day_memory.close.values / self.data.close.values\n",
        "            #         - self.actions_memory[-2] * portfolio_value_reshaped)  # Use portfolio_value_reshaped\n",
        "            # )\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value\n",
        "            # self.reward = new_portfolio_value - transaction_fee   # normal portfolio return\n",
        "            # self.reward = np.log(new_portfolio_value/ old_portfolio_value)      # log return of portfolio\n",
        "            # self.reward = self.calculate_DSR(new_portfolio_value)             # Differential Sharpe ratio\n",
        "            # self.reward = -((max(self.asset_memory) - new_portfolio_value)/ (max(self.asset_memory) + 1e-7)) * 100          # drawdown ( try to bring the gap between highest and current value to 0)\n",
        "            # self.reward = self.calculate_MDDR(new_portfolio_value)             # MDD with return\n",
        "            # self.reward = -rew*1000\n",
        "            #print(\"Step reward: \", self.reward)\n",
        "            #self.reward = self.reward*self.reward_scaling\n",
        "            # r1 = self.calculate_DSR(new_portfolio_value)\n",
        "            # r2 = np.log(new_portfolio_value/ old_portfolio_value)\n",
        "            # r3 = ((max(self.asset_memory) - new_portfolio_value)/ (max(self.asset_memory) + 1e-7)) * 100\n",
        "            # self.reward = 0.25*r1 + 0.415*r2 - 0.335*r3\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "\n",
        "        hist_voll = self.hist_vol.values[self.day,:]\n",
        "        self.state = np.concatenate([self.state, hist_voll.reshape(1,-1) ], axis=0)\n",
        "\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.DSR_A = 0.0\n",
        "        self.DSR_B = 0.0\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs\n",
        "\n",
        "    def calculate_DSR(self, R):\n",
        "      eta = 0.004\n",
        "      delta_A = R - self.DSR_A\n",
        "      delta_B = R**2 - self.DSR_B\n",
        "      Dt = (self.DSR_B*delta_A - 0.5*self.DSR_A*delta_B) / ((self.DSR_B-self.DSR_A**2)**(3/2) + 1e-6)\n",
        "      self.DSR_A = self.DSR_A + eta*delta_A\n",
        "      self.DSR_B = self.DSR_B + eta*delta_B\n",
        "      return(Dt)\n",
        "\n",
        "    def calculate_MDDR(self, R):\n",
        "      k = 1\n",
        "      a = 3\n",
        "      mdd = ((max(self.asset_memory) - R)/ (max(self.asset_memory) + 1e-7)) * 100\n",
        "      mddr = (1 / (1 + np.exp(-R))) * (-np.exp(mdd) + np.exp(a))\n",
        "      return(mddr)\n",
        "\n",
        "    def repair_portfolio(self, actions, K, l, u):\n",
        "      \"\"\"\n",
        "      Parameters:\n",
        "          actions (numpy array): Raw action vector from DRL agent.\n",
        "          K (int): Maximum number of selected assets (cardinality constraint).\n",
        "          lower_bounds (numpy array): Minimum allowed weights (l_i).\n",
        "          upper_bounds (numpy array): Maximum allowed weights (u_i).\n",
        "\n",
        "      Returns:\n",
        "          numpy array: Adjusted and valid portfolio weights.\n",
        "      \"\"\"\n",
        "\n",
        "      # Step 1: Get indices of Top-K values (sorted in descending order)\n",
        "      top_k_indices = np.argsort(actions)[::-1][:K]  # Get indices of top K largest values\n",
        "\n",
        "      # Step 2: Extract Top-K values using these indices\n",
        "      weights = actions[top_k_indices]\n",
        "      weights = np.maximum(weights, 0)  # Replace negative values with 0\n",
        "      # Step 3: Apply a mathematical operation (Softmax normalization)\n",
        "      sum_weights = np.sum(weights)\n",
        "\n",
        "      # Step 4: Apply a mathematical operation (Repair mechanism)\n",
        "      if sum_weights > 1:\n",
        "          # If sum of weights is greater than 1, reduce values proportionally\n",
        "          modified_values = []\n",
        "          for i in weights:\n",
        "              numerator = (i - 0.01)\n",
        "              denominator = np.sum(weights - l)  # Summation over j\n",
        "              repaired_value = 0.01 + (numerator / denominator) * (1 - len(weights) * 0.01)\n",
        "              modified_values.append(repaired_value)\n",
        "\n",
        "      elif sum_weights < 1:\n",
        "          # If sum of weights is less than 1, increase values proportionally\n",
        "          modified_values = []\n",
        "          for i in weights:\n",
        "              numerator = (1 - i)\n",
        "              denominator = np.sum(u - weights)  # Summation over j\n",
        "              repaired_value = 1 - (numerator / denominator) * (len(weights) * 1 - 1)\n",
        "              modified_values.append(repaired_value)\n",
        "\n",
        "      else:\n",
        "          # If sum of weights is exactly 1, no modification is needed\n",
        "          modified_values = weights\n",
        "\n",
        "      # Convert to NumPy array\n",
        "      modified_values = np.array(modified_values)\n",
        "      modified_values = np.clip(modified_values, 0.01, 1) # Bound on K assets\n",
        "      # Step 4: Create a new array and assign 0 to all positions\n",
        "      result_arr = np.full_like(actions, 0)  # Initialize everything with 0\n",
        "\n",
        "      # Step 5: Assign modified Softmax values to the Top-K indices\n",
        "      result_arr[top_k_indices] = modified_values  # Assign only to top K elements\n",
        "\n",
        "      # Step 6: Identify fixed values (0)\n",
        "      fixed_mask = (result_arr == 0.01)  # Boolean mask where values are exactly 0\n",
        "      fixed_sum = np.sum(result_arr[fixed_mask])  # Sum of fixed values\n",
        "\n",
        "      # Step 7: Compute current sum and required adjustment\n",
        "      total_sum = np.sum(result_arr)\n",
        "      adjustable_sum = total_sum - fixed_sum  # Sum of changeable values\n",
        "      target_sum = 1 - fixed_sum  # Required sum for adjustable values\n",
        "\n",
        "      # Step 8: Rescale only the non-fixed values\n",
        "      result_arr[~fixed_mask] *= (target_sum / adjustable_sum)  # Scale non-fixed values\n",
        "\n",
        "      return result_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzD06X0CbU43",
        "outputId": "c9b29718-eab3-4b6d-b764-345268f7965b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 30, State Space: 30\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "jyg0_ZuVEVQ5"
      },
      "outputs": [],
      "source": [
        "turbulence_threshold= 0.03\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"transaction_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"Rebalance\":False,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"turbulence_threshold\": turbulence_threshold,\n",
        "    \"hist_vol\": hist_vol_train\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "nUx4CqjJ8QOl"
      },
      "outputs": [],
      "source": [
        "trade_env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"transaction_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"Rebalance\":False,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"turbulence_threshold\": turbulence_threshold,\n",
        "    \"hist_vol\": hist_vol_trade\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "6kGYVSUSIwwS"
      },
      "outputs": [],
      "source": [
        "# # Uncomment you want results without Transection Cost\n",
        "# env_kwargs = {\n",
        "#     \"hmax\": 100,\n",
        "#     \"initial_amount\": 1000000,\n",
        "#     \"transaction_cost_pct\": 0,\n",
        "#     \"state_space\": state_space,\n",
        "#     \"stock_dim\": stock_dimension,\n",
        "#     \"tech_indicator_list\": INDICATORS,\n",
        "#     \"Rebalance\":False,\n",
        "#     \"action_space\": stock_dimension,\n",
        "#     \"reward_scaling\": 1e-4,\n",
        "# }\n",
        "\n",
        "# trade_env_kwargs = {\n",
        "#     \"hmax\": 100,\n",
        "#     \"initial_amount\": 1000000,\n",
        "#     \"transaction_cost_pct\": 0,\n",
        "#     \"state_space\": state_space,\n",
        "#     \"stock_dim\": stock_dimension,\n",
        "#     \"tech_indicator_list\": INDICATORS,\n",
        "#     \"Rebalance\":True,\n",
        "#     \"action_space\": stock_dimension,\n",
        "#     \"reward_scaling\": 1e-4,\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlLUzMG327FI",
        "outputId": "3c6cd78a-c07f-4589-95f8-01e37d1c0527"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "\n",
        "e_val_gym = StockPortfolioEnv(df = val, **trade_env_kwargs)\n",
        "env_val, _ = e_val_gym.get_sb_env()\n",
        "\n",
        "e_train_full_gym = StockPortfolioEnv(df = full_train, **env_kwargs)\n",
        "env_full_train, _ = e_train_full_gym.get_sb_env()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = trade, **trade_env_kwargs)\n",
        "env_trade, _ = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eKIu5UPlPnk"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* ## PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "fh2H3roIEzpS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from scipy.stats import multivariate_normal\n",
        "from torch.autograd import grad\n",
        "\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim, num_layers, act_fn, dr):\n",
        "        super(Actor, self).__init__()\n",
        "        self.action_dim = action_dim  # Store action dimension\n",
        "        layers = []\n",
        "\n",
        "        if act_fn == 'relu': activation_fn = nn.ReLU()\n",
        "        if act_fn == 'tanh': activation_fn = nn.Tanh()\n",
        "        if act_fn == 'sigmoid': activation_fn = nn.Sigmoid()\n",
        "\n",
        "        # Add input layer\n",
        "        layers.append(nn.Flatten())\n",
        "        layers.append(nn.Linear(state_dim, hidden_dim))\n",
        "        layers.append(activation_fn)\n",
        "        layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "        # Add hidden layers\n",
        "        for _ in range(num_layers - 2):  # -2 because we already added the input and output layers\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(activation_fn)\n",
        "            layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "        # Add output layer\n",
        "        layers.append(nn.Linear(hidden_dim, action_dim))\n",
        "\n",
        "        # Create the sequential model\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "        logstds_param = nn.Parameter(torch.full((action_dim,), -0.5))\n",
        "        self.register_parameter(\"logstds\", logstds_param)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.model(state)\n",
        "        means = torch.tanh(x)\n",
        "        stds = torch.clamp(self.logstds.exp(), 1e-3, 0.5)\n",
        "        # cov_mat = torch.diag_embed(stds)\n",
        "        cov_mat = torch.diag_embed(stds) + 1e-6 * torch.eye(self.action_dim) # Add this line\n",
        "        return torch.distributions.MultivariateNormal(means, cov_mat)\n",
        "\n",
        "    # def forward(self, state):\n",
        "    #   x = self.model(state)\n",
        "    #   means = torch.tanh(x)\n",
        "    #   if torch.isnan(means).any() or torch.isinf(means).any():\n",
        "    #     print(\"Warning: NaN detected in means! Clamping values.\")\n",
        "    #     means = torch.clamp(means, -1e3, 1e3)\n",
        "    #   stds = torch.clamp(self.logstds.exp(), 1e-3, 0.5)\n",
        "    #   # cov_mat = torch.diag_embed(stds)\n",
        "    #   cov_mat = torch.diag_embed(stds) + 1e-6 * torch.eye(self.action_dim) # Add this line\n",
        "    #   return torch.distributions.MultivariateNormal(means, cov_mat)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim, hidden_dim, num_layers, act_fn, dr):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        if act_fn == 'relu': activation_fn = nn.ReLU()\n",
        "        if act_fn == 'tanh': activation_fn = nn.Tanh()\n",
        "        if act_fn == 'sigmoid': activation_fn = nn.Sigmoid()\n",
        "\n",
        "        # Add input layer\n",
        "        layers.append(nn.Flatten())\n",
        "        layers.append(nn.Linear(state_dim, hidden_dim))\n",
        "        layers.append(activation_fn)\n",
        "        layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "        # Add hidden layers\n",
        "        for _ in range(num_layers - 2):  # -2 because we already added the input and output layers\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(activation_fn)\n",
        "            layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "        # Add output layer\n",
        "        layers.append(nn.Linear(hidden_dim, 1))\n",
        "\n",
        "        # Create the sequential model\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, state):\n",
        "        x = self.model(state)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class CostNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network for estimating portfolio risk (cost).\n",
        "    \"\"\"\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim,num_layers, act_fn, dr):\n",
        "        super(CostNetwork, self).__init__()\n",
        "\n",
        "        state_dim=int(state_dim)\n",
        "        action_dim=int(action_dim)\n",
        "        hidden_dim=int(hidden_dim)\n",
        "        # print(\"state_dim:\", state_dim)\n",
        "        # print(\"action_dim:\", action_dim)\n",
        "        # print(\"hidden_dim:\", hidden_dim)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(state_dim + action_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)  # Outputs cost estimate\n",
        "        )\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        \"\"\"\n",
        "        Forward pass for the cost network.\n",
        "\n",
        "        Computes:\n",
        "        c_wv(s, a) = E[VaR(s, a)]  (Eq. 19 in the paper)\n",
        "\n",
        "        Args:\n",
        "        - state (torch.Tensor): State tensor with shape [batch_size, *]\n",
        "        - action (torch.Tensor): Action tensor with shape [batch_size, action_dim]\n",
        "\n",
        "        Returns:\n",
        "        - Cost estimation (torch.Tensor)\n",
        "        \"\"\"\n",
        "\n",
        "        # print(\" cost network forward ((((((((((((((((((((((((((((((((((((((()))))))))))))))))))))))))))))))))))))))\")\n",
        "        # 🔍 Print debug info to check tensor shapes\n",
        "        # print(\"state :: \", type(state) , state.shape)\n",
        "        # print(\"action :: \", type(action) , action.shape)\n",
        "        # 🔄 Flatten state if it has more than 2 dimensions\n",
        "        if state.dim() > 2:\n",
        "            state = state.view(state.shape[0], -1)  # Reshape to [batch_size, flattened_features]\n",
        "\n",
        "        # 🔄 Ensure action is 2D\n",
        "        if action.dim() > 2:\n",
        "            action = action.view(action.shape[0], -1)  # Reshape to [batch_size, action_dim]\n",
        "\n",
        "        # 🔍 Print final shapes\n",
        "        # print(f\"State shape after reshape: {state.shape}, Action shape after reshape: {action.shape}\")\n",
        "\n",
        "        # ✅ Now both state and action are 2D → Safe to concatenate\n",
        "        x = torch.cat([state, action], dim=1)\n",
        "        # Forward pass through the Cost network\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "EDNLkFNLFDB8"
      },
      "outputs": [],
      "source": [
        "class PPOagent:\n",
        "  def __init__(self, env, params, eps_clip=0.2):\n",
        "    # Params\n",
        "    self.num_states = env.observation_space.shape[0]*env.observation_space.shape[1]\n",
        "    self.num_actions = env.action_space.shape[0]\n",
        "    self.gamma = params['gamma']\n",
        "    self.env = env\n",
        "    # self.PPO_epochs = int(params['PPO_epochs'])\n",
        "    self.PPO_epochs = 10\n",
        "    self.value_coeff = params['val_coeff']\n",
        "    self.ent_coeff = params['ent_coeff']\n",
        "    self.eps_clip = eps_clip\n",
        "\n",
        "    # constraint params--\n",
        "    self.rho = 0.01\n",
        "    self.violations= 0\n",
        "    self.zeta= env.envs[0].turbulence_threshold\n",
        "    self.lambda_ = torch.tensor(0.01, requires_grad=False).to(device)\n",
        "\n",
        "    # Networks\n",
        "    self.policy = Actor(self.num_states, self.num_actions, int(params['Ahidden_dim']), int(params['Anum_layers']), params['Aact_fn'], params['Adr']).to(device)\n",
        "    self.critic = Critic(self.num_states, int(params['Chidden_dim']), int(params['Cnum_layers']), params['Cact_fn'], params['Cdr']).to(device)\n",
        "    self.cost_network = CostNetwork(self.num_states, self.num_actions, params['Costhidden_dim'], int (params['Costnum_layers']),params['Costact_fn'], params['Cdr']  ).to(device)\n",
        "    self.cost_target = CostNetwork(self.num_states, self.num_actions, int(params['Costhidden_dim']), int (params['Costnum_layers']),params['Costact_fn'], params['Costdr']).to(device)\n",
        "\n",
        "    # Training\n",
        "    self.optimizer = torch.optim.Adam([\n",
        "                        {'params': self.policy.parameters(), 'lr': params['alr']},\n",
        "                        {'params': self.critic.parameters(), 'lr': params['clr']},\n",
        "                        {'params': self.cost.parameters(), 'lr': params['costlr']}])\n",
        "\n",
        "    self.MseLoss = nn.MSELoss().to(device)\n",
        "\n",
        "\n",
        "  def get_action(self, state):\n",
        "    # state_tensor = torch.FloatTensor(state).to(device)\n",
        "    norm_dists = self.policy(state)\n",
        "    action = torch.tanh(norm_dists.sample())\n",
        "    logs_probs = norm_dists.log_prob(action)\n",
        "    entropy = norm_dists.entropy()\n",
        "    return action, logs_probs, entropy\n",
        "\n",
        "\n",
        "  def calculate_returns(self, rewards, discount_factor):\n",
        "    returns = []\n",
        "    R = 0\n",
        "    for r in reversed(rewards):\n",
        "        R = r + R * discount_factor\n",
        "        returns.insert(0, R)\n",
        "\n",
        "    return torch.tensor(returns)\n",
        "\n",
        "  def VaR(self, states, actions, confidence_level=0.95):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        actions = actions.to(device)\n",
        "        states = states.to(device)  # assume actions is already on the correct device\n",
        "\n",
        "        batch_size = states.shape[0]  # ✅ Do NOT use `.to(device)` here\n",
        "        num_assets = 30\n",
        "\n",
        "        states = states.squeeze(1).to(device)  # [batch_size, 38, 30]\n",
        "        states_n = states  # already squeezed\n",
        "\n",
        "        cov_matrix = states[:, :num_assets, :].to(device)  # [batch_size, 30, 30]\n",
        "        hist_volatility = states_n[:, -1, :].to(device)  # [batch_size, 30]\n",
        "\n",
        "        z_score = torch.tensor(1.645, device=device)  # ✅ place tensor on the same device\n",
        "        individual_VaR = z_score * hist_volatility  # [batch_size, 30]\n",
        "\n",
        "        VaR_portfolio = torch.zeros(batch_size, device=device)  # ✅ directly initialize on device\n",
        "\n",
        "        for i in range(num_assets):\n",
        "            for j in range(num_assets):\n",
        "                VaR_portfolio = VaR_portfolio + (\n",
        "                    actions[:, i] * individual_VaR[:, i] *\n",
        "                    actions[:, j] * individual_VaR[:, j] * cov_matrix[:, i, j]\n",
        "                )\n",
        "\n",
        "        return VaR_portfolio\n",
        "\n",
        "\n",
        "  def compute_cost_target(self, states, actions, next_states, dones):\n",
        "        \"\"\"\n",
        "        Compute the target cost using the Bellman equation.\n",
        "\n",
        "        Equation (20):\n",
        "        c_{w_v}(s, a) = VaR(s, a) + \\eta (1 - d) c'_{w_v'}(s', a')\n",
        "        \"\"\"\n",
        "        next_actions = self.actor_target.forward(next_states)  # π'(s')\n",
        "        next_cost = self.cost_target.forward(next_states, next_actions.detach())  # c'_wv'(s', a')\n",
        "        cost_target = self.VaR(next_states, next_actions) + self.gamma * (1 - dones) * next_cost\n",
        "        return cost_target\n",
        "\n",
        "\n",
        "  def update_policy(self, states, actions, log_prob_actions, advantages, returns):\n",
        "    old_states = states.detach().to(device)\n",
        "    old_actions = actions.detach().to(device)\n",
        "    old_log_probs = log_prob_actions.detach().to(device)\n",
        "    advantages = advantages.detach().to(device)\n",
        "    returns = returns.detach().to(device)\n",
        "    cost_target = self.compute_cost_target(states, actions, next_states, dones).detach()\n",
        "\n",
        "\n",
        "    # violations --\n",
        "    violations_count = (cost_target > self.zeta).sum().item()  # Count how many elements violate the constraint\n",
        "    # print(\" violations ::: \" , violations_count)\n",
        "    # Update the number of violations\n",
        "    self.violations  =  self.violations + violations_count\n",
        "\n",
        "    # C= c(si, ai) − ζ, if c(si, ai) >=  ζ else 0\n",
        "    constraint_penalty = torch.where(\n",
        "        constraint_penalty <= self.zeta,\n",
        "        torch.tensor(0.0, device=constraint_penalty.device, dtype=constraint_penalty.dtype),\n",
        "        constraint_penalty - self.zeta\n",
        "    )\n",
        "    quadratic_penalty = (self.rho / 2) * (constaint_penalty ** 2).mean().clone()\n",
        "    constraint_penalty =(self.lambda_) * constraint_penalty.mean().clone()\n",
        "    final_loss= constraint_penalty + quadratic_penalty\n",
        "\n",
        "\n",
        "    for _ in range(self.PPO_epochs):\n",
        "      #get new log prob of old actions for all input states\n",
        "      action, log_probs_new, entropy = self.get_action(old_states)\n",
        "      value_pred = self.critic(old_states)\n",
        "\n",
        "      policy_ratio = (log_probs_new - old_log_probs).exp()\n",
        "      policy_loss_1 = policy_ratio * advantages\n",
        "      policy_loss_2 = torch.clamp(policy_ratio, min=1.0 - self.eps_clip, max=1.0 + self.eps_clip) * advantages\n",
        "\n",
        "      policy_loss = - torch.min(policy_loss_1, policy_loss_2).mean()\n",
        "\n",
        "      value_loss = self.MseLoss(self.critic(old_states), returns)\n",
        "\n",
        "      loss = policy_loss + self.value_coeff * value_loss - self.ent_coeff * entropy.mean()\n",
        "      loss= -1*loss + final\n",
        "\n",
        "      # take gradient step\n",
        "      self.optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "\n",
        "  def trade(self, val_env, e_val_gym, n_steps):\n",
        "    Reward = []\n",
        "    state = val_env.reset()\n",
        "    if n_steps == None:\n",
        "      n_steps = len(e_val_gym.df.index.unique())\n",
        "    for i in range(n_steps):\n",
        "      state_tensor = torch.FloatTensor(state).to(device)\n",
        "      action, logs_probs, _ = self.get_action(state_tensor)\n",
        "      action = action.cpu()\n",
        "      next_obs, reward, done, _ = val_env.step(action.detach().numpy())\n",
        "      Reward.append(reward)\n",
        "\n",
        "      if i == (n_steps - 2):\n",
        "          account_memory = val_env.env_method(method_name=\"save_asset_memory\")\n",
        "          actions_memory = val_env.env_method(method_name=\"save_action_memory\")\n",
        "\n",
        "      if done[0]:\n",
        "        print(\"hit end!\")\n",
        "        # account_memory = val_env.env_method(method_name=\"save_asset_memory\")\n",
        "        # actions_memory = val_env.env_method(method_name=\"save_action_memory\")\n",
        "        break\n",
        "      state = next_obs\n",
        "\n",
        "    # account_memory = val_env.env_method(method_name=\"save_asset_memory\")\n",
        "    # actions_memory = val_env.env_method(method_name=\"save_action_memory\")\n",
        "    return account_memory, actions_memory, sum(Reward)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBb4d7wvSShZ"
      },
      "source": [
        "* TRPO Agent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HzwmQixHSQQU"
      },
      "outputs": [],
      "source": [
        "# from torch.autograd import grad\n",
        "# # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# class TRPOagent:\n",
        "#     def __init__(self, env, params, max_kl=0.01, damping=0.1):\n",
        "#         self.num_states = env.observation_space.shape[0] * env.observation_space.shape[1]\n",
        "#         self.num_actions = env.action_space.shape[0]\n",
        "#         self.gamma = params['gamma']\n",
        "#         self.env = env\n",
        "#         self.value_coeff = params['val_coeff']\n",
        "#         self.ent_coeff = params['ent_coeff']\n",
        "#         self.max_kl = max_kl\n",
        "#         self.damping = damping\n",
        "\n",
        "#         # Networks\n",
        "#         self.policy = Actor(self.num_states, self.num_actions, int(params['Ahidden_dim']),\n",
        "#                             int(params['Anum_layers']), params['Aact_fn'], params['Adr']).to(device)\n",
        "#         self.critic = Critic(self.num_states, int(params['Chidden_dim']),\n",
        "#                              int(params['Cnum_layers']), params['Cact_fn'], params['Cdr']).to(device)\n",
        "\n",
        "#         self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=params['clr'])\n",
        "#         self.MseLoss = nn.MSELoss().to(device)\n",
        "\n",
        "#     def get_action(self, state):\n",
        "#       if torch.isnan(state).any() or torch.isinf(state).any():\n",
        "#           print(\"Warning: NaN or Inf detected in state! Replacing with zeros.\")\n",
        "#           state = torch.where(torch.isnan(state) | torch.isinf(state), torch.zeros_like(state), state)\n",
        "\n",
        "#       norm_dists = self.policy(state)\n",
        "#       action = torch.tanh(norm_dists.sample())\n",
        "#       log_probs = norm_dists.log_prob(action)\n",
        "#       entropy = norm_dists.entropy()\n",
        "#       return action, log_probs, entropy\n",
        "\n",
        "\n",
        "\n",
        "#     def calculate_returns(self, rewards, discount_factor):\n",
        "#         returns = []\n",
        "#         R = 0\n",
        "#         for r in reversed(rewards):\n",
        "#             R = r + R * discount_factor\n",
        "#             returns.insert(0, R)\n",
        "#         return torch.tensor(returns).to(device)\n",
        "\n",
        "#     def conjugate_gradient(self, Avp_func, b, n_steps=10, residual_tol=1e-10):\n",
        "#         x = torch.zeros_like(b).to(device)\n",
        "#         r = b.clone()\n",
        "#         p = b.clone()\n",
        "#         rdotr = torch.dot(r, r)\n",
        "\n",
        "#         for _ in range(n_steps):\n",
        "#             Avp = Avp_func(p)\n",
        "#             alpha = rdotr / torch.dot(p, Avp)\n",
        "#             x += alpha * p\n",
        "#             r -= alpha * Avp\n",
        "#             new_rdotr = torch.dot(r, r)\n",
        "#             beta = new_rdotr / rdotr\n",
        "#             p = r + beta * p\n",
        "#             rdotr = new_rdotr\n",
        "#             if rdotr < residual_tol:\n",
        "#                 break\n",
        "#         return x\n",
        "\n",
        "#     def compute_fisher_vector_product(self, states, p):\n",
        "#         def hvp(v):\n",
        "#             kl = self.kl_divergence(states).mean()\n",
        "#             grads = grad(kl, self.policy.parameters(), create_graph=True)\n",
        "#             flat_grad_kl = torch.cat([g.view(-1) for g in grads])\n",
        "#             grad_kl_v = torch.dot(flat_grad_kl, v)\n",
        "#             grads = grad(grad_kl_v, self.policy.parameters())\n",
        "#             flat_grad_kl_v = torch.cat([g.contiguous().view(-1) for g in grads]).data\n",
        "#             return flat_grad_kl_v + self.damping * v\n",
        "#         return hvp(p)\n",
        "\n",
        "#     def kl_divergence(self, states):\n",
        "#       old_policy = self.policy(states)\n",
        "#       old_mean = old_policy.mean.detach()\n",
        "#       old_cov = old_policy.covariance_matrix.detach()\n",
        "#       old_policy = torch.distributions.MultivariateNormal(old_mean, old_cov)\n",
        "\n",
        "#       new_policy = self.policy(states)\n",
        "#       return torch.distributions.kl.kl_divergence(old_policy, new_policy)\n",
        "\n",
        "\n",
        "#     def update_policy(self, states, actions, log_prob_actions, advantages, returns):\n",
        "#         old_log_probs = log_prob_actions.detach().to(device)\n",
        "#         advantages = advantages.detach().to(device)\n",
        "#         states = states.detach().to(device)\n",
        "#         actions = actions.detach().to(device)\n",
        "#         returns = returns.detach().to(device)\n",
        "\n",
        "#         def surrogate_loss():\n",
        "#             new_log_probs = self.policy(states).log_prob(actions).sum(dim=-1)\n",
        "#             ratio = torch.exp(new_log_probs - old_log_probs)\n",
        "#             return -(ratio * advantages).mean()\n",
        "\n",
        "#         loss = surrogate_loss()\n",
        "#         grads = grad(loss, self.policy.parameters(), create_graph=True)\n",
        "#         flat_grads = torch.cat([g.view(-1) for g in grads]).detach()\n",
        "\n",
        "#         search_direction = self.conjugate_gradient(\n",
        "#             lambda p: self.compute_fisher_vector_product(states, p), flat_grads)\n",
        "\n",
        "#         step_size = torch.sqrt(2 * self.max_kl / (torch.dot(search_direction,\n",
        "#                         self.compute_fisher_vector_product(states, search_direction)) + 1e-8))\n",
        "\n",
        "#         new_params = []\n",
        "#         for param, direction in zip(self.policy.parameters(), search_direction):\n",
        "#             new_params.append(param + step_size * direction)\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for param, new_param in zip(self.policy.parameters(), new_params):\n",
        "#                 param.copy_(new_param)\n",
        "\n",
        "#         value_loss = self.MseLoss(self.critic(states), returns)\n",
        "#         self.critic_optimizer.zero_grad()\n",
        "#         value_loss.backward()\n",
        "#         self.critic_optimizer.step()\n",
        "\n",
        "#     def trade(self, val_env, e_val_gym, n_steps):\n",
        "#         Reward = []\n",
        "#         state = val_env.reset()\n",
        "#         if n_steps is None:\n",
        "#             n_steps = len(e_val_gym.df.index.unique())\n",
        "#         for i in range(n_steps):\n",
        "#             state_tensor = torch.FloatTensor(state).to(device)\n",
        "#             action, log_probs, _ = self.get_action(state_tensor)\n",
        "#             action = action.cpu()\n",
        "#             next_obs, reward, done, _ = val_env.step(action.detach().numpy())\n",
        "#             Reward.append(reward)\n",
        "\n",
        "#             if i == (n_steps - 2):\n",
        "#                 account_memory = val_env.env_method(method_name=\"save_asset_memory\")\n",
        "#                 actions_memory = val_env.env_method(method_name=\"save_action_memory\")\n",
        "\n",
        "#             if done[0]:\n",
        "#                 print(\"hit end!\")\n",
        "#                 break\n",
        "#             state = next_obs\n",
        "\n",
        "#         return account_memory, actions_memory, sum(Reward)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "WCPMF7ZZL0rQ"
      },
      "outputs": [],
      "source": [
        "#device = 'cpu'\n",
        "# Set the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "1M5fFJNoLRqA"
      },
      "outputs": [],
      "source": [
        "#Calculate the Sharpe ratio\n",
        "#This is our objective for tuning\n",
        "def calculate_sharpe(df):\n",
        "  #df['daily_return'] = df['account_value'].pct_change(1)\n",
        "  if df['daily_return'].std() !=0:\n",
        "    sharpe = (252**0.5)*df['daily_return'].mean()/ \\\n",
        "          df['daily_return'].std()\n",
        "    return sharpe\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "WyEBcE0PL-jJ"
      },
      "outputs": [],
      "source": [
        "space = {\n",
        "    'Ahidden_dim': hp.quniform('Ahidden_dim', 2, 256,1),\n",
        "    'Anum_layers': hp.quniform('Anum_layers', 1, 8,1),\n",
        "    'Chidden_dim': hp.quniform('Chidden_dim', 2, 256, 1),\n",
        "    'Cnum_layers': hp.quniform('Cnum_layers', 1, 8,1),\n",
        "    'Costhidden_dim': hp.quniform('Costhidden_dim', 2, 256, 1),\n",
        "    'Costnum_layers': hp.quniform('Costnum_layers', 1, 8,1),\n",
        "    'alr': hp.loguniform('alr', -8, -1),\n",
        "    'clr': hp.loguniform('clr', -8, -1),\n",
        "    'costlr': hp.loguniform('costlr', -8, -1),\n",
        "\n",
        "    'gamma': hp.uniform('gamma', 0.9, 0.99),\n",
        "    'PPO_epochs': hp.quniform('PPO_epochs', 5, 50, 5),\n",
        "    'val_coeff': hp.uniform('val_coeff', 0.5, 1.0),\n",
        "    'ent_coeff': hp.uniform('ent_coeff', 0.01, 0.1),\n",
        "    'Aact_fn': hp.choice('Aact_fn', ['relu', 'tanh', 'sigmoid']),\n",
        "    'Adr': hp.uniform('Adr', 0, 0.5),\n",
        "    'Cact_fn': hp.choice('Cact_fn', ['relu', 'tanh', 'sigmoid']),\n",
        "    'Cdr': hp.uniform('Cdr', 0, 0.5),\n",
        "    'Costdr': hp.uniform('Costdr', 0, 0.5),\n",
        "    'Costact_fn': hp.choice('Costact_fn', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "}\n",
        "\n",
        "def objective(params):\n",
        "    print(params)\n",
        "    model = PPOagent(env_train, params)\n",
        "    num_steps = 512\n",
        "    Actions = []\n",
        "    States = []\n",
        "    Rewards = []\n",
        "    Log_probs = []\n",
        "    Values = []\n",
        "\n",
        "    state = env_train.reset()\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "\n",
        "    for i in range(num_steps):\n",
        "      state_tensor = torch.FloatTensor(state).to(device)\n",
        "      state_value = model.critic(state_tensor).to(device)\n",
        "      States.append(state_tensor)\n",
        "      Values.append(state_value)\n",
        "\n",
        "      action, logs_probs, entropy = model.get_action(state_tensor)\n",
        "      action = action.cpu()\n",
        "      next_state, reward, done, _ = env_train.step(action.detach().numpy())\n",
        "\n",
        "      Actions.append(action)\n",
        "      Rewards.append(reward)\n",
        "      Log_probs.append(logs_probs)\n",
        "      state = next_state\n",
        "\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    actions = torch.cat(Actions).to(device)\n",
        "    states = torch.cat(States).to(device)\n",
        "    values = torch.cat(Values).to(device)\n",
        "    log_prob_old = torch.cat(Log_probs).to(device)\n",
        "    returns = (model.calculate_returns(Rewards, model.gamma)).to(device)\n",
        "    advantages = (returns - values).to(device)\n",
        "    advantages = ((advantages - advantages.mean()) / (advantages.std() + 1e-5)).to(device)\n",
        "\n",
        "    model.update_policy(states, actions, log_prob_old, advantages, returns)\n",
        "\n",
        "    account_memory, actions_memory, rewardd = model.trade(env_val, e_val_gym, None)\n",
        "    print(rewardd)\n",
        "\n",
        "    sharpe = calculate_sharpe(account_memory[0])\n",
        "    return -sharpe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WCTq53n1MP3m",
        "outputId": "4b4fee40-ff0c-4a20-a69a-276502d7ccd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Aact_fn': 'sigmoid', 'Adr': 0.42732391637866113, 'Ahidden_dim': 60.0, 'Anum_layers': 3.0, 'Cact_fn': 'relu', 'Cdr': 0.23081728566804455, 'Chidden_dim': 63.0, 'Cnum_layers': 3.0, 'Costact_fn': 'tanh', 'Costdr': 0.35217882850956067, 'Costhidden_dim': 31.0, 'Costnum_layers': 3.0, 'PPO_epochs': 30.0, 'alr': 0.03482610939034329, 'clr': 0.030731352858176353, 'costlr': 0.000854175665945104, 'ent_coeff': 0.09146841249318294, 'gamma': 0.9867165795639116, 'val_coeff': 0.77134824668578}\n",
            "  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:hyperopt.fmin:job exception: 'PPOagent' object has no attribute 'cost'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0%|          | 0/2 [00:00<?, ?trial/s, best loss=?]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'PPOagent' object has no attribute 'cost'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-d15944a687a9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#max_evals = 500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    541\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    672\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             )\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-32b5643b4613>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPPOagent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mnum_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mActions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-9464da0c28b0>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, env, params, eps_clip)\u001b[0m\n\u001b[1;32m     28\u001b[0m                         \u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                         \u001b[0;34m{\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'clr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                         {'params': self.cost.parameters(), 'lr': params['costlr']}])\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMseLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PPOagent' object has no attribute 'cost'"
          ]
        }
      ],
      "source": [
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=2, trials=Trials())  #max_evals = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4I7TxxrmMT3g"
      },
      "outputs": [],
      "source": [
        "best['Aact_fn'] = ['relu', 'tanh', 'sigmoid'][best['Aact_fn']]\n",
        "best['Cact_fn'] = ['relu', 'tanh', 'sigmoid'][best['Cact_fn']]\n",
        "best = {k: v.item() if isinstance(v, (np.floating, np.integer)) else v for k, v in best.items()}\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUUYrYTDBoru"
      },
      "outputs": [],
      "source": [
        "# best = {'Aact_fn': 'tanh',\n",
        "#  'Adr': 0.09469604167663657,\n",
        "#  'Ahidden_dim': 134.0,\n",
        "#  'Anum_layers': 6.0,\n",
        "#  'Cact_fn': 'sigmoid',\n",
        "#  'Cdr': 0.07090572811851073,\n",
        "#  'Chidden_dim': 94.0,\n",
        "#  'Cnum_layers': 4.0,\n",
        "#  'PPO_epochs': 5.0,\n",
        "#  'alr': 0.04309959558707145,\n",
        "#  'clr': 0.0031332098700080904,\n",
        "#  'ent_coeff': 0.0281538173792947,\n",
        "#  'gamma': 0.9815938027079978,\n",
        "#  'val_coeff': 0.9431334795629683}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkg_HQ46MYt1"
      },
      "outputs": [],
      "source": [
        "agent = PPOagent(env_full_train, best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3xkcGuPF4cU"
      },
      "outputs": [],
      "source": [
        "env = env_full_train\n",
        "Episode_rewards = []\n",
        "Avg_rewards = []\n",
        "num_episodes = 10\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  Actions = []\n",
        "  States = []\n",
        "  Rewards = []\n",
        "  Log_probs = []\n",
        "  Values = []\n",
        "\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  episode_reward = 0\n",
        "\n",
        "  while not done:\n",
        "    state_tensor = torch.FloatTensor(state).to(device)\n",
        "    state_value = agent.critic(state_tensor).to(device)\n",
        "    States.append(state_tensor)\n",
        "    Values.append(state_value)\n",
        "\n",
        "    action, logs_probs, entropy = agent.get_action(state_tensor)\n",
        "    action = action.cpu()\n",
        "    next_state, reward, done, _ = env.step(action.detach().numpy())\n",
        "\n",
        "    Actions.append(action)\n",
        "    Rewards.append(reward)\n",
        "    Log_probs.append(logs_probs)\n",
        "\n",
        "    state = next_state\n",
        "    episode_reward += reward\n",
        "\n",
        "  actions = torch.cat(Actions).to(device)\n",
        "  states = torch.cat(States).to(device)\n",
        "  values = torch.cat(Values).to(device)   #.squeeze(-1)\n",
        "  log_prob_old = torch.cat(Log_probs).to(device)\n",
        "  returns = (agent.calculate_returns(Rewards, agent.gamma)).to(device)\n",
        "  advantages = (returns - values).to(device)\n",
        "  advantages = ((advantages - advantages.mean()) / (advantages.std() + 1e-5)).to(device)\n",
        "\n",
        "  agent.update_policy(states, actions, log_prob_old, advantages, returns)\n",
        "\n",
        "  ## update lambda and rho --\n",
        "  agent.lambda_ = agent.lambda_ + agent.rho * agent.cost_network.forward(\n",
        "        state_tensor,\n",
        "        action_tensor\n",
        "    ).mean().detach().to(device)\n",
        "\n",
        "  agent.rho= agent.rho * 1.008\n",
        "\n",
        "  Episode_rewards.append(episode_reward)\n",
        "  Avg_rewards.append(np.mean(Episode_rewards[-10:]))\n",
        "\n",
        "  print(f\"Episode: {episode+1}, Episode Reward: {episode_reward}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O4Leqa8Mho_"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.plot(Episode_rewards)\n",
        "plt.plot(Avg_rewards)\n",
        "plt.plot()\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Ma6YpTlnuZ"
      },
      "source": [
        "## Trading\n",
        "Assume that we have $1,000,000 initial capital at 2019-01-01. We use the A2C model to trade Dow jones 30 stocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Utx9sg-Kv54"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockPortfolioEnv(df = trade, **trade_env_kwargs)\n",
        "test_env, test_obs = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqfAFtscOEE-"
      },
      "outputs": [],
      "source": [
        "account_memory, actions_memory, rewardd = agent.trade(env_trade, e_trade_gym, None)\n",
        "print(rewardd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp8FWh4q68LF"
      },
      "outputs": [],
      "source": [
        "calculate_sharpe(account_memory[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY_7t6B_68i9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "account_memory[0].to_csv('df_daily_return_'+ Market +'_' + Reward +'.csv')\n",
        "files.download('df_daily_return_'+ Market +'_' + Reward +'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tByVcZ2L9TAJ"
      },
      "outputs": [],
      "source": [
        "actions_memory[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVJaqIaF13Hw"
      },
      "outputs": [],
      "source": [
        "actions_memory[0].to_csv('df_actions_Trade_'+ Market +'_' + Reward +'.csv')\n",
        "files.download('df_actions_Trade_'+ Market +'_' + Reward +'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoudukHdK3U-"
      },
      "outputs": [],
      "source": [
        "df_daily_return = account_memory[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt7FlUQHKoMO"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n",
        "test_env, test_obs = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGzGF-WZKsqJ"
      },
      "outputs": [],
      "source": [
        "account_memory, actions_memory, rewardd = agent.trade(env_trade, e_trade_gym, None)\n",
        "print(rewardd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nuYo2gdsdAV"
      },
      "outputs": [],
      "source": [
        "df_daily_return_T = account_memory[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC1-n8gSm2yr"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "df_daily_return_T.to_csv('df_daily_return_WT '+ Market +'_' + Reward +'.csv')\n",
        "files.download('df_daily_return_WT '+ Market +'_' + Reward +'.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFO42LcomPUT"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAvxipWFmUe8"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n",
        "# Nifty 50 -- ^NSEI\n",
        "# Sensex 30 -- ^BSESN\n",
        "# Dow 30 -- ^DJI\n",
        "# DAX 40 -- ^GDAXI\n",
        "# HSI 30 -- ^HSI\n",
        "# TIRKEY -- XU100.IS\n",
        "# Nikeei -- ^N225\n",
        "# IBEX Spain -- ^IBEX\n",
        "# Tiwan -- ^TWII\n",
        "# Nifty 100 -- ^CNX100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFuernJxLURD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oGu3PCa8l6L"
      },
      "outputs": [],
      "source": [
        "from pyfolio import timeseries\n",
        "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return_T)\n",
        "perf_func = perf_stats\n",
        "perf_stats_all = perf_func( returns=DRL_strat,\n",
        "                              factor_returns=DRL_strat,\n",
        "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqvwr6SY8l9A"
      },
      "outputs": [],
      "source": [
        "print(\"==============DRL Strategy Stats===========\")\n",
        "print(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcWzfa6UloDM"
      },
      "outputs": [],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline(\n",
        "        ticker= BL,\n",
        "        start = df_daily_return.loc[0,'date'],\n",
        "        end = df_daily_return.loc[len(df_daily_return)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVVCMVSAmcrI"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMDyd89wCQuE"
      },
      "outputs": [],
      "source": [
        "pip install empyrical==0.3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fqSEF5PfjjT"
      },
      "outputs": [],
      "source": [
        "import pyfolio\n",
        "%matplotlib inline\n",
        "\n",
        "baseline_df = get_baseline(\n",
        "        ticker=BL, start=df_daily_return.loc[0,'date'], end='2025-02-28')\n",
        "\n",
        "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "# with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
        "#         pyfolio.create_full_tear_sheet(returns = DRL_strat,\n",
        "#                                        benchmark_rets=baseline_returns, set_context=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F5HyduNW3Mr"
      },
      "outputs": [],
      "source": [
        "DRL_strat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOtZbwZbXB8B"
      },
      "outputs": [],
      "source": [
        "baseline_returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zg0EjrXyCT0"
      },
      "outputs": [],
      "source": [
        "baseline_returns.to_csv('Baseline_Daily_Return_'+ Market +'.csv')\n",
        "files.download('Baseline_Daily_Return_'+ Market +'.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3Ibcj5hUbz"
      },
      "source": [
        "## Min-Variance Portfolio Allocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VE2eUEuhMKs"
      },
      "outputs": [],
      "source": [
        "%pip install PyPortfolioOpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0NiefM7hHn0"
      },
      "outputs": [],
      "source": [
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDYDIBH9hcUP"
      },
      "outputs": [],
      "source": [
        "unique_tic = trade.tic.unique()\n",
        "unique_trade_date = trade.date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EICNukJZgnWl"
      },
      "outputs": [],
      "source": [
        "#calculate_portfolio_minimum_variance\n",
        "portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
        "initial_capital = 1000000\n",
        "portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
        "\n",
        "for i in range(len( unique_trade_date)-1):\n",
        "    df_temp = df[df.date==unique_trade_date[i]].reset_index(drop=True)\n",
        "    df_temp_next = df[df.date==unique_trade_date[i+1]].reset_index(drop=True)\n",
        "    #Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
        "    #calculate covariance matrix\n",
        "    Sigma = df_temp.return_list[0].cov()\n",
        "    #portfolio allocation\n",
        "    ef_min_var = EfficientFrontier(None, Sigma,weight_bounds=(0, 0.1))\n",
        "    #minimum variance\n",
        "    raw_weights_min_var = ef_min_var.min_volatility()\n",
        "    #get weights\n",
        "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
        "\n",
        "    #current capital\n",
        "    cap = portfolio.iloc[0, i]\n",
        "    #current cash invested for each stock\n",
        "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
        "    # current held shares\n",
        "    current_shares = list(np.array(current_cash)\n",
        "                                      / np.array(df_temp.close))\n",
        "    # next time period price\n",
        "    next_price = np.array(df_temp_next.close)\n",
        "    ##next_price * current share to calculate next total account value\n",
        "    portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
        "\n",
        "portfolio=portfolio.T\n",
        "portfolio.columns = ['account_value']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_gu9_edV724"
      },
      "source": [
        "# Markowitz's with Transection Cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EeCJGvoVQp6"
      },
      "outputs": [],
      "source": [
        "#calculate_portfolio_minimum_variance\n",
        "portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
        "initial_capital = 1000000\n",
        "portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
        "\n",
        "# Define transaction cost rate\n",
        "transaction_cost_rate = 0.005\n",
        "\n",
        "for i in range(len( unique_trade_date)-1):\n",
        "    df_temp = df[df.date==unique_trade_date[i]].reset_index(drop=True)\n",
        "    df_temp_next = df[df.date==unique_trade_date[i+1]].reset_index(drop=True)\n",
        "    #Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
        "    #calculate covariance matrix\n",
        "    Sigma = df_temp.return_list[0].cov()\n",
        "    #portfolio allocation\n",
        "    ef_min_var = EfficientFrontier(None, Sigma,weight_bounds=(0, 0.1))\n",
        "    #minimum variance\n",
        "    raw_weights_min_var = ef_min_var.min_volatility()\n",
        "    #get weights\n",
        "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
        "\n",
        "    #current capital\n",
        "    cap = portfolio.iloc[0, i]\n",
        "    #current cash invested for each stock\n",
        "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
        "    # current held shares\n",
        "    current_shares = list(np.array(current_cash)\n",
        "                                      / np.array(df_temp.close))\n",
        "    # next time period price\n",
        "    next_price = np.array(df_temp_next.close)\n",
        "\n",
        "    # Calculate next portfolio value without transaction cost\n",
        "    next_value = np.dot(current_shares, next_price)\n",
        "\n",
        "    # Calculate transaction costs\n",
        "    new_shares = current_cash / next_price\n",
        "    share_differences = np.abs(new_shares - current_shares)\n",
        "    transaction_cost = np.sum(share_differences * next_price * transaction_cost_rate)\n",
        "\n",
        "    # Deduct transaction cost from portfolio value\n",
        "    portfolio.iloc[0, i + 1] = next_value - transaction_cost\n",
        "\n",
        "portfolio=portfolio.T\n",
        "portfolio.columns = ['account_value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNk7BbVnyb1h"
      },
      "outputs": [],
      "source": [
        "def calculate_daily_return(current_value, previous_value):\n",
        "    return (current_value - previous_value) / previous_value\n",
        "\n",
        "# Calculate daily return and add it as a new column\n",
        "daily_returns = [0]  # Daily return for the first day is assumed to be 0\n",
        "for i in range(1, len(portfolio)):\n",
        "    current_value = portfolio['account_value'][i]\n",
        "    previous_value = portfolio['account_value'][i - 1]\n",
        "    daily_returns.append(calculate_daily_return(current_value, previous_value))\n",
        "\n",
        "portfolio['daily_return'] = daily_returns\n",
        "\n",
        "print(portfolio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2zmv1ISkpXu"
      },
      "outputs": [],
      "source": [
        "portfolio.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RmNa7m_f590"
      },
      "outputs": [],
      "source": [
        "Agent =(df_daily_return_T.daily_return+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y821cLKkhCn6"
      },
      "outputs": [],
      "source": [
        "min_var_cumpod =(portfolio.account_value.pct_change()+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-nS5eTu4G_C"
      },
      "outputs": [],
      "source": [
        "portfolio.drop(columns=['account_value'], inplace=True)\n",
        "portfolio.to_csv('Markowitz_Portfolio_Return_'+ Market +'.csv')\n",
        "files.download('Markowitz_Portfolio_Return_'+ Market +'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E1X9FFGgqeZ"
      },
      "outputs": [],
      "source": [
        "Baseline =(baseline_returns+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih6Jim-blNKY"
      },
      "source": [
        "## Plotly: DRL, Min-Variance, DJIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CISw6s8rbnpZ"
      },
      "outputs": [],
      "source": [
        "%pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJRH-FX3hTRZ"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpfgJcG5PInj"
      },
      "outputs": [],
      "source": [
        "time_ind = pd.Series(df_daily_return_T.date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM-NJKa8g7Jp"
      },
      "outputs": [],
      "source": [
        "trace0_portfolio = go.Scatter(x = time_ind, y = Agent, mode = 'lines', name = 'Agent (Portfolio Allocation)')\n",
        "\n",
        "trace1_portfolio = go.Scatter(x = time_ind, y = Baseline, mode = 'lines', name = 'Baseline')\n",
        "trace2_portfolio = go.Scatter(x = time_ind, y = min_var_cumpod, mode = 'lines', name = 'Min-Variance')\n",
        "#trace3_portfolio = go.Scatter(x = time_ind, y = a2c_cumpod_esg, mode = 'lines', name = 'ESG-A2C (Portfolio Allocation)')\n",
        "#trace3_portfolio = go.Scatter(x = time_ind, y = ddpg_cumpod, mode = 'lines', name = 'DDPG')\n",
        "#trace4_portfolio = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
        "#trace5_portfolio = go.Scatter(x = time_ind, y = min_cumpod, mode = 'lines', name = 'Min-Variance')\n",
        "\n",
        "#trace4 = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
        "\n",
        "#trace2 = go.Scatter(x = time_ind, y = portfolio_cost_minv, mode = 'lines', name = 'Min-Variance')\n",
        "#trace3 = go.Scatter(x = time_ind, y = spx_value, mode = 'lines', name = 'SPX')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35nVVmEuhGa1"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(trace0_portfolio)\n",
        "\n",
        "fig.add_trace(trace1_portfolio)\n",
        "\n",
        "fig.add_trace(trace2_portfolio)\n",
        "\n",
        "#fig.add_trace(trace3_portfolio)\n",
        "\n",
        "fig.update_layout(\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1,\n",
        "        traceorder=\"normal\",\n",
        "        font=dict(\n",
        "            family=\"sans-serif\",\n",
        "            size=15,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        bgcolor=\"White\",\n",
        "        bordercolor=\"white\",\n",
        "        borderwidth=2\n",
        "\n",
        "    ),\n",
        ")\n",
        "#fig.update_layout(legend_orientation=\"h\")\n",
        "fig.update_layout(title={\n",
        "        #'text': \"Cumulative Return using FinRL\",\n",
        "        'y':0.85,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'})\n",
        "#with Transaction cost\n",
        "#fig.update_layout(title =  'Quarterly Trade Date')\n",
        "fig.update_layout(\n",
        "#    margin=dict(l=20, r=20, t=20, b=20),\n",
        "\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "    #xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Cumulative Return\",\n",
        "xaxis={'type': 'date',\n",
        "       'tick0': time_ind[0],\n",
        "        'tickmode': 'linear',\n",
        "       'dtick': 86400000.0 *80}\n",
        "\n",
        ")\n",
        "fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "\n",
        "fig.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bNmvYN9YbU4B",
        "rsDbM5Ex5Z1f",
        "tFQZ_bX25BR_",
        "xtvHJlZ6Fqhn",
        "5mnKtEacCSiZ",
        "qFO42LcomPUT",
        "te3Ibcj5hUbz"
      ],
      "provenance": []
    },
    "interpreter": {
      "hash": "0cd912b5b8ef2e2cf6ba30a360471b623d2891ab42b88478be3d571482cb392e"
    },
    "kernelspec": {
      "display_name": "PyCharm (FinRL)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}