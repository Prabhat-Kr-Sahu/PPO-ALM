{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Meta/blob/master/tutorials/1-Introduction/FinRL_PortfolioAllocation_NeurIPS_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv3IDvrobU37"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Portfolio Allocation\n",
        "\n",
        "Tutorials to use OpenAI DRL to perform portfolio allocation in one Jupyter Notebook | Presented at NeurIPS 2020: Deep RL Workshop\n",
        "\n",
        "* This blog is based on our paper: FinRL: A Deep Reinforcement Learning Library for Automated Stock Trading in Quantitative Finance, presented at NeurIPS 2020: Deep RL Workshop.\n",
        "* Check out medium blog for detailed explanations: https://towardsdatascience.com/finrl-for-quantitative-finance-tutorial-for-portfolio-allocation-9b417660c7cd\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-Foundation/FinRL/issues\n",
        "\n",
        "ESG-VARIABLES-PENALIZING\n",
        "* **Pytorch Version**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kHCfEiTA80V"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUmLTmoQA7_w"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12v1i0jVkg48"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L63HKnWvkirx"
      },
      "source": [
        "This problem is to design an automated trading solution for portfolio alloacation. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A represents the weight of a stock in the porfolio: a ∈ (-1,1). Assume our stock pool includes N stocks, we can use a list [a<sub>1</sub>, a<sub>2</sub>, ... , a<sub>N</sub>] to determine the weight for each stock in the porfotlio, where a<sub>i</sub> ∈ (-1,1), a<sub>1</sub>+ a<sub>2</sub>+...+a<sub>N</sub>=1. For example, \"The weight of AAPL in the portfolio is 10%.\" is [0.1 , ...].\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_emqQCCklVt"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVCcCalAknGn"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2568cp5bU38"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them.\n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNmvYN9YbU4B"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eI2jQ9ITiOFS",
        "outputId": "48fadfbf-6ff3-4bb6-acd3-77039aff5a66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from stockstats) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from stockstats) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->stockstats) (1.17.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n",
            "Requirement already satisfied: pyfolio in /usr/local/lib/python3.11/dist-packages (0.9.2)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (7.34.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (2.2.2)\n",
            "Requirement already satisfied: pytz>=2014.10 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (2025.2)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn>=0.16.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (1.6.1)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from pyfolio) (0.13.2)\n",
            "Collecting empyrical>=0.5.0 (from pyfolio)\n",
            "  Using cached empyrical-0.5.5-py3-none-any.whl\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.11/dist-packages (from empyrical>=0.5.0->pyfolio) (0.10.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (66.0.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (3.0.50)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (2.18.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=3.2.3->pyfolio) (4.9.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->pyfolio) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18.1->pyfolio) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.16.1->pyfolio) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.16.1->pyfolio) (3.6.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio) (0.8.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (5.3.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.32.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=3.2.3->pyfolio) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=1.4.0->pyfolio) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->pandas-datareader>=0.2->empyrical>=0.5.0->pyfolio) (2025.1.31)\n",
            "Installing collected packages: empyrical\n",
            "  Attempting uninstall: empyrical\n",
            "    Found existing installation: empyrical 0.3.4\n",
            "    Uninstalling empyrical-0.3.4:\n",
            "      Successfully uninstalled empyrical-0.3.4\n",
            "Successfully installed empyrical-0.5.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/pyfolio/pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install stockstats\n",
        "!pip install hyperopt\n",
        "!pip install pyfolio\n",
        "import stockstats\n",
        "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
        "import pyfolio\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlIS2abxkwan"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. FinRL Offline Scripts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsDbM5Ex5Z1f"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4.1. Yahoo Downloader (from finrl.meta.preprocessor.yahoodownloader import YahooDownloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dZ8zDBudTvb4"
      },
      "outputs": [],
      "source": [
        "\"\"\"Contains methods and classes to collect data from\n",
        "Yahoo Finance API\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None, auto_adjust=False) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic,\n",
        "                start=self.start_date,\n",
        "                end=self.end_date,\n",
        "                proxy=proxy,\n",
        "                auto_adjust=auto_adjust,\n",
        "            )\n",
        "            if temp_df.columns.nlevels != 1:\n",
        "                temp_df.columns = temp_df.columns.droplevel(1)\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures += 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "        try:\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(\n",
        "                columns={\n",
        "                    \"Date\": \"date\",\n",
        "                    \"Adj Close\": \"adjcp\",\n",
        "                    \"Close\": \"close\",\n",
        "                    \"High\": \"high\",\n",
        "                    \"Low\": \"low\",\n",
        "                    \"Volume\": \"volume\",\n",
        "                    \"Open\": \"open\",\n",
        "                    \"tic\": \"tic\",\n",
        "                },\n",
        "                inplace=True,\n",
        "            )\n",
        "\n",
        "            # use adjusted close price instead of close price\n",
        "            data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "            # drop the adjusted close price column\n",
        "            data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFQZ_bX25BR_"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4.2. Data Split (from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oo0isHPfbyEQ"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing.sharedctypes import Value\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "def load_dataset(*, file_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    load csv dataset from path\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n",
        "    _data = pd.read_csv(file_name)\n",
        "    return _data\n",
        "\n",
        "\n",
        "def data_split(df, start, end, target_date_col=\"date\"):\n",
        "    \"\"\"\n",
        "    split the dataset into training or testing using date\n",
        "    :param data: (df) pandas dataframe, start, end\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
        "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
        "    data.index = data[target_date_col].factorize()[0]\n",
        "    return data\n",
        "\n",
        "\n",
        "def convert_to_datetime(time):\n",
        "    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n",
        "    if isinstance(time, str):\n",
        "        return datetime.datetime.strptime(time, time_fmt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtvHJlZ6Fqhn"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4.3. Backtesting Functions (from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline,convert_daily_return_to_pyfolio_ts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rJVQA9fudIkf"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import copy\n",
        "import datetime\n",
        "from copy import deepcopy\n",
        "import empyrical as ep\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyfolio\n",
        "from pyfolio import timeseries\n",
        "import itertools\n",
        "\n",
        "# Replacing from pyfolio import timeseries with original codes ##\n",
        "\n",
        "def gross_lev(positions):\n",
        "    \"\"\"\n",
        "    Calculates the gross leverage of a strategy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    positions : pd.DataFrame\n",
        "        Daily net position values.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.Series\n",
        "        Gross leverage.\n",
        "    \"\"\"\n",
        "\n",
        "    exposure = positions.drop('cash', axis=1).abs().sum(axis=1)\n",
        "    return exposure / positions.sum(axis=1)\n",
        "\n",
        "def get_txn_vol(transactions):\n",
        "    \"\"\"\n",
        "    Extract daily transaction data from set of transaction objects.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    transactions : pd.DataFrame\n",
        "        Time series containing one row per symbol (and potentially\n",
        "        duplicate datetime indices) and columns for amount and\n",
        "        price.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.DataFrame\n",
        "        Daily transaction volume and number of shares.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "    \"\"\"\n",
        "\n",
        "    txn_norm = transactions.copy()\n",
        "    txn_norm.index = txn_norm.index.normalize()\n",
        "    amounts = txn_norm.amount.abs()\n",
        "    prices = txn_norm.price\n",
        "    values = amounts * prices\n",
        "    daily_amounts = amounts.groupby(amounts.index).sum()\n",
        "    daily_values = values.groupby(values.index).sum()\n",
        "    daily_amounts.name = \"txn_shares\"\n",
        "    daily_values.name = \"txn_volume\"\n",
        "    return pd.concat([daily_values, daily_amounts], axis=1)\n",
        "\n",
        "def get_turnover(positions, transactions, denominator='AGB'):\n",
        "    \"\"\"\n",
        "     - Value of purchases and sales divided\n",
        "    by either the actual gross book or the portfolio value\n",
        "    for the time step.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    positions : pd.DataFrame\n",
        "        Contains daily position values including cash.\n",
        "        - See full explanation in tears.create_full_tear_sheet\n",
        "    transactions : pd.DataFrame\n",
        "        Prices and amounts of executed trades. One row per trade.\n",
        "        - See full explanation in tears.create_full_tear_sheet\n",
        "    denominator : str, optional\n",
        "        Either 'AGB' or 'portfolio_value', default AGB.\n",
        "        - AGB (Actual gross book) is the gross market\n",
        "        value (GMV) of the specific algo being analyzed.\n",
        "        Swapping out an entire portfolio of stocks for\n",
        "        another will yield 200% turnover, not 100%, since\n",
        "        transactions are being made for both sides.\n",
        "        - We use average of the previous and the current end-of-period\n",
        "        AGB to avoid singularities when trading only into or\n",
        "        out of an entire book in one trading period.\n",
        "        - portfolio_value is the total value of the algo's\n",
        "        positions end-of-period, including cash.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    turnover_rate : pd.Series\n",
        "        timeseries of portfolio turnover rates.\n",
        "    \"\"\"\n",
        "\n",
        "    txn_vol = get_txn_vol(transactions)\n",
        "    traded_value = txn_vol.txn_volume\n",
        "\n",
        "    if denominator == 'AGB':\n",
        "        # Actual gross book is the same thing as the algo's GMV\n",
        "        # We want our denom to be avg(AGB previous, AGB current)\n",
        "        AGB = positions.drop('cash', axis=1).abs().sum(axis=1)\n",
        "        denom = AGB.rolling(2).mean()\n",
        "\n",
        "        # Since the first value of pd.rolling returns NaN, we\n",
        "        # set our \"day 0\" AGB to 0.\n",
        "        denom.iloc[0] = AGB.iloc[0] / 2\n",
        "    elif denominator == 'portfolio_value':\n",
        "        denom = positions.sum(axis=1)\n",
        "    else:\n",
        "        raise ValueError(\n",
        "            \"Unexpected value for denominator '{}'. The \"\n",
        "            \"denominator parameter must be either 'AGB'\"\n",
        "            \" or 'portfolio_value'.\".format(denominator)\n",
        "        )\n",
        "\n",
        "    denom.index = denom.index.normalize()\n",
        "    turnover = traded_value.div(denom, axis='index')\n",
        "    turnover = turnover.fillna(0)\n",
        "    return turnover\n",
        "\n",
        "SIMPLE_STAT_FUNCS = [\n",
        "    ep.annual_return,\n",
        "    ep.cum_returns_final,\n",
        "    ep.annual_volatility,\n",
        "    ep.sharpe_ratio,\n",
        "    ep.calmar_ratio,\n",
        "    ep.stability_of_timeseries,\n",
        "    # ep.max_drawdown,\n",
        "    ep.omega_ratio,\n",
        "    # ep.sortino_ratio,\n",
        "    # stats.skew,\n",
        "    # stats.kurtosis,\n",
        "    # ep.tail_ratio,\n",
        "    # value_at_risk\n",
        "]\n",
        "\n",
        "FACTOR_STAT_FUNCS = [\n",
        "    # ep.alpha,\n",
        "    # ep.beta,\n",
        "]\n",
        "\n",
        "STAT_FUNC_NAMES = {\n",
        "    'annual_return': 'Annual return',\n",
        "    'cum_returns_final': 'Cumulative returns',\n",
        "    'annual_volatility': 'Annual volatility',\n",
        "    'sharpe_ratio': 'Sharpe ratio',\n",
        "    'calmar_ratio': 'Calmar ratio',\n",
        "    'stability_of_timeseries': 'Stability',\n",
        "    # 'max_drawdown': 'Max drawdown',\n",
        "    'omega_ratio': 'Omega ratio',\n",
        "    # 'sortino_ratio': 'Sortino ratio',\n",
        "    # 'skew': 'Skew',\n",
        "    # 'kurtosis': 'Kurtosis',\n",
        "    # 'tail_ratio': 'Tail ratio',\n",
        "    # 'common_sense_ratio': 'Common sense ratio',\n",
        "    # 'value_at_risk': 'Daily value at risk',\n",
        "    # 'alpha': 'Alpha',\n",
        "    # 'beta': 'Beta',\n",
        "}\n",
        "\n",
        "\n",
        "def perf_stats(returns, factor_returns=None, positions=None,\n",
        "               transactions=None, turnover_denom='AGB'):\n",
        "    \"\"\"\n",
        "    Calculates various performance metrics of a strategy, for use in\n",
        "    plotting.show_perf_stats.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    returns : pd.Series\n",
        "        Daily returns of the strategy, noncumulative.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "    factor_returns : pd.Series, optional\n",
        "        Daily noncumulative returns of the benchmark factor to which betas are\n",
        "        computed. Usually a benchmark such as market returns.\n",
        "         - This is in the same style as returns.\n",
        "         - If None, do not compute alpha, beta, and information ratio.\n",
        "    positions : pd.DataFrame\n",
        "        Daily net position values.\n",
        "         - See full explanation in tears.create_full_tear_sheet.\n",
        "    transactions : pd.DataFrame\n",
        "        Prices and amounts of executed trades. One row per trade.\n",
        "        - See full explanation in tears.create_full_tear_sheet.\n",
        "    turnover_denom : str\n",
        "        Either AGB or portfolio_value, default AGB.\n",
        "        - See full explanation in txn.get_turnover.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    pd.Series\n",
        "        Performance metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    stats = pd.Series()\n",
        "    for stat_func in SIMPLE_STAT_FUNCS:\n",
        "        stats[STAT_FUNC_NAMES[stat_func.__name__]] = stat_func(returns)\n",
        "\n",
        "    if positions is not None:\n",
        "        stats['Gross leverage'] = gross_lev(positions).mean()\n",
        "        if transactions is not None:\n",
        "            stats['Daily turnover'] = get_turnover(positions,\n",
        "                                                   transactions,\n",
        "                                                   turnover_denom).mean()\n",
        "    if factor_returns is not None:\n",
        "        for stat_func in FACTOR_STAT_FUNCS:\n",
        "            res = stat_func(returns, factor_returns)\n",
        "            stats[STAT_FUNC_NAMES[stat_func.__name__]] = res\n",
        "\n",
        "    return stats\n",
        "#######################\n",
        "def date2str(dat: datetime.date) -> str:\n",
        "    return datetime.date.strftime(dat, \"%Y-%m-%d\")\n",
        "\n",
        "def str2date(dat: str) -> datetime.date:\n",
        "    return datetime.datetime.strptime(dat, \"%Y-%m-%d\").date()\n",
        "\n",
        "def get_daily_return(df, value_col_name=\"account_value\"):\n",
        "    df = deepcopy(df)\n",
        "    df[\"daily_return\"] = df[value_col_name].pct_change(1)\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    df.set_index(\"date\", inplace=True, drop=True)\n",
        "    df.index = df.index.tz_localize(\"UTC\")\n",
        "    return pd.Series(df[\"daily_return\"], index=df.index)\n",
        "\n",
        "\n",
        "def convert_daily_return_to_pyfolio_ts(df):\n",
        "    strategy_ret = df.copy()\n",
        "    strategy_ret[\"date\"] = pd.to_datetime(strategy_ret[\"date\"])\n",
        "    strategy_ret.set_index(\"date\", drop=False, inplace=True)\n",
        "    strategy_ret.index = strategy_ret.index.tz_localize(\"UTC\")\n",
        "    del strategy_ret[\"date\"]\n",
        "    return pd.Series(strategy_ret[\"daily_return\"].values, index=strategy_ret.index)\n",
        "\n",
        "\n",
        "# def backtest_stats(account_value, value_col_name=\"account_value\"):\n",
        "#     dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n",
        "#     perf_stats_all = timeseries.perf_stats(\n",
        "#         returns=dr_test,\n",
        "#         positions=None,\n",
        "#         transactions=None,\n",
        "#         turnover_denom=\"AGB\",\n",
        "#     )\n",
        "#     print(perf_stats_all)\n",
        "#     return perf_stats_all\n",
        "\n",
        "def backtest_stats(account_value, value_col_name=\"account_value\"):\n",
        "    dr_test = get_daily_return(account_value, value_col_name=value_col_name)\n",
        "    perf_stats_all = perf_stats(\n",
        "        returns=dr_test,\n",
        "        positions=None,\n",
        "        transactions=None,\n",
        "        turnover_denom=\"AGB\",\n",
        "    )\n",
        "    print(perf_stats_all)\n",
        "    return perf_stats_all\n",
        "\n",
        "\n",
        "# def backtest_plot(\n",
        "#     account_value,\n",
        "#     baseline_start=TRADE_START_DATE,\n",
        "#     baseline_end=TRADE_END_DATE,\n",
        "#     baseline_ticker=\"^DJI\",\n",
        "#     value_col_name=\"account_value\",\n",
        "# ):\n",
        "#     df = deepcopy(account_value)\n",
        "#     df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "#     test_returns = get_daily_return(df, value_col_name=value_col_name)\n",
        "\n",
        "#     baseline_df = get_baseline(\n",
        "#         ticker=baseline_ticker, start=baseline_start, end=baseline_end\n",
        "#     )\n",
        "\n",
        "#     baseline_df[\"date\"] = pd.to_datetime(baseline_df[\"date\"], format=\"%Y-%m-%d\")\n",
        "#     baseline_df = pd.merge(df[[\"date\"]], baseline_df, how=\"left\", on=\"date\")\n",
        "#     baseline_df = baseline_df.fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
        "#     baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "#     with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
        "#         pyfolio.create_full_tear_sheet(\n",
        "#             returns=test_returns, benchmark_rets=baseline_returns, set_context=False\n",
        "#         )\n",
        "\n",
        "\n",
        "def get_baseline(ticker, start, end):\n",
        "    return YahooDownloader(\n",
        "        start_date=start, end_date=end, ticker_list=[ticker]\n",
        "    ).fetch_data()\n",
        "\n",
        "\n",
        "def trx_plot(df_trade, df_actions, ticker_list):\n",
        "    df_trx = pd.DataFrame(np.array(df_actions[\"transactions\"].to_list()))\n",
        "    df_trx.columns = ticker_list\n",
        "    df_trx.index = df_actions[\"date\"]\n",
        "    df_trx.index.name = \"\"\n",
        "\n",
        "    for i in range(df_trx.shape[1]):\n",
        "        df_trx_temp = df_trx.iloc[:, i]\n",
        "        df_trx_temp_sign = np.sign(df_trx_temp)\n",
        "        buying_signal = df_trx_temp_sign.apply(lambda x: x > 0)\n",
        "        selling_signal = df_trx_temp_sign.apply(lambda x: x < 0)\n",
        "\n",
        "        tic_plot = df_trade[\n",
        "            (df_trade[\"tic\"] == df_trx_temp.name)\n",
        "            & (df_trade[\"date\"].isin(df_trx.index))\n",
        "        ][\"close\"]\n",
        "        tic_plot.index = df_trx_temp.index\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        plt.plot(tic_plot, color=\"g\", lw=2.0)\n",
        "        plt.plot(\n",
        "            tic_plot,\n",
        "            \"^\",\n",
        "            markersize=10,\n",
        "            color=\"m\",\n",
        "            label=\"buying signal\",\n",
        "            markevery=buying_signal,\n",
        "        )\n",
        "        plt.plot(\n",
        "            tic_plot,\n",
        "            \"v\",\n",
        "            markersize=10,\n",
        "            color=\"k\",\n",
        "            label=\"selling signal\",\n",
        "            markevery=selling_signal,\n",
        "        )\n",
        "        plt.title(\n",
        "            f\"{df_trx_temp.name} Num Transactions: {len(buying_signal[buying_signal == True]) + len(selling_signal[selling_signal == True])}\"\n",
        "        )\n",
        "        plt.legend()\n",
        "        plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval=25))\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# 2022-01-15 -> 01/15/2022\n",
        "def transfer_date(str_dat):\n",
        "    return datetime.datetime.strptime(str_dat, \"%Y-%m-%d\").date().strftime(\"%m/%d/%Y\")\n",
        "\n",
        "\n",
        "def plot_result_from_csv(\n",
        "    csv_file: str,\n",
        "    column_as_x: str,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Result\",\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    result = pd.read_csv(csv_file)\n",
        "    plot_result(\n",
        "        result,\n",
        "        column_as_x,\n",
        "        savefig_filename,\n",
        "        xlabel,\n",
        "        ylabel,\n",
        "        num_days_xticks,\n",
        "        xrotation,\n",
        "    )\n",
        "\n",
        "\n",
        "# select_start_date: included\n",
        "# select_end_date: included\n",
        "# is if_need_calc_return is True, it is account_value, and then transfer it to return\n",
        "# it is better that column_as_x is the first column, and the other columns are strategies\n",
        "# xrotation: the rotation of xlabel, may be used in dates. Default=0 (adaptive adjustment)\n",
        "def plot_result(\n",
        "    result: pd.DataFrame(),\n",
        "    column_as_x: str,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Result\",\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    columns = result.columns\n",
        "    columns_strtegy = []\n",
        "    for i in range(len(columns)):\n",
        "        col = columns[i]\n",
        "        if \"Unnamed\" not in col and col != column_as_x:\n",
        "            columns_strtegy.append(col)\n",
        "\n",
        "    result.reindex()\n",
        "\n",
        "    x = result[column_as_x].values.tolist()\n",
        "    plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
        "    # plt.figure()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    colors = [\n",
        "        \"black\",\n",
        "        \"red\",\n",
        "        \"green\",\n",
        "        \"blue\",\n",
        "        \"cyan\",\n",
        "        \"magenta\",\n",
        "        \"yellow\",\n",
        "        \"aliceblue\",\n",
        "        \"coral\",\n",
        "        \"darksalmon\",\n",
        "        \"firebrick\",\n",
        "        \"honeydew\",\n",
        "    ]\n",
        "    for i in range(len(columns_strtegy)):\n",
        "        col = columns_strtegy[i]\n",
        "        ax.plot(\n",
        "            x,\n",
        "            result[col],\n",
        "            color=colors[i],\n",
        "            linewidth=1,\n",
        "            linestyle=\"-\",\n",
        "        )\n",
        "\n",
        "    plt.title(\"\", fontsize=20)\n",
        "    plt.xlabel(xlabel, fontsize=20)\n",
        "    plt.ylabel(ylabel, fontsize=20)\n",
        "\n",
        "    plt.legend(labels=columns_strtegy, loc=\"best\", fontsize=16)\n",
        "\n",
        "    # set grid\n",
        "    plt.grid()\n",
        "\n",
        "    plt.xticks(size=22)  # 设置刻度大小\n",
        "    plt.yticks(size=22)  # 设置刻度大小\n",
        "\n",
        "    # #设置每隔多少距离⼀个刻度\n",
        "    # plt.xticks(x[::60])\n",
        "\n",
        "    # # 设置每月定位符\n",
        "    # if if_set_x_monthlocator:\n",
        "    #     ax.xaxis.set_major_locator(mdates.MonthLocator())  # interval = 1\n",
        "\n",
        "    # 设置每隔多少距离⼀个刻度\n",
        "    plt.xticks(x[::num_days_xticks])\n",
        "\n",
        "    plt.setp(ax.get_xticklabels(), rotation=xrotation, horizontalalignment=\"center\")\n",
        "\n",
        "    # 为防止x轴label重叠，自动调整label旋转角度\n",
        "    if xrotation == 0:\n",
        "        if_overlap = get_if_overlap(fig, ax)\n",
        "\n",
        "        if if_overlap == True:\n",
        "            plt.gcf().autofmt_xdate(ha=\"right\")  # ⾃动旋转⽇期标记\n",
        "\n",
        "    plt.tight_layout()  # 自动调整子图间距\n",
        "\n",
        "    plt.savefig(savefig_filename)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def get_if_overlap(fig, ax):\n",
        "    fig.canvas.draw()\n",
        "    # 获取日期标签的边界框\n",
        "    bboxes = [label.get_window_extent() for label in ax.get_xticklabels()]\n",
        "    # 计算日期标签之间的距离\n",
        "    distances = [bboxes[i + 1].x0 - bboxes[i].x1 for i in range(len(bboxes) - 1)]\n",
        "    # 如果有任何距离小于0，说明有重叠\n",
        "    if any(distance < 0 for distance in distances):\n",
        "        if_overlap = True\n",
        "    else:\n",
        "        if_overlap = False\n",
        "\n",
        "    return if_overlap\n",
        "\n",
        "\n",
        "def plot_return(\n",
        "    result: pd.DataFrame(),\n",
        "    column_as_x: str,\n",
        "    if_need_calc_return: bool,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Return\",\n",
        "    if_transfer_date: bool = True,\n",
        "    select_start_date: str = None,\n",
        "    select_end_date: str = None,\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    if select_start_date is None:\n",
        "        select_start_date: str = result[column_as_x].iloc[0]\n",
        "        select_end_date: str = result[column_as_x].iloc[-1]\n",
        "    # calc returns if if_need_calc_return is True, so that result stores returns\n",
        "    select_start_date_index = result[column_as_x].tolist().index(select_start_date)\n",
        "    columns = result.columns\n",
        "    columns_strtegy = []\n",
        "    column_as_x_index = None\n",
        "    for i in range(len(columns)):\n",
        "        col = columns[i]\n",
        "        if col == column_as_x:\n",
        "            column_as_x_index = i\n",
        "        elif \"Unnamed\" not in col:\n",
        "            columns_strtegy.append(col)\n",
        "            if if_need_calc_return:\n",
        "                result[col] = result[col] / result[col][select_start_date_index] - 1\n",
        "\n",
        "    # select the result between select_start_date and select_end_date\n",
        "    # if date is 2020-01-15, transfer it to 01/15/2020\n",
        "    num_rows, num_cols = result.shape\n",
        "    tmp_result = copy.deepcopy(result)\n",
        "    result = pd.DataFrame()\n",
        "    if_first_row = True\n",
        "    columns = []\n",
        "    for i in range(num_rows):\n",
        "        if (\n",
        "            str2date(select_start_date)\n",
        "            <= str2date(tmp_result[column_as_x][i])\n",
        "            <= str2date(select_end_date)\n",
        "        ):\n",
        "            if \"-\" in tmp_result.iloc[i][column_as_x] and if_transfer_date:\n",
        "                new_date = transfer_date(tmp_result.iloc[i][column_as_x])\n",
        "            else:\n",
        "                new_date = tmp_result.iloc[i][column_as_x]\n",
        "            tmp_result.iloc[i, column_as_x_index] = new_date\n",
        "            # print(\"tmp_result.iloc[i]: \", tmp_result.iloc[i])\n",
        "            # result = result.append(tmp_result.iloc[i])\n",
        "            if if_first_row:\n",
        "                columns = tmp_result.iloc[i].index.tolist()\n",
        "                result = pd.DataFrame(columns=columns)\n",
        "                # result = pd.concat([result, tmp_result.iloc[i]], axis=1)\n",
        "                # result = pd.DataFrame(tmp_result.iloc[i])\n",
        "                # result.columns = tmp_result.iloc[i].index.tolist()\n",
        "                if_first_row = False\n",
        "            row = pd.DataFrame([tmp_result.iloc[i].tolist()], columns=columns)\n",
        "            result = pd.concat([result, row], axis=0)\n",
        "\n",
        "    # print final return of each strategy\n",
        "    final_return = {}\n",
        "    for col in columns_strtegy:\n",
        "        final_return[col] = result.iloc[-1][col]\n",
        "    print(\"final return: \", final_return)\n",
        "\n",
        "    result.reindex()\n",
        "\n",
        "    plot_result(\n",
        "        result=result,\n",
        "        column_as_x=column_as_x,\n",
        "        savefig_filename=savefig_filename,\n",
        "        xlabel=xlabel,\n",
        "        ylabel=ylabel,\n",
        "        num_days_xticks=num_days_xticks,\n",
        "        xrotation=xrotation,\n",
        "    )\n",
        "\n",
        "\n",
        "def plot_return_from_csv(\n",
        "    csv_file: str,\n",
        "    column_as_x: str,\n",
        "    if_need_calc_return: bool,\n",
        "    savefig_filename: str = \"fig/result.png\",\n",
        "    xlabel: str = \"Date\",\n",
        "    ylabel: str = \"Return\",\n",
        "    if_transfer_date: bool = True,\n",
        "    select_start_date: str = None,\n",
        "    select_end_date: str = None,\n",
        "    num_days_xticks: int = 20,\n",
        "    xrotation: int = 0,\n",
        "):\n",
        "    result = pd.read_csv(csv_file)\n",
        "    plot_return(\n",
        "        result,\n",
        "        column_as_x,\n",
        "        if_need_calc_return,\n",
        "        savefig_filename,\n",
        "        xlabel,\n",
        "        ylabel,\n",
        "        if_transfer_date,\n",
        "        select_start_date,\n",
        "        select_end_date,\n",
        "        num_days_xticks,\n",
        "        xrotation,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_vwG5axWdu7S"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime\n",
        "import os\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slBria_QbU4F"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vAxVlL6wwooM"
      },
      "outputs": [],
      "source": [
        "# Indian Sensex 33\n",
        "sensex_ticker = [\"ASIANPAINT.NS\", \"AXISBANK.NS\", \"BAJFINANCE.NS\", \"BAJAJFINSV.NS\", \"BHARTIARTL.NS\", \"HCLTECH.NS\", \"HDFCBANK.NS\",\n",
        "                 \"HINDUNILVR.NS\", \"ICICIBANK.NS\", \"INDUSINDBK.NS\", \"INFY.NS\", \"ITC.NS\", \"JSWSTEEL.NS\", \"KOTAKBANK.NS\", \"LT.NS\",\n",
        "                 \"M&M.NS\", \"MARUTI.NS\", \"NESTLEIND.NS\", \"NTPC.NS\", \"POWERGRID.NS\", \"RELIANCE.NS\", \"SBIN.NS\", \"SUNPHARMA.NS\",\n",
        "                 \"TATAMOTORS.NS\", \"TATASTEEL.NS\", \"TCS.NS\", \"TECHM.NS\", \"TITAN.NS\", \"ULTRACEMCO.NS\", \"WIPRO.NS\"]\n",
        "\n",
        "Nifty_50 = ['ADANIENT.NS', 'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS',\n",
        "       'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJAJFINSV.NS', 'BAJFINANCE.NS',\n",
        "       'BHARTIARTL.NS', 'BPCL.NS', 'BRITANNIA.NS', 'CIPLA.NS', 'COALINDIA.NS',\n",
        "       'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS', 'GRASIM.NS', 'HCLTECH.NS',\n",
        "       'HDFCBANK.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS',\n",
        "       'ICICIBANK.NS', 'INDUSINDBK.NS', 'ITC.NS', 'JSWSTEEL.NS',\n",
        "       'KOTAKBANK.NS', 'LT.NS', 'M&M.NS', 'MARUTI.NS', 'NESTLEIND.NS',\n",
        "       'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBIN.NS',\n",
        "       'SUNPHARMA.NS', 'TATACONSUM.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS',\n",
        "       'TCS.NS', 'TECHM.NS', 'TITAN.NS', 'UPL.NS', 'WIPRO.NS', \"INFY.NS\", \"ULTRACEMCO.NS\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "maq0L3gcXvFO",
        "outputId": "a091b3b7-8f76-428c-d5d6-ad739582e417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: setuptools==66 in /usr/local/lib/python3.11/dist-packages (66.0.0)\n",
            "Requirement already satisfied: stockstats in /usr/local/lib/python3.11/dist-packages (0.6.4)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.11/dist-packages (from stockstats) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from stockstats) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->stockstats) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->stockstats) (1.17.0)\n",
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install setuptools==66\n",
        "!pip install stockstats\n",
        "!pip install hyperopt\n",
        "# !pip install pyfolio\n",
        "import stockstats\n",
        "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
        "# import pyfolio\n",
        "from collections import deque"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "J-9xQFbkX0D9"
      },
      "outputs": [],
      "source": [
        "\"\"\"Contains methods and classes to collect data from\n",
        "Yahoo Finance API\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import annotations\n",
        "\n",
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "\n",
        "\n",
        "class YahooDownloader:\n",
        "    \"\"\"Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from neofinrl_config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from neofinrl_config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from neofinrl_config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, start_date: str, end_date: str, ticker_list: list):\n",
        "        self.start_date = start_date\n",
        "        self.end_date = end_date\n",
        "        self.ticker_list = ticker_list\n",
        "\n",
        "    def fetch_data(self, proxy=None, auto_adjust=False) -> pd.DataFrame:\n",
        "        \"\"\"Fetches data from Yahoo API\n",
        "        Parameters\n",
        "        ----------\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        `pd.DataFrame`\n",
        "            7 columns: A date, open, high, low, close, volume and tick symbol\n",
        "            for the specified stock ticker\n",
        "        \"\"\"\n",
        "        # Download and save the data in a pandas DataFrame:\n",
        "        data_df = pd.DataFrame()\n",
        "        num_failures = 0\n",
        "        for tic in self.ticker_list:\n",
        "            temp_df = yf.download(\n",
        "                tic,\n",
        "                start=self.start_date,\n",
        "                end=self.end_date,\n",
        "                proxy=proxy,\n",
        "                auto_adjust=auto_adjust,\n",
        "            )\n",
        "            if temp_df.columns.nlevels != 1:\n",
        "                temp_df.columns = temp_df.columns.droplevel(1)\n",
        "            temp_df[\"tic\"] = tic\n",
        "            if len(temp_df) > 0:\n",
        "                # data_df = data_df.append(temp_df)\n",
        "                data_df = pd.concat([data_df, temp_df], axis=0)\n",
        "            else:\n",
        "                num_failures = num_failures+ 1\n",
        "        if num_failures == len(self.ticker_list):\n",
        "            raise ValueError(\"no data is fetched.\")\n",
        "        # reset the index, we want to use numbers as index instead of dates\n",
        "        data_df = data_df.reset_index()\n",
        "        try:\n",
        "            # convert the column names to standardized names\n",
        "            data_df.rename(\n",
        "                columns={\n",
        "                    \"Date\": \"date\",\n",
        "                    \"Adj Close\": \"adjcp\",\n",
        "                    \"Close\": \"close\",\n",
        "                    \"High\": \"high\",\n",
        "                    \"Low\": \"low\",\n",
        "                    \"Volume\": \"volume\",\n",
        "                    \"Open\": \"open\",\n",
        "                    \"tic\": \"tic\",\n",
        "                },\n",
        "                inplace=True,\n",
        "            )\n",
        "\n",
        "            # use adjusted close price instead of close price\n",
        "            data_df[\"close\"] = data_df[\"adjcp\"]\n",
        "            # drop the adjusted close price column\n",
        "            data_df = data_df.drop(labels=\"adjcp\", axis=1)\n",
        "        except NotImplementedError:\n",
        "            print(\"the features are not supported currently\")\n",
        "        # create day of the week column (monday = 0)\n",
        "        data_df[\"day\"] = data_df[\"date\"].dt.dayofweek\n",
        "        # convert date to standard string format, easy to filter\n",
        "        data_df[\"date\"] = data_df.date.apply(lambda x: x.strftime(\"%Y-%m-%d\"))\n",
        "        # drop missing data\n",
        "        data_df = data_df.dropna()\n",
        "        data_df = data_df.reset_index(drop=True)\n",
        "        print(\"Shape of DataFrame: \", data_df.shape)\n",
        "        # print(\"Display DataFrame: \", data_df.head())\n",
        "\n",
        "        data_df = data_df.sort_values(by=[\"date\", \"tic\"]).reset_index(drop=True)\n",
        "\n",
        "        return data_df\n",
        "\n",
        "    def select_equal_rows_stock(self, df):\n",
        "        df_check = df.tic.value_counts()\n",
        "        df_check = pd.DataFrame(df_check).reset_index()\n",
        "        df_check.columns = [\"tic\", \"counts\"]\n",
        "        mean_df = df_check.counts.mean()\n",
        "        equal_list = list(df.tic.value_counts() >= mean_df)\n",
        "        names = df.tic.value_counts().index\n",
        "        select_stocks_list = list(names[equal_list])\n",
        "        df = df[df.tic.isin(select_stocks_list)]\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vqYU4J64X3G-"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from multiprocessing.sharedctypes import Value\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "def load_dataset(*, file_name: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    load csv dataset from path\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    # _data = pd.read_csv(f\"{config.DATASET_DIR}/{file_name}\")\n",
        "    _data = pd.read_csv(file_name)\n",
        "    return _data\n",
        "\n",
        "\n",
        "def data_split(df, start, end, target_date_col=\"date\"):\n",
        "    \"\"\"\n",
        "    split the dataset into training or testing using date\n",
        "    :param data: (df) pandas dataframe, start, end\n",
        "    :return: (df) pandas dataframe\n",
        "    \"\"\"\n",
        "    data = df[(df[target_date_col] >= start) & (df[target_date_col] < end)]\n",
        "    data = data.sort_values([target_date_col, \"tic\"], ignore_index=True)\n",
        "    data.index = data[target_date_col].factorize()[0]\n",
        "    return data\n",
        "\n",
        "\n",
        "def convert_to_datetime(time):\n",
        "    time_fmt = \"%Y-%m-%dT%H:%M:%S\"\n",
        "    if isinstance(time, str):\n",
        "        return datetime.datetime.strptime(time, time_fmt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6aiSeCMfX5p7"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import datetime\n",
        "import os\n",
        "from datetime import date\n",
        "from datetime import timedelta\n",
        "from typing import List\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mnKtEacCSiZ"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y97Nv8RbX7xa",
        "outputId": "1ec96889-070b-4384-d01b-a29817127c86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.11/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.17.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.4.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from hyperopt) (1.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from hyperopt) (4.67.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from hyperopt) (3.1.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install hyperopt\n",
        "from hyperopt import fmin, tpe, hp, Trials, space_eval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afbOK2ImYLIr"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jgD9YxMjy4gb"
      },
      "outputs": [],
      "source": [
        "Market = 'Nifty_50'\n",
        "Reward = 'LSTM'\n",
        "BL = '^NSEI'\n",
        "#BL = '^CNX100'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQT27rmvV0BG",
        "outputId": "76f87120-53a2-4759-f160-ec47c747335b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame:  (165064, 8)\n"
          ]
        }
      ],
      "source": [
        "# Download and save the data in a pandas DataFrame:\n",
        "df = YahooDownloader(start_date = '2011-01-01',\n",
        "                     end_date = '2025-03-31',\n",
        "                     ticker_list = Nifty_50).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mS1-nxRzbU4i",
        "outputId": "fef46e11-cc75-422e-aee0-ed29f2398a82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Price         date         close          high           low          open  \\\n",
              "0       2011-01-03     83.078514    101.130882     98.862411    100.395164   \n",
              "1       2011-01-03    134.131119    146.399994    143.050003    145.550003   \n",
              "2       2011-01-03    437.000702    469.950012    458.000000    459.000000   \n",
              "3       2011-01-03    256.154358    293.739990    286.005005    289.799988   \n",
              "4       2011-01-03    251.461945    274.399994    268.459991    273.000000   \n",
              "...            ...           ...           ...           ...           ...   \n",
              "165059  2025-03-28   1418.250000   1430.000000   1408.550049   1415.099976   \n",
              "165060  2025-03-28   3063.350098   3111.800049   3051.050049   3094.000000   \n",
              "165061  2025-03-28  11509.549805  11699.000000  11458.650391  11585.500000   \n",
              "165062  2025-03-28    636.250000    660.400024    624.000000    656.650024   \n",
              "165063  2025-03-28    262.250000    271.850006    261.600006    271.000000   \n",
              "\n",
              "Price     volume            tic  day  \n",
              "0         877846    ADANIENT.NS    0  \n",
              "1         487210  ADANIPORTS.NS    0  \n",
              "2          51291  APOLLOHOSP.NS    0  \n",
              "3         454300  ASIANPAINT.NS    0  \n",
              "4        5266100    AXISBANK.NS    0  \n",
              "...          ...            ...  ...  \n",
              "165059   1642693       TECHM.NS    4  \n",
              "165060    778417       TITAN.NS    4  \n",
              "165061    280960  ULTRACEMCO.NS    4  \n",
              "165062   4421109         UPL.NS    4  \n",
              "165063  14283389       WIPRO.NS    4  \n",
              "\n",
              "[165064 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-41ee4c40-712f-4eab-8199-247c6bc85889\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Price</th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>83.078514</td>\n",
              "      <td>101.130882</td>\n",
              "      <td>98.862411</td>\n",
              "      <td>100.395164</td>\n",
              "      <td>877846</td>\n",
              "      <td>ADANIENT.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>134.131119</td>\n",
              "      <td>146.399994</td>\n",
              "      <td>143.050003</td>\n",
              "      <td>145.550003</td>\n",
              "      <td>487210</td>\n",
              "      <td>ADANIPORTS.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>437.000702</td>\n",
              "      <td>469.950012</td>\n",
              "      <td>458.000000</td>\n",
              "      <td>459.000000</td>\n",
              "      <td>51291</td>\n",
              "      <td>APOLLOHOSP.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>256.154358</td>\n",
              "      <td>293.739990</td>\n",
              "      <td>286.005005</td>\n",
              "      <td>289.799988</td>\n",
              "      <td>454300</td>\n",
              "      <td>ASIANPAINT.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2011-01-03</td>\n",
              "      <td>251.461945</td>\n",
              "      <td>274.399994</td>\n",
              "      <td>268.459991</td>\n",
              "      <td>273.000000</td>\n",
              "      <td>5266100</td>\n",
              "      <td>AXISBANK.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165059</th>\n",
              "      <td>2025-03-28</td>\n",
              "      <td>1418.250000</td>\n",
              "      <td>1430.000000</td>\n",
              "      <td>1408.550049</td>\n",
              "      <td>1415.099976</td>\n",
              "      <td>1642693</td>\n",
              "      <td>TECHM.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165060</th>\n",
              "      <td>2025-03-28</td>\n",
              "      <td>3063.350098</td>\n",
              "      <td>3111.800049</td>\n",
              "      <td>3051.050049</td>\n",
              "      <td>3094.000000</td>\n",
              "      <td>778417</td>\n",
              "      <td>TITAN.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165061</th>\n",
              "      <td>2025-03-28</td>\n",
              "      <td>11509.549805</td>\n",
              "      <td>11699.000000</td>\n",
              "      <td>11458.650391</td>\n",
              "      <td>11585.500000</td>\n",
              "      <td>280960</td>\n",
              "      <td>ULTRACEMCO.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165062</th>\n",
              "      <td>2025-03-28</td>\n",
              "      <td>636.250000</td>\n",
              "      <td>660.400024</td>\n",
              "      <td>624.000000</td>\n",
              "      <td>656.650024</td>\n",
              "      <td>4421109</td>\n",
              "      <td>UPL.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165063</th>\n",
              "      <td>2025-03-28</td>\n",
              "      <td>262.250000</td>\n",
              "      <td>271.850006</td>\n",
              "      <td>261.600006</td>\n",
              "      <td>271.000000</td>\n",
              "      <td>14283389</td>\n",
              "      <td>WIPRO.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>165064 rows × 8 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41ee4c40-712f-4eab-8199-247c6bc85889')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41ee4c40-712f-4eab-8199-247c6bc85889 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41ee4c40-712f-4eab-8199-247c6bc85889');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-125a1fb4-f0e9-4aed-9769-960a06d1cf09\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-125a1fb4-f0e9-4aed-9769-960a06d1cf09')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-125a1fb4-f0e9-4aed-9769-960a06d1cf09 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_64462159-4b01-4e31-99a2-2d438ef83d35\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_64462159-4b01-4e31-99a2-2d438ef83d35 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.shape\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srkOBy5nY9Hv"
      },
      "source": [
        "## Our Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JQKygIHcuWsN"
      },
      "outputs": [],
      "source": [
        "from stockstats import StockDataFrame as Sdf\n",
        "\n",
        "def add_tech(data, INDICATORS):\n",
        "  df = data.copy()\n",
        "  df = df.sort_values(by=[\"tic\", \"date\"])\n",
        "  stock = Sdf.retype(df.copy())\n",
        "  unique_ticker = stock.tic.unique()\n",
        "\n",
        "  for indicator in INDICATORS:\n",
        "      indicator_df = pd.DataFrame()\n",
        "      for i in range(len(unique_ticker)):\n",
        "          try:\n",
        "              temp_indicator = stock[stock.tic == unique_ticker[i]][indicator]\n",
        "              temp_indicator = pd.DataFrame(temp_indicator)\n",
        "              temp_indicator[\"tic\"] = unique_ticker[i]\n",
        "              temp_indicator[\"date\"] = df[df.tic == unique_ticker[i]][\n",
        "                  \"date\"\n",
        "              ].to_list()\n",
        "              # indicator_df = indicator_df.append(\n",
        "              #     temp_indicator, ignore_index=True\n",
        "              # )\n",
        "              indicator_df = pd.concat(\n",
        "                  [indicator_df, temp_indicator], axis=0, ignore_index=True\n",
        "              )\n",
        "          except Exception as e:\n",
        "              print(e)\n",
        "      df = df.merge(\n",
        "          indicator_df[[\"tic\", \"date\", indicator]], on=[\"tic\", \"date\"], how=\"left\"\n",
        "      )\n",
        "\n",
        "  df = df.sort_values(by=[\"date\", \"tic\"])\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "noCZD8Ysudjp"
      },
      "outputs": [],
      "source": [
        "INDICATORS = ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
        "df = add_tech(df, INDICATORS)\n",
        "df = df.ffill().bfill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HRhdUmpRukT0"
      },
      "outputs": [],
      "source": [
        "# add covariance matrix as states\n",
        "df=df.sort_values(['date','tic'],ignore_index=True)\n",
        "df.index = df.date.factorize()[0]\n",
        "\n",
        "cov_list = []\n",
        "return_list = []\n",
        "\n",
        "# look back is one year\n",
        "lookback=252\n",
        "for i in range(lookback,len(df.index.unique())):\n",
        "  data_lookback = df.loc[i-lookback:i,:]\n",
        "  price_lookback=data_lookback.pivot_table(index = 'date',columns = 'tic', values = 'close')\n",
        "  return_lookback = price_lookback.pct_change().dropna()\n",
        "  return_list.append(return_lookback)\n",
        "\n",
        "  covs = return_lookback.cov().values\n",
        "  cov_list.append(covs)\n",
        "\n",
        "\n",
        "df_cov = pd.DataFrame({'date':df.date.unique()[lookback:],'cov_list':cov_list,'return_list':return_list})\n",
        "df = df.merge(df_cov, on='date')\n",
        "df = df.sort_values(['date','tic']).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "kdeVQHXrun6t",
        "outputId": "4ccf2865-b6e9-4bd3-8d53-0c347128faa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date       close        high         low        open    volume  \\\n",
              "0  2012-01-10   36.641663   43.760029   41.185009   41.185009  14022646   \n",
              "1  2012-01-10  127.016884  137.000000  132.850006  133.850006    869679   \n",
              "2  2012-01-10  557.239258  597.900024  574.000000  575.099976    201647   \n",
              "3  2012-01-10  239.222260  269.500000  264.500000  268.855011    338040   \n",
              "4  2012-01-10  166.384033  179.399994  173.220001  173.800003   9827090   \n",
              "\n",
              "             tic  day      macd     boll_ub     boll_lb     rsi_30  \\\n",
              "0    ADANIENT.NS    1 -2.567197   44.168874   33.781454  34.120872   \n",
              "1  ADANIPORTS.NS    1 -0.575367  125.065236  106.958192  51.531531   \n",
              "2  APOLLOHOSP.NS    1  1.530863  581.333663  469.007817  53.572836   \n",
              "3  ASIANPAINT.NS    1 -4.970677  250.422287  230.752893  40.195494   \n",
              "4    AXISBANK.NS    1 -5.285489  175.857171  144.370972  44.932195   \n",
              "\n",
              "       cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
              "0 -128.817245  39.740656     39.926283     47.257094   \n",
              "1  192.372520   8.682980    117.216412    127.663853   \n",
              "2    7.650272   5.583804    548.080473    528.434672   \n",
              "3  -53.408598  30.113608    245.870750    261.232402   \n",
              "4  -19.455753  18.677290    168.103823    183.434647   \n",
              "\n",
              "                                            cov_list  \\\n",
              "0  [[0.0008295954814270387, 0.0002227298398581159...   \n",
              "1  [[0.0008295954814270387, 0.0002227298398581159...   \n",
              "2  [[0.0008295954814270387, 0.0002227298398581159...   \n",
              "3  [[0.0008295954814270387, 0.0002227298398581159...   \n",
              "4  [[0.0008295954814270387, 0.0002227298398581159...   \n",
              "\n",
              "                                         return_list  \n",
              "0  tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...  \n",
              "1  tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...  \n",
              "2  tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...  \n",
              "3  tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...  \n",
              "4  tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-76ee1fc4-33e2-4147-97ca-ae342675c30b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>close</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>open</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>cov_list</th>\n",
              "      <th>return_list</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>36.641663</td>\n",
              "      <td>43.760029</td>\n",
              "      <td>41.185009</td>\n",
              "      <td>41.185009</td>\n",
              "      <td>14022646</td>\n",
              "      <td>ADANIENT.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-2.567197</td>\n",
              "      <td>44.168874</td>\n",
              "      <td>33.781454</td>\n",
              "      <td>34.120872</td>\n",
              "      <td>-128.817245</td>\n",
              "      <td>39.740656</td>\n",
              "      <td>39.926283</td>\n",
              "      <td>47.257094</td>\n",
              "      <td>[[0.0008295954814270387, 0.0002227298398581159...</td>\n",
              "      <td>tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>127.016884</td>\n",
              "      <td>137.000000</td>\n",
              "      <td>132.850006</td>\n",
              "      <td>133.850006</td>\n",
              "      <td>869679</td>\n",
              "      <td>ADANIPORTS.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.575367</td>\n",
              "      <td>125.065236</td>\n",
              "      <td>106.958192</td>\n",
              "      <td>51.531531</td>\n",
              "      <td>192.372520</td>\n",
              "      <td>8.682980</td>\n",
              "      <td>117.216412</td>\n",
              "      <td>127.663853</td>\n",
              "      <td>[[0.0008295954814270387, 0.0002227298398581159...</td>\n",
              "      <td>tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>557.239258</td>\n",
              "      <td>597.900024</td>\n",
              "      <td>574.000000</td>\n",
              "      <td>575.099976</td>\n",
              "      <td>201647</td>\n",
              "      <td>APOLLOHOSP.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>1.530863</td>\n",
              "      <td>581.333663</td>\n",
              "      <td>469.007817</td>\n",
              "      <td>53.572836</td>\n",
              "      <td>7.650272</td>\n",
              "      <td>5.583804</td>\n",
              "      <td>548.080473</td>\n",
              "      <td>528.434672</td>\n",
              "      <td>[[0.0008295954814270387, 0.0002227298398581159...</td>\n",
              "      <td>tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>239.222260</td>\n",
              "      <td>269.500000</td>\n",
              "      <td>264.500000</td>\n",
              "      <td>268.855011</td>\n",
              "      <td>338040</td>\n",
              "      <td>ASIANPAINT.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-4.970677</td>\n",
              "      <td>250.422287</td>\n",
              "      <td>230.752893</td>\n",
              "      <td>40.195494</td>\n",
              "      <td>-53.408598</td>\n",
              "      <td>30.113608</td>\n",
              "      <td>245.870750</td>\n",
              "      <td>261.232402</td>\n",
              "      <td>[[0.0008295954814270387, 0.0002227298398581159...</td>\n",
              "      <td>tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-01-10</td>\n",
              "      <td>166.384033</td>\n",
              "      <td>179.399994</td>\n",
              "      <td>173.220001</td>\n",
              "      <td>173.800003</td>\n",
              "      <td>9827090</td>\n",
              "      <td>AXISBANK.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>-5.285489</td>\n",
              "      <td>175.857171</td>\n",
              "      <td>144.370972</td>\n",
              "      <td>44.932195</td>\n",
              "      <td>-19.455753</td>\n",
              "      <td>18.677290</td>\n",
              "      <td>168.103823</td>\n",
              "      <td>183.434647</td>\n",
              "      <td>[[0.0008295954814270387, 0.0002227298398581159...</td>\n",
              "      <td>tic         ADANIENT.NS  ADANIPORTS.NS  APOLLO...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76ee1fc4-33e2-4147-97ca-ae342675c30b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-76ee1fc4-33e2-4147-97ca-ae342675c30b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-76ee1fc4-33e2-4147-97ca-ae342675c30b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b5c4b375-b319-4bd7-a281-e4546129d36a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5c4b375-b319-4bd7-a281-e4546129d36a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b5c4b375-b319-4bd7-a281-e4546129d36a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPkxeRDRYrKO",
        "outputId": "1cb691ac-2720-4af7-8e7d-01e2312bce1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(153220, 18)\n",
            "153220\n"
          ]
        }
      ],
      "source": [
        "print(df.shape)\n",
        "\n",
        "hist_vol=[]\n",
        "for i in range(len(df['return_list'])):\n",
        "  returns = df['return_list'].values[i].std()\n",
        "  hist_vol.append(returns)\n",
        "print(len(hist_vol))\n",
        "\n",
        "hist_vol= np.array(hist_vol)\n",
        "# print(hist_vol.shape)\n",
        "# print(hist_vol)\n",
        "hist_vol= pd.DataFrame(hist_vol, df['date'])\n",
        "# print(hist_vol.shape)\n",
        "# print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UooHj1OgbU4v"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6LcOPKtkquK",
        "outputId": "ce100831-a4d9-45a9-e0d4-d6b3a41c2372"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: shimmy in /usr/local/lib/python3.11/dist-packages (2.0.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=1.0.0a1 in /usr/local/lib/python3.11/dist-packages (from shimmy) (1.1.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (4.13.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium>=1.0.0a1->shimmy) (0.0.4)\n",
            "Requirement already satisfied: stable_baselines3 in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Requirement already satisfied: gymnasium<1.2.0,>=0.29.1 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.1.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (1.26.4)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.6.0+cu124)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.1.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from stable_baselines3) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (4.13.1)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from gymnasium<1.2.0,>=0.29.1->stable_baselines3) (0.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0,>=2.3->stable_baselines3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable_baselines3) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->stable_baselines3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->stable_baselines3) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->stable_baselines3) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0,>=2.3->stable_baselines3) (3.0.2)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.11/dist-packages (from gym) (1.26.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "# %%capture\n",
        "!pip install shimmy\n",
        "!pip install stable_baselines3\n",
        "!pip install gym"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xlfE-VERbU40"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gym.utils import seeding\n",
        "import gym\n",
        "from gym import spaces\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQnmN1qdk88I"
      },
      "source": [
        "## Training data split: 2009-01-01 to 2020-07-01"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b8woqs1gQy4",
        "outputId": "f4c6f62a-74a3-40c6-eb32-5b07040fcb81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(127229, 18)\n"
          ]
        }
      ],
      "source": [
        "TRAIN_START_DATE = '2011-01-01'\n",
        "TRAIN_END_DATE = '2021-12-31'\n",
        "\n",
        "# TRAIN_END_DATE = '2012-12-01'\n",
        "\n",
        "Val_START_DATE = '2022-01-01'\n",
        "VAL_END_DATE =  '2022-12-31'\n",
        "TRADE_START_DATE = '2023-01-01'\n",
        "TRADE_END_DATE = '2025-03-31'\n",
        "# print(df[30:])\n",
        "# hist_vol = hist_vol.reset_index(drop=True)\n",
        "\n",
        "train = data_split(df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "hist_vol_train = hist_vol[TRAIN_START_DATE : TRAIN_END_DATE]\n",
        "\n",
        "val = data_split(df, Val_START_DATE, VAL_END_DATE)\n",
        "hist_vol_val=hist_vol[Val_START_DATE :VAL_END_DATE]\n",
        "\n",
        "full_train = data_split(df, TRAIN_START_DATE, VAL_END_DATE)\n",
        "hist_vol_full_train= hist_vol[TRAIN_START_DATE :VAL_END_DATE]\n",
        "\n",
        "\n",
        "# full_train = data_split(df, TRAIN_START_DATE,TRAIN_END_DATE)\n",
        "# hist_vol_full_train= hist_vol[TRAIN_START_DATE :TRAIN_END_DATE]\n",
        "\n",
        "trade = data_split(df, TRADE_START_DATE,TRADE_END_DATE)\n",
        "hist_vol_trade= hist_vol[TRADE_START_DATE  : TRADE_END_DATE]\n",
        "\n",
        "print(full_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Az9fR5itsMj1",
        "outputId": "b6baf2e3-485c-45a5-8c08-5a11f602c440"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{47}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "values = val.index\n",
        "set(Counter(values).values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO2-gdFopwqd",
        "outputId": "e62dd67c-67e9-4858-cd87-afc13be12a54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ADANIENT.NS', 'ADANIPORTS.NS', 'APOLLOHOSP.NS', 'ASIANPAINT.NS',\n",
              "       'AXISBANK.NS', 'BAJAJ-AUTO.NS', 'BAJAJFINSV.NS', 'BAJFINANCE.NS',\n",
              "       'BHARTIARTL.NS', 'BPCL.NS', 'BRITANNIA.NS', 'CIPLA.NS', 'COALINDIA.NS',\n",
              "       'DIVISLAB.NS', 'DRREDDY.NS', 'EICHERMOT.NS', 'GRASIM.NS', 'HCLTECH.NS',\n",
              "       'HDFCBANK.NS', 'HEROMOTOCO.NS', 'HINDALCO.NS', 'HINDUNILVR.NS',\n",
              "       'ICICIBANK.NS', 'INDUSINDBK.NS', 'INFY.NS', 'ITC.NS', 'JSWSTEEL.NS',\n",
              "       'KOTAKBANK.NS', 'LT.NS', 'M&M.NS', 'MARUTI.NS', 'NESTLEIND.NS',\n",
              "       'NTPC.NS', 'ONGC.NS', 'POWERGRID.NS', 'RELIANCE.NS', 'SBIN.NS',\n",
              "       'SUNPHARMA.NS', 'TATACONSUM.NS', 'TATAMOTORS.NS', 'TATASTEEL.NS',\n",
              "       'TCS.NS', 'TECHM.NS', 'TITAN.NS', 'ULTRACEMCO.NS', 'UPL.NS',\n",
              "       'WIPRO.NS'],\n",
              "      dtype='object', name='tic')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Working Stocks\n",
        "train.loc[0,:]['return_list'].values[0].columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-Hs-Qzzpzv_",
        "outputId": "8084fc91-5f2b-46b8-de06-14e243bb3b61"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "len(train.loc[0,:]['return_list'].values[0].columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RYE3YvyfVMb"
      },
      "source": [
        "Here is the definition of the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "lo5O9o1dUu5C"
      },
      "outputs": [],
      "source": [
        "class StockPortfolioEnv(gym.Env):\n",
        "    \"\"\"A single stock trading environment for OpenAI gym\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        df: DataFrame\n",
        "            input data\n",
        "        stock_dim : int\n",
        "            number of unique stocks\n",
        "        hmax : int\n",
        "            maximum number of shares to trade\n",
        "        initial_amount : int\n",
        "            start money\n",
        "        transaction_cost_pct: float\n",
        "            transaction cost percentage per trade\n",
        "        reward_scaling: float\n",
        "            scaling factor for reward, good for training\n",
        "        state_space: int\n",
        "            the dimension of input features\n",
        "        action_space: int\n",
        "            equals stock dimension\n",
        "        tech_indicator_list: list\n",
        "            a list of technical indicator names\n",
        "        turbulence_threshold: int\n",
        "            a threshold to control risk aversion\n",
        "        day: int\n",
        "            an increment number to control date\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    _sell_stock()\n",
        "        perform sell action based on the sign of the action\n",
        "    _buy_stock()\n",
        "        perform buy action based on the sign of the action\n",
        "    step()\n",
        "        at each step the agent will return actions, then\n",
        "        we will calculate the reward, and return the next observation.\n",
        "    reset()\n",
        "        reset the environment\n",
        "    render()\n",
        "        use render to return other functions\n",
        "    save_asset_memory()\n",
        "        return account value at each time step\n",
        "    save_action_memory()\n",
        "        return actions/positions at each time step\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "\n",
        "    def __init__(self,\n",
        "                df,\n",
        "                stock_dim,\n",
        "                hmax,\n",
        "                initial_amount,\n",
        "                transaction_cost_pct,\n",
        "                reward_scaling,\n",
        "                state_space,\n",
        "                action_space,\n",
        "                tech_indicator_list,\n",
        "                Rebalance=False,\n",
        "                turbulence_threshold=None,\n",
        "                lookback=252,\n",
        "                day = 0, hist_vol = None ):\n",
        "        #super(StockEnv, self).__init__()\n",
        "        #money = 10 , scope = 1\n",
        "        self.day = day\n",
        "        self.lookback=lookback\n",
        "        self.df = df\n",
        "        self.stock_dim = stock_dim\n",
        "        self.hmax = hmax\n",
        "        self.initial_amount = initial_amount\n",
        "        self.transaction_cost_pct = transaction_cost_pct\n",
        "        self.reward_scaling = reward_scaling\n",
        "        self.state_space = state_space\n",
        "        self.action_space = action_space\n",
        "        self.tech_indicator_list = tech_indicator_list\n",
        "        self.rebalance = Rebalance\n",
        "        self.DSR_A = 0.0\n",
        "        self.DSR_B = 0.0\n",
        "        self.Return_queue = deque([0]*50, maxlen=50)\n",
        "        self.hist_vol= hist_vol\n",
        "        # action_space normalization and shape is self.stock_dim\n",
        "        self.action_space = spaces.Box(low = 0, high = 1,shape = (self.action_space,))\n",
        "        # Shape = (34, 30)\n",
        "        # covariance matrix + technical indicators + ESG (4). Ojo, no funciona meter aqui el shape bueno. Esto puede causar problemas.\n",
        "\n",
        "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape = (self.state_space + 1 +len(self.tech_indicator_list), self.state_space))\n",
        "\n",
        "        # load data from a pandas dataframe\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "\n",
        "        self.state = np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "        hist_vollll= self.hist_vol.values[self.day,:]\n",
        "        self.state = np.concatenate([self.state, hist_vollll.reshape(1,-1) ], axis=0)\n",
        "\n",
        "\n",
        "        self.terminal = False\n",
        "        self.turbulence_threshold = turbulence_threshold\n",
        "        # initalize state: inital portfolio return + individual stock return + individual weights\n",
        "        self.portfolio_value = self.initial_amount\n",
        "\n",
        "        # memorize portfolio value each step\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        # memorize portfolio return each step\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        # print(f\" the len of the df is  {len(self.df.index.unique())}  and the current day is :  {self.day } and  if  terminal is  : { self.day >= len(self.df.index.unique()) - 1 }\")\n",
        "\n",
        "        self.terminal = self.day >= len(self.df.index.unique())-1\n",
        "        # print(actions)\n",
        "\n",
        "        if self.terminal:\n",
        "            df = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df.columns = ['daily_return']\n",
        "            # plt.plot(df.daily_return.cumsum(),'r')\n",
        "            # plt.savefig('results/cumulative_reward.png')\n",
        "            # plt.close()\n",
        "\n",
        "            # plt.plot(self.portfolio_return_memory,'r')\n",
        "            # plt.savefig('results/rewards.png')\n",
        "            # plt.close()\n",
        "\n",
        "            print(\"=================================\")\n",
        "            print(\"begin_total_asset:{}\".format(self.asset_memory[0]))\n",
        "            print(\"end_total_asset:{}\".format(self.portfolio_value))\n",
        "\n",
        "            df_daily_return = pd.DataFrame(self.portfolio_return_memory)\n",
        "            df_daily_return.columns = ['daily_return']\n",
        "            if df_daily_return['daily_return'].std() !=0:\n",
        "              sharpe = (252**0.5)*df_daily_return['daily_return'].mean()/ \\\n",
        "                       df_daily_return['daily_return'].std()\n",
        "              print(\"Sharpe: \",sharpe)\n",
        "            print(\"=================================\")\n",
        "\n",
        "            return self.state, self.reward, self.terminal,{}\n",
        "\n",
        "        else:\n",
        "            #print(\"Model actions: \",actions)\n",
        "            # actions are the portfolio weight\n",
        "            # normalize to sum of 1\n",
        "            #if (np.array(actions) - np.array(actions).min()).sum() != 0:\n",
        "            #  norm_actions = (np.array(actions) - np.array(actions).min()) / (np.array(actions) - np.array(actions).min()).sum()\n",
        "            #else:\n",
        "            #  norm_actions = actions\n",
        "            weights = self.softmax_normalization(actions)\n",
        "\n",
        "            ## Repair Mechanism\n",
        "            # weights = self.repair_portfolio(actions, 15, 0.01, 1)\n",
        "            # print('Weights', weights)\n",
        "            # print('Weights',np.sum(weights))\n",
        "            # ## Rebalancing of the Portfolio Weights\n",
        "            # print('Actions', actions)\n",
        "            # weights = self.softmax_normalization(actions)\n",
        "            # print('Weights',weights)\n",
        "            # if self.rebalance == True:\n",
        "            #   if self.actions_memory:\n",
        "            #       w_old = self.actions_memory[-1]\n",
        "            #   else:\n",
        "            #       w_old = np.zeros(self.stock_dim)\n",
        "\n",
        "            #   rebalance_threshold = 0.01\n",
        "            #   del_w = weights - w_old\n",
        "            #   del_w[np.abs(del_w) < rebalance_threshold] = 0\n",
        "            #   new_w = w_old + del_w\n",
        "\n",
        "            #   different_mask = w_old != new_w\n",
        "            #   sum_same = np.sum(new_w[~different_mask])\n",
        "            #   rem_balance = 1 - sum_same\n",
        "\n",
        "            #   different_entries = new_w[different_mask]\n",
        "            #   sum_diff = np.sum(different_entries)\n",
        "            #   if sum_diff != 0:\n",
        "            #       normalized_diff = different_entries / sum_diff\n",
        "            #   else:\n",
        "            #       normalized_diff = different_entries\n",
        "\n",
        "            #   new_w[different_mask] = normalized_diff*rem_balance\n",
        "\n",
        "            #   weights = new_w\n",
        "\n",
        "            #print(\"Weights: \",weights)\n",
        "\n",
        "            #print(\"Weights: \",weights\n",
        "            #print(\"Normalized actions: \", weights)\n",
        "            self.actions_memory.append(weights)\n",
        "            last_day_memory = self.data\n",
        "\n",
        "            #load next state\n",
        "            self.day = self.day +  1\n",
        "            self.data = self.df.loc[self.day,:]\n",
        "            self.covs = self.data['cov_list'].values[0]\n",
        "            self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "            #print(self.state)\n",
        "            hist_volll = self.hist_vol.values[self.day,:]\n",
        "            self.state = np.concatenate([self.state, hist_volll.reshape(1,-1) ], axis=0)\n",
        "\n",
        "            #print(self.state)\n",
        "            portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            self.Return_queue.appendleft(portfolio_return)\n",
        "\n",
        "            #...Weights tbc by investor´s preference\n",
        "            # portfolio_return = sum(((self.data.close.values / last_day_memory.close.values)-1)*weights)\n",
        "            # update portfolio value\n",
        "            if self.rebalance == True:\n",
        "              new_portfolio_value = self.portfolio_value*(1+portfolio_return) - np.sum(self.transaction_cost_pct*self.portfolio_value*del_w)\n",
        "            else:\n",
        "              new_portfolio_value = self.portfolio_value*(1+portfolio_return) - np.sum(self.transaction_cost_pct*self.portfolio_value*weights)\n",
        "\n",
        "            rew = 0\n",
        "            for i in range(self.covs.shape[0]):\n",
        "              for j in range(self.covs.shape[1]):\n",
        "                rew = rew + weights[i]*weights[j]*self.covs[i][j]\n",
        "\n",
        "            #Aqui es donde hay que ponderar el ESG.\n",
        "            self.portfolio_value = new_portfolio_value\n",
        "            old_portfolio_value = self.asset_memory[-1]\n",
        "\n",
        "            # save into memory\n",
        "            self.portfolio_return_memory.append(portfolio_return)\n",
        "            self.date_memory.append(self.data.date.unique()[0])\n",
        "            self.asset_memory.append(new_portfolio_value)\n",
        "            # Calculate Transaction Fee\n",
        "            phi = 0.0025  # 0.25% transaction cost\n",
        "            # # Reshape portfolio_value to match dimensions of other arrays\n",
        "            # portfolio_value_reshaped = np.repeat(self.portfolio_value, len(weights))\n",
        "            transaction_fee = phi * sum(\n",
        "                abs(weights * new_portfolio_value * last_day_memory.close.values / self.data.close.values\n",
        "                    - self.actions_memory[-2] * portfolio_value_reshaped)  # Use portfolio_value_reshaped\n",
        "            )\n",
        "\n",
        "            # the reward is the new portfolio value or end portfolo value\n",
        "            self.reward = new_portfolio_value - old_portfolio_value - transaction_fee\n",
        "            # self.reward = new_portfolio_value - transaction_fee   # normal portfolio return\n",
        "            # self.reward = np.log(new_portfolio_value/ old_portfolio_value)      # log return of portfolio\n",
        "            # self.reward = self.calculate_DSR(new_portfolio_value)             # Differential Sharpe ratio\n",
        "            # self.reward = -((max(self.asset_memory) - new_portfolio_value)/ (max(self.asset_memory) + 1e-7)) * 100          # drawdown ( try to bring the gap between highest and current value to 0)\n",
        "            # self.reward = self.calculate_MDDR(new_portfolio_value)             # MDD with return\n",
        "            # self.reward = -rew*1000\n",
        "            #print(\"Step reward: \", self.reward)\n",
        "            #self.reward = self.reward*self.reward_scaling\n",
        "            # r1 = self.calculate_DSR(new_portfolio_value)\n",
        "            # r2 = np.log(new_portfolio_value/ old_portfolio_value)\n",
        "            # r3 = ((max(self.asset_memory) - new_portfolio_value)/ (max(self.asset_memory) + 1e-7)) * 100\n",
        "            # self.reward = 0.25*r1 + 0.415*r2 - 0.335*r3\n",
        "\n",
        "        return self.state, self.reward, self.terminal, {}\n",
        "\n",
        "    def reset(self):\n",
        "        self.asset_memory = [self.initial_amount]\n",
        "        self.day = 0\n",
        "        self.data = self.df.loc[self.day,:]\n",
        "        # load states\n",
        "        self.covs = self.data['cov_list'].values[0]\n",
        "        self.state =  np.append(np.array(self.covs), [self.data[tech].values.tolist() for tech in self.tech_indicator_list ], axis=0)\n",
        "\n",
        "        hist_voll = self.hist_vol.values[self.day,:]\n",
        "        self.state = np.concatenate([self.state, hist_voll.reshape(1,-1) ], axis=0)\n",
        "\n",
        "        self.portfolio_value = self.initial_amount\n",
        "        #self.cost = 0\n",
        "        #self.trades = 0\n",
        "        self.DSR_A = 0.0\n",
        "        self.DSR_B = 0.0\n",
        "        self.terminal = False\n",
        "        self.portfolio_return_memory = [0]\n",
        "        self.actions_memory=[[1/self.stock_dim]*self.stock_dim]\n",
        "        self.date_memory=[self.data.date.unique()[0]]\n",
        "        return self.state\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        return self.state\n",
        "\n",
        "    def softmax_normalization(self, actions):\n",
        "        numerator = np.exp(actions)\n",
        "        denominator = np.sum(np.exp(actions))\n",
        "        softmax_output = numerator/denominator\n",
        "        return softmax_output\n",
        "\n",
        "\n",
        "    def save_asset_memory(self):\n",
        "        date_list = self.date_memory\n",
        "        portfolio_return = self.portfolio_return_memory\n",
        "        #print(len(date_list))\n",
        "        #print(len(asset_list))\n",
        "        df_account_value = pd.DataFrame({'date':date_list,'daily_return':portfolio_return})\n",
        "        return df_account_value\n",
        "\n",
        "    def save_action_memory(self):\n",
        "        # date and close price length must match actions length\n",
        "        date_list = self.date_memory\n",
        "        df_date = pd.DataFrame(date_list)\n",
        "        df_date.columns = ['date']\n",
        "\n",
        "        action_list = self.actions_memory\n",
        "        df_actions = pd.DataFrame(action_list)\n",
        "        df_actions.columns = self.data.tic.values\n",
        "        df_actions.index = df_date.date\n",
        "        #df_actions = pd.DataFrame({'date':date_list,'actions':action_list})\n",
        "        return df_actions\n",
        "\n",
        "    def _seed(self, seed=None):\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def get_sb_env(self):\n",
        "        e = DummyVecEnv([lambda: self])\n",
        "        obs = e.reset()\n",
        "        return e, obs\n",
        "\n",
        "    def calculate_DSR(self, R):\n",
        "      eta = 0.004\n",
        "      delta_A = R - self.DSR_A\n",
        "      delta_B = R**2 - self.DSR_B\n",
        "      Dt = (self.DSR_B*delta_A - 0.5*self.DSR_A*delta_B) / ((self.DSR_B-self.DSR_A**2)**(3/2) + 1e-6)\n",
        "      self.DSR_A = self.DSR_A + eta*delta_A\n",
        "      self.DSR_B = self.DSR_B + eta*delta_B\n",
        "      return(Dt)\n",
        "\n",
        "    def calculate_MDDR(self, R):\n",
        "      k = 1\n",
        "      a = 3\n",
        "      mdd = ((max(self.asset_memory) - R)/ (max(self.asset_memory) + 1e-7)) * 100\n",
        "      mddr = (1 / (1 + np.exp(-R))) * (-np.exp(mdd) + np.exp(a))\n",
        "      return(mddr)\n",
        "\n",
        "    def repair_portfolio(self, actions, K, l, u):\n",
        "      \"\"\"\n",
        "      Parameters:\n",
        "          actions (numpy array): Raw action vector from DRL agent.\n",
        "          K (int): Maximum number of selected assets (cardinality constraint).\n",
        "          lower_bounds (numpy array): Minimum allowed weights (l_i).\n",
        "          upper_bounds (numpy array): Maximum allowed weights (u_i).\n",
        "\n",
        "      Returns:\n",
        "          numpy array: Adjusted and valid portfolio weights.\n",
        "      \"\"\"\n",
        "\n",
        "      # Step 1: Get indices of Top-K values (sorted in descending order)\n",
        "      top_k_indices = np.argsort(actions)[::-1][:K]  # Get indices of top K largest values\n",
        "\n",
        "      # Step 2: Extract Top-K values using these indices\n",
        "      weights = actions[top_k_indices]\n",
        "      weights = np.maximum(weights, 0)  # Replace negative values with 0\n",
        "      # Step 3: Apply a mathematical operation (Softmax normalization)\n",
        "      sum_weights = np.sum(weights)\n",
        "\n",
        "      # Step 4: Apply a mathematical operation (Repair mechanism)\n",
        "      if sum_weights > 1:\n",
        "          # If sum of weights is greater than 1, reduce values proportionally\n",
        "          modified_values = []\n",
        "          for i in weights:\n",
        "              numerator = (i - 0.01)\n",
        "              denominator = np.sum(weights - l)  # Summation over j\n",
        "              repaired_value = 0.01 + (numerator / denominator) * (1 - len(weights) * 0.01)\n",
        "              modified_values.append(repaired_value)\n",
        "\n",
        "      elif sum_weights < 1:\n",
        "          # If sum of weights is less than 1, increase values proportionally\n",
        "          modified_values = []\n",
        "          for i in weights:\n",
        "              numerator = (1 - i)\n",
        "              denominator = np.sum(u - weights)  # Summation over j\n",
        "              repaired_value = 1 - (numerator / denominator) * (len(weights) * 1 - 1)\n",
        "              modified_values.append(repaired_value)\n",
        "\n",
        "      else:\n",
        "          # If sum of weights is exactly 1, no modification is needed\n",
        "          modified_values = weights\n",
        "\n",
        "      # Convert to NumPy array\n",
        "      modified_values = np.array(modified_values)\n",
        "      modified_values = np.clip(modified_values, 0.01, 1) # Bound on K assets\n",
        "      # Step 4: Create a new array and assign 0 to all positions\n",
        "      result_arr = np.full_like(actions, 0)  # Initialize everything with 0\n",
        "\n",
        "      # Step 5: Assign modified Softmax values to the Top-K indices\n",
        "      result_arr[top_k_indices] = modified_values  # Assign only to top K elements\n",
        "\n",
        "      # Step 6: Identify fixed values (0)\n",
        "      fixed_mask = (result_arr == 0.01)  # Boolean mask where values are exactly 0\n",
        "      fixed_sum = np.sum(result_arr[fixed_mask])  # Sum of fixed values\n",
        "\n",
        "      # Step 7: Compute current sum and required adjustment\n",
        "      total_sum = np.sum(result_arr)\n",
        "      adjustable_sum = total_sum - fixed_sum  # Sum of changeable values\n",
        "      target_sum = 1 - fixed_sum  # Required sum for adjustable values\n",
        "\n",
        "      # Step 8: Rescale only the non-fixed values\n",
        "      result_arr[~fixed_mask] *= (target_sum / adjustable_sum)  # Scale non-fixed values\n",
        "\n",
        "      return result_arr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzD06X0CbU43",
        "outputId": "94a6fa3e-a7fd-4031-f884-e15feb23512c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 47, State Space: 47\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(train.tic.unique())\n",
        "state_space = stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "jyg0_ZuVEVQ5"
      },
      "outputs": [],
      "source": [
        "turbulence_threshold= 0.03\n",
        "env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"transaction_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"Rebalance\":False,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"turbulence_threshold\": turbulence_threshold,\n",
        "    \"hist_vol\": hist_vol_train\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "nUx4CqjJ8QOl"
      },
      "outputs": [],
      "source": [
        "trade_env_kwargs = {\n",
        "    \"hmax\": 100,\n",
        "    \"initial_amount\": 1000000,\n",
        "    \"transaction_cost_pct\": 0.001,\n",
        "    \"state_space\": state_space,\n",
        "    \"stock_dim\": stock_dimension,\n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"Rebalance\":False,\n",
        "    \"action_space\": stock_dimension,\n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"turbulence_threshold\": turbulence_threshold,\n",
        "    \"hist_vol\": hist_vol_trade\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "6kGYVSUSIwwS"
      },
      "outputs": [],
      "source": [
        "# # Uncomment you want results without Transection Cost\n",
        "# env_kwargs = {\n",
        "#     \"hmax\": 100,\n",
        "#     \"initial_amount\": 1000000,\n",
        "#     \"transaction_cost_pct\": 0,\n",
        "#     \"state_space\": state_space,\n",
        "#     \"stock_dim\": stock_dimension,\n",
        "#     \"tech_indicator_list\": INDICATORS,\n",
        "#     \"Rebalance\":False,\n",
        "#     \"action_space\": stock_dimension,\n",
        "#     \"reward_scaling\": 1e-4,\n",
        "# }\n",
        "\n",
        "# trade_env_kwargs = {\n",
        "#     \"hmax\": 100,\n",
        "#     \"initial_amount\": 1000000,\n",
        "#     \"transaction_cost_pct\": 0,\n",
        "#     \"state_space\": state_space,\n",
        "#     \"stock_dim\": stock_dimension,\n",
        "#     \"tech_indicator_list\": INDICATORS,\n",
        "#     \"Rebalance\":True,\n",
        "#     \"action_space\": stock_dimension,\n",
        "#     \"reward_scaling\": 1e-4,\n",
        "# }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlLUzMG327FI",
        "outputId": "44ccc1c7-1cd0-4780-b95a-1b54af5dc0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "e_train_gym = StockPortfolioEnv(df = train, **env_kwargs)\n",
        "env_train, _ = e_train_gym.get_sb_env()\n",
        "\n",
        "e_val_gym = StockPortfolioEnv(df = val, **trade_env_kwargs)\n",
        "env_val, _ = e_val_gym.get_sb_env()\n",
        "\n",
        "e_train_full_gym = StockPortfolioEnv(df = full_train, **env_kwargs)\n",
        "env_full_train, _ = e_train_full_gym.get_sb_env()\n",
        "\n",
        "e_trade_gym = StockPortfolioEnv(df = trade, **trade_env_kwargs)\n",
        "env_trade, _ = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eKIu5UPlPnk"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* ## PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "fh2H3roIEzpS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import  torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import Flatten\n",
        "from scipy.stats import multivariate_normal\n",
        "from torch.autograd import grad\n",
        "\n",
        "class Actor(nn.Module):\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim, num_layers, act_fn, dr):\n",
        "        super(Actor, self).__init__()\n",
        "        self.action_dim = action_dim  # Store action dimension\n",
        "        layers = []\n",
        "\n",
        "        if act_fn == 'relu': activation_fn = nn.ReLU()\n",
        "        if act_fn == 'tanh': activation_fn = nn.Tanh()\n",
        "        if act_fn == 'sigmoid': activation_fn = nn.Sigmoid()\n",
        "\n",
        "        # Add input layer\n",
        "        layers.append(nn.Flatten())\n",
        "        layers.append(nn.Linear(state_dim, hidden_dim))\n",
        "        layers.append(activation_fn)\n",
        "        layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "        # Add hidden layers\n",
        "        for _ in range(num_layers - 2):  # -2 because we already added the input and output layers\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(activation_fn)\n",
        "            layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "        # Add output layer\n",
        "        layers.append(nn.Linear(hidden_dim, action_dim))\n",
        "\n",
        "        # Create the sequential model\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "        logstds_param = nn.Parameter(torch.full((action_dim,), -0.5))\n",
        "        self.register_parameter(\"logstds\", logstds_param)\n",
        "\n",
        "    def forward(self, state):\n",
        "        # print(\" Actor forward ((((((((((((((((((((((((((((((((((((((()))))))))))))))))))))))))))))))))))))))\")\n",
        "        # 🔍 Print debug info to check tensor shapes\n",
        "        # print(\"state :: \", type(state) , state.shape)\n",
        "\n",
        "        x = self.model(torch.tensor(state))\n",
        "        # print(\" x from model:: \", type(x) , x.shape)\n",
        "\n",
        "        means = torch.tanh(x)\n",
        "        stds = torch.clamp(self.logstds.exp(), 1e-3, 0.5)\n",
        "        # cov_mat = torch.diag_embed(stds)\n",
        "        cov_mat = torch.diag_embed(stds) + 1e-6 * torch.eye(self.action_dim) # Add this line\n",
        "        return torch.distributions.MultivariateNormal(means, cov_mat)\n",
        "\n",
        "    # def forward(self, state):\n",
        "    #   x = self.model(state)\n",
        "    #   means = torch.tanh(x)\n",
        "    #   if torch.isnan(means).any() or torch.isinf(means).any():\n",
        "    #     print(\"Warning: NaN detected in means! Clamping values.\")\n",
        "    #     means = torch.clamp(means, -1e3, 1e3)\n",
        "    #   stds = torch.clamp(self.logstds.exp(), 1e-3, 0.5)\n",
        "    #   # cov_mat = torch.diag_embed(stds)\n",
        "    #   cov_mat = torch.diag_embed(stds) + 1e-6 * torch.eye(self.action_dim) # Add this line\n",
        "    #   return torch.distributions.MultivariateNormal(means, cov_mat)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, state_dim,action_dim, hidden_dim, num_layers, act_fn, dr):\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        if act_fn == 'relu': activation_fn = nn.ReLU()\n",
        "        if act_fn == 'tanh': activation_fn = nn.Tanh()\n",
        "        if act_fn == 'sigmoid': activation_fn = nn.Sigmoid()\n",
        "\n",
        "        # Add input layer\n",
        "        hidden_dim = int(hidden_dim)\n",
        "        num_layers = int(num_layers)\n",
        "        action_dim = int(action_dim)\n",
        "        state_dim = int(state_dim)\n",
        "\n",
        "\n",
        "\n",
        "        layers.append(nn.Linear(state_dim + action_dim, hidden_dim))\n",
        "        layers.append(activation_fn)\n",
        "        layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "\n",
        "        # Add hidden layers\n",
        "        for _ in range(num_layers - 2):  # -2 because we already added the input and output layers\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(activation_fn)\n",
        "            layers.append(nn.Dropout(p=dr))\n",
        "\n",
        "        # Add output layer\n",
        "        layers.append(nn.Linear(hidden_dim, 1))\n",
        "\n",
        "        # Create the sequential model\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        state = state.reshape(state.shape[0], -1)\n",
        "        state = torch.FloatTensor(state)\n",
        "        action = torch.FloatTensor(action)\n",
        "        # print(\" Critic forward ((((((((((((((((((((((((((((((((((((((()))))))))))))))))))))))))))))))))))))))\")\n",
        "        # # 🔍 Print debug info to check tensor shapes\n",
        "        # print(\"state critc fwd :: \", type(state) , state.shape)\n",
        "        # print(\"action critic fwd :: \", type(action) , action.shape)\n",
        "\n",
        "        x = torch.cat([state, action], dim=1)\n",
        "        # x = self.model(x)\n",
        "        # return x\n",
        "\n",
        "        # # 🔄 Flatten state if it has more than 2 dimensions (CNN case)\n",
        "        # if state.dim() > 2:\n",
        "        #     state = state.view(state.shape[0], -1)  # Convert to (batch_size, features)\n",
        "\n",
        "        # # 🔄 Ensure action is 2D\n",
        "        # if action.dim() > 2:\n",
        "        #     action = action.view(action.shape[0], -1)  # Convert to (batch_size, action_dim)\n",
        "\n",
        "        # # 🔍 Print final shapes\n",
        "        # # print(f\"State shape after reshape: {state.shape}, Action shape after reshape: {action.shape}\")\n",
        "\n",
        "        # # ✅ Now both state and action are 2D → Safe to concatenate\n",
        "        # x = torch.cat([state, action], dim=1)\n",
        "        # print(\" return  x  critic fwd:: \", x.shape)\n",
        "        # Forward pass through Critic layers\n",
        "        x = self.model(x)\n",
        "        # print(\" return  x  critic fwd after passing to model :: \", x.shape)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class CostNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Neural network for estimating portfolio risk (cost).\n",
        "    \"\"\"\n",
        "    def __init__(self, state_dim, action_dim, hidden_dim,num_layers, act_fn, dr):\n",
        "        super(CostNetwork, self).__init__()\n",
        "\n",
        "        state_dim=int(state_dim)\n",
        "        action_dim=int(action_dim)\n",
        "        hidden_dim=int(hidden_dim)\n",
        "        # print(\"state_dim:\", state_dim)\n",
        "        # print(\"action_dim:\", action_dim)\n",
        "        # print(\"hidden_dim:\", hidden_dim)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(state_dim + action_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, 1)  # Outputs cost estimate\n",
        "        )\n",
        "\n",
        "    def forward(self, state, action):\n",
        "        \"\"\"\n",
        "        Forward pass for the cost network.\n",
        "\n",
        "        Computes:\n",
        "        c_wv(s, a) = E[VaR(s, a)]  (Eq. 19 in the paper)\n",
        "\n",
        "        Args:\n",
        "        - state (torch.Tensor): State tensor with shape [batch_size, *]\n",
        "        - action (torch.Tensor): Action tensor with shape [batch_size, action_dim]\n",
        "\n",
        "        Returns:\n",
        "        - Cost estimation (torch.Tensor)\n",
        "        \"\"\"\n",
        "\n",
        "        # print(\" cost network forward ((((((((((((((((((((((((((((((((((((((()))))))))))))))))))))))))))))))))))))))\")\n",
        "        # 🔍 Print debug info to check tensor shapes\n",
        "        # print(\"state :: \", type(state) , state.shape)\n",
        "        # print(\"action :: \", type(action) , action.shape)\n",
        "        # 🔄 Flatten state if it has more than 2 dimensions\n",
        "        if state.dim() > 2:\n",
        "            state = state.view(state.shape[0], -1)  # Reshape to [batch_size, flattened_features]\n",
        "\n",
        "        # 🔄 Ensure action is 2D\n",
        "        if action.dim() > 2:\n",
        "            action = action.view(action.shape[0], -1)  # Reshape to [batch_size, action_dim]\n",
        "\n",
        "        # 🔍 Print final shapes\n",
        "        # print(f\"State shape after reshape: {state.shape}, Action shape after reshape: {action.shape}\")\n",
        "\n",
        "        # ✅ Now both state and action are 2D → Safe to concatenate\n",
        "        x = torch.cat([state, action], dim=1)\n",
        "        # Forward pass through the Cost network\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "EDNLkFNLFDB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc94b6b7-1b0c-485e-d0fc-1305a342d59d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:90: DeprecationWarning: invalid escape sequence '\\e'\n"
          ]
        }
      ],
      "source": [
        "class PPOagent:\n",
        "  def __init__(self, env, params, eps_clip=0.2):\n",
        "    # Params\n",
        "    self.num_states = env.observation_space.shape[0]*env.observation_space.shape[1]\n",
        "    self.num_actions = env.action_space.shape[0]\n",
        "    self.gamma = params['gamma']\n",
        "    self.env = env\n",
        "    # self.PPO_epochs = int(params['PPO_epochs'])\n",
        "    self.PPO_epochs = 10\n",
        "    self.value_coeff = params['val_coeff']\n",
        "    self.ent_coeff = params['ent_coeff']\n",
        "    self.eps_clip = eps_clip\n",
        "\n",
        "    # constraint params--\n",
        "    self.rho = 0.01\n",
        "    self.violations= 0\n",
        "    self.zeta= env.envs[0].turbulence_threshold\n",
        "    self.lambda_ = torch.tensor(0.01, requires_grad=False).to(device)\n",
        "\n",
        "    # Networks\n",
        "    self.policy = Actor(self.num_states, self.num_actions, int(params['Ahidden_dim']), int(params['Anum_layers']), params['Aact_fn'], params['Adr']).to(device)\n",
        "    self.critic = Critic(self.num_states, self.num_actions, int(params['Chidden_dim']), int(params['Cnum_layers']), params['Cact_fn'], params['Cdr']).to(device)\n",
        "    self.cost_network = CostNetwork(self.num_states, self.num_actions, params['Costhidden_dim'], int (params['Costnum_layers']),params['Costact_fn'], params['Cdr']  ).to(device)\n",
        "    self.cost_target = CostNetwork(self.num_states, self.num_actions, int(params['Costhidden_dim']), int (params['Costnum_layers']),params['Costact_fn'], params['Costdr']).to(device)\n",
        "    self.critic_criterion = nn.MSELoss()\n",
        "    self.cost_criterion = nn.MSELoss()\n",
        "\n",
        "    # Training\n",
        "    self.optimizer = torch.optim.Adam([\n",
        "                        {'params': self.policy.parameters(), 'lr': params['alr']},\n",
        "                        {'params': self.critic.parameters(), 'lr': params['clr']},\n",
        "                        {'params': self.cost_network.parameters(), 'lr': params['costlr']}])\n",
        "\n",
        "\n",
        "    self.actor_optimizer = optim.Adam(self.policy.parameters(), lr=params['alr'])\n",
        "    self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=params['clr'])\n",
        "    self.cost_optimizer = optim.Adam(self.cost_network.parameters(), lr=params['clr'])\n",
        "    self.MseLoss = nn.MSELoss().to(device)\n",
        "\n",
        "\n",
        "  def get_action(self, state):\n",
        "    # state_tensor = torch.FloatTensor(state).to(device)\n",
        "    norm_dists = self.policy(state)\n",
        "    action = torch.tanh(norm_dists.sample())\n",
        "    logs_probs = norm_dists.log_prob(action)\n",
        "    entropy = norm_dists.entropy()\n",
        "    return action, logs_probs, entropy\n",
        "\n",
        "\n",
        "  def calculate_returns(self, rewards, discount_factor):\n",
        "    returns = []\n",
        "    R = 0\n",
        "    for r in reversed(rewards):\n",
        "        R = r + R * discount_factor\n",
        "        returns.insert(0, R)\n",
        "\n",
        "    return torch.tensor(returns)\n",
        "\n",
        "  def VaR(self, states, actions, confidence_level=0.95):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        actions = actions.to(device)\n",
        "        states = states.to(device)  # assume actions is already on the correct device\n",
        "\n",
        "        batch_size = states.shape[0]  # ✅ Do NOT use `.to(device)` here\n",
        "        num_assets = 30\n",
        "\n",
        "        states = states.squeeze(1).to(device)  # [batch_size, 38, 30]\n",
        "        states_n = states  # already squeezed\n",
        "\n",
        "        cov_matrix = states[:, :num_assets, :].to(device)  # [batch_size, 30, 30]\n",
        "        hist_volatility = states_n[:, -1, :].to(device)  # [batch_size, 30]\n",
        "\n",
        "        z_score = torch.tensor(1.645, device=device)  # ✅ place tensor on the same device\n",
        "        individual_VaR = z_score * hist_volatility  # [batch_size, 30]\n",
        "\n",
        "        VaR_portfolio = torch.zeros(batch_size, device=device)  # ✅ directly initialize on device\n",
        "\n",
        "        for i in range(num_assets):\n",
        "            for j in range(num_assets):\n",
        "                VaR_portfolio = VaR_portfolio + (\n",
        "                    actions[:, i] * individual_VaR[:, i] *\n",
        "                    actions[:, j] * individual_VaR[:, j] * cov_matrix[:, i, j]\n",
        "                )\n",
        "\n",
        "        return VaR_portfolio\n",
        "\n",
        "\n",
        "  def compute_cost_target(self, states, actions, next_states ):\n",
        "        \"\"\"\n",
        "        Compute the target cost using the Bellman equation.\n",
        "\n",
        "        Equation (20):\n",
        "        c_{w_v}(s, a) = VaR(s, a) + \\eta (1 - d) c'_{w_v'}(s', a')\n",
        "        \"\"\"\n",
        "\n",
        "        next_actions = self.policy.forward(next_states)  # π'(s')\n",
        "        next_actions = next_actions.sample().detach()\n",
        "\n",
        "        # print(\" in compute_cost_target  next_actions.shape :: \", next_actions.shape)\n",
        "        #print(\" in compute_cost_target  next_actions.shape :: \", next_actions.shape)\n",
        "\n",
        "        next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
        "        # print(\" in compute_cost_target  nect cost .shape  ::  \", next_cost.shape)\n",
        "\n",
        "        cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
        "        # print(\" in compute_cost_target  cost_target.shape :: \", cost_target.shape)\n",
        "        return cost_target\n",
        "\n",
        "\n",
        "  def update_policy(self, states, actions, log_prob_actions, advantages, returns):\n",
        "    old_states = states.detach().to(device)\n",
        "    old_actions = actions.detach().to(device)\n",
        "    old_log_probs = log_prob_actions.detach().to(device)\n",
        "    advantages = advantages.detach().to(device)\n",
        "    returns = returns.detach().to(device)\n",
        "\n",
        "\n",
        "    # print(\"old_states ::\" , old_states.shape)\n",
        "    # print(\"old_actions ::\" , old_actions.shape)\n",
        "    # print(\"old_log_probs ::\" , old_log_probs.shape)\n",
        "    # print(\"advantages ::\" , advantages.shape)\n",
        "    # print(\"returns ::\" , returns.shape)\n",
        "\n",
        "\n",
        "\n",
        "    for _ in range(self.PPO_epochs):\n",
        "      #get new log prob of old actions for all input states\n",
        "      action, log_probs_new, entropy = self.get_action(old_states)\n",
        "      next_state, reward, done, _ = self.env.step(action.detach().numpy())\n",
        "\n",
        "      # print(\"action in loop ::\" , action.shape)\n",
        "      # print(\"log_probs_new in loop::\" , log_probs_new.shape)\n",
        "      # print(\"entropy in loop ::\" , entropy.shape)\n",
        "\n",
        "      value_pred = self.critic.forward(old_states, action)\n",
        "\n",
        "      # print(\"next state in loop :: \" , value_pred.shape)\n",
        "\n",
        "\n",
        "\n",
        "      cost_target = self.compute_cost_target(old_states, old_actions, next_state ).detach()\n",
        "      # print(\"cost_tgt in loop  :: \", cost_target.shape)\n",
        "\n",
        "      # violations --\n",
        "      violations_count = (cost_target > self.zeta).sum().item()  # Count how many elements violate the constraint\n",
        "      print(\" violations ::: \" , violations_count)\n",
        "      # Update the number of violations\n",
        "      self.violations  =  self.violations + violations_count\n",
        "\n",
        "      # C= c(si, ai) − ζ, if c(si, ai) >=  ζ else 0\n",
        "      constraint_penalty = torch.where(\n",
        "          cost_target <= self.zeta,\n",
        "          torch.tensor(0.0, device=cost_target.device, dtype=cost_target.dtype),\n",
        "          cost_target - self.zeta\n",
        "      )\n",
        "      quadratic_penalty = (self.rho / 2) * (constraint_penalty ** 2).mean().clone()\n",
        "      constraint_penalty =(self.lambda_) * constraint_penalty.mean().clone()\n",
        "      final_loss= constraint_penalty + quadratic_penalty\n",
        "\n",
        "\n",
        "      policy_ratio = (log_probs_new - old_log_probs).exp()\n",
        "      policy_loss_1 = policy_ratio * advantages\n",
        "      policy_loss_2 = torch.clamp(policy_ratio, min=1.0 - self.eps_clip, max=1.0 + self.eps_clip) * advantages\n",
        "\n",
        "      policy_loss = - torch.min(policy_loss_1, policy_loss_2).mean()\n",
        "\n",
        "      value_loss = self.MseLoss(self.critic.forward(old_states, action), returns)\n",
        "\n",
        "      loss = policy_loss + self.value_coeff * value_loss - self.ent_coeff * entropy.mean()\n",
        "      loss= -1*loss + final_loss\n",
        "\n",
        "\n",
        "      # cost loss back --\n",
        "\n",
        "      cost_pred = self.cost_network.forward(states, actions)\n",
        "      cost_loss = self.cost_criterion(cost_pred, cost_target)\n",
        "\n",
        "      #critic loss back --\n",
        "\n",
        "      next_actions = self.policy.forward(next_state)  # π'(s')\n",
        "      next_actions = next_actions.sample().detach()\n",
        "      # Q_target = reward  + self.gamma  * self.critic.forward(torch.tensor(next_state), torch.tensor(next_actions))\n",
        "      next_state_tensor = torch.tensor(next_state, dtype=torch.float32).to(device)\n",
        "      next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
        "      # print(\" Q'  forward critic::  and reward type:: \", type(reward) )\n",
        "      Q_target = torch.tensor(reward) + self.gamma * self.critic.forward(next_state_tensor, next_action_tensor)\n",
        "\n",
        "      critic_loss = self.critic_criterion(value_pred, Q_target.detach())\n",
        "\n",
        "\n",
        "\n",
        "      # take gradient step\n",
        "      self.actor_optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      self.actor_optimizer.step()\n",
        "\n",
        "      # take gradient step\n",
        "      # self.policy_optimizer.zero_grad()\n",
        "      # loss.backward()\n",
        "      # self.policy_optimizer.step()\n",
        "\n",
        "      self.critic_optimizer.zero_grad()\n",
        "      critic_loss.backward()\n",
        "      self.critic_optimizer.step()\n",
        "\n",
        "      self.cost_optimizer.zero_grad()\n",
        "      cost_loss.backward()\n",
        "      self.cost_optimizer.step()\n",
        "\n",
        "  def trade(self, val_env, e_val_gym, n_steps):\n",
        "    Reward = []\n",
        "    state = val_env.reset()\n",
        "    if n_steps == None:\n",
        "      n_steps = len(e_val_gym.df.index.unique())\n",
        "    for i in range(n_steps):\n",
        "      state_tensor = torch.FloatTensor(state).to(device)\n",
        "      action, logs_probs, _ = self.get_action(state_tensor)\n",
        "      action = action.cpu()\n",
        "      next_obs, reward, done, _ = val_env.step(action.detach().numpy())\n",
        "      Reward.append(reward)\n",
        "\n",
        "      if i == (n_steps - 2):\n",
        "          account_memory = val_env.env_method(method_name=\"save_asset_memory\")\n",
        "          actions_memory = val_env.env_method(method_name=\"save_action_memory\")\n",
        "\n",
        "      if done[0]:\n",
        "        print(\"hit end!\")\n",
        "        # account_memory = val_env.env_method(method_name=\"save_asset_memory\")\n",
        "        # actions_memory = val_env.env_method(method_name=\"save_action_memory\")\n",
        "        break\n",
        "      state = next_obs\n",
        "\n",
        "    # account_memory = val_env.env_method(method_name=\"save_asset_memory\")\n",
        "    # actions_memory = val_env.env_method(method_name=\"save_action_memory\")\n",
        "    return account_memory, actions_memory, sum(Reward)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WCPMF7ZZL0rQ"
      },
      "outputs": [],
      "source": [
        "#device = 'cpu'\n",
        "# Set the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "1M5fFJNoLRqA"
      },
      "outputs": [],
      "source": [
        "#Calculate the Sharpe ratio\n",
        "#This is our objective for tuning\n",
        "def calculate_sharpe(df):\n",
        "  #df['daily_return'] = df['account_value'].pct_change(1)\n",
        "  if df['daily_return'].std() !=0:\n",
        "    sharpe = (252**0.5)*df['daily_return'].mean()/ \\\n",
        "          df['daily_return'].std()\n",
        "    return sharpe\n",
        "  else:\n",
        "    return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "WyEBcE0PL-jJ"
      },
      "outputs": [],
      "source": [
        "space = {\n",
        "    'Ahidden_dim': hp.quniform('Ahidden_dim', 2, 256,1),\n",
        "    'Anum_layers': hp.quniform('Anum_layers', 1, 8,1),\n",
        "    'Chidden_dim': hp.quniform('Chidden_dim', 2, 256, 1),\n",
        "    'Cnum_layers': hp.quniform('Cnum_layers', 1, 8,1),\n",
        "    'Costhidden_dim': hp.quniform('Costhidden_dim', 2, 256, 1),\n",
        "    'Costnum_layers': hp.quniform('Costnum_layers', 1, 8,1),\n",
        "    'alr': hp.loguniform('alr', -8, -1),\n",
        "    'clr': hp.loguniform('clr', -8, -1),\n",
        "    'costlr': hp.loguniform('costlr', -8, -1),\n",
        "\n",
        "    'gamma': hp.uniform('gamma', 0.9, 0.99),\n",
        "    'PPO_epochs': hp.quniform('PPO_epochs', 5, 50, 5),\n",
        "    'val_coeff': hp.uniform('val_coeff', 0.5, 1.0),\n",
        "    'ent_coeff': hp.uniform('ent_coeff', 0.01, 0.1),\n",
        "    'Aact_fn': hp.choice('Aact_fn', ['relu', 'tanh', 'sigmoid']),\n",
        "    'Adr': hp.uniform('Adr', 0, 0.5),\n",
        "    'Cact_fn': hp.choice('Cact_fn', ['relu', 'tanh', 'sigmoid']),\n",
        "    'Cdr': hp.uniform('Cdr', 0, 0.5),\n",
        "    'Costdr': hp.uniform('Costdr', 0, 0.5),\n",
        "    'Costact_fn': hp.choice('Costact_fn', ['relu', 'tanh', 'sigmoid'])\n",
        "\n",
        "}\n",
        "\n",
        "def objective(params):\n",
        "    print(params)\n",
        "    model = PPOagent(env_train, params)\n",
        "    num_steps = 512\n",
        "    Actions = []\n",
        "    States = []\n",
        "    Rewards = []\n",
        "    Log_probs = []\n",
        "    Values = []\n",
        "\n",
        "    state = env_train.reset()\n",
        "    done = False\n",
        "    episode_reward = 0\n",
        "\n",
        "    for i in range(num_steps):\n",
        "      state_tensor = torch.FloatTensor(state).to(device)\n",
        "\n",
        "\n",
        "\n",
        "      action, logs_probs, entropy = model.get_action(state_tensor)\n",
        "      state_value = model.critic(state_tensor, action).to(device)\n",
        "      States.append(state_tensor)\n",
        "      Values.append(state_value)\n",
        "\n",
        "      action = action.cpu()\n",
        "      next_state, reward, done, _ = env_train.step(action.detach().numpy())\n",
        "\n",
        "      Actions.append(action)\n",
        "      Rewards.append(reward)\n",
        "      Log_probs.append(logs_probs)\n",
        "      state = next_state\n",
        "\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "    actions = torch.cat(Actions).to(device)\n",
        "    states = torch.cat(States).to(device)\n",
        "    values = torch.cat(Values).to(device)\n",
        "    log_prob_old = torch.cat(Log_probs).to(device)\n",
        "    returns = (model.calculate_returns(Rewards, model.gamma)).to(device)\n",
        "    advantages = (returns - values).to(device)\n",
        "    advantages = ((advantages - advantages.mean()) / (advantages.std() + 1e-5)).to(device)\n",
        "\n",
        "    model.update_policy(states, actions, log_prob_old, advantages, returns)\n",
        "\n",
        "    account_memory, actions_memory, rewardd = model.trade(env_val, e_val_gym, None)\n",
        "    print(rewardd)\n",
        "\n",
        "    sharpe = calculate_sharpe(account_memory[0])\n",
        "    return -sharpe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDr1kZIXrnLS",
        "outputId": "18232c32-6ed6-4164-8162-65e7ed9fafdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0+cu124\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCTq53n1MP3m",
        "outputId": "14d3d2ac-7a64-4833-e7cb-f1ef5558e605"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Aact_fn': 'sigmoid', 'Adr': 0.3241205788469952, 'Ahidden_dim': 135.0, 'Anum_layers': 7.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.13219977903530916, 'Chidden_dim': 133.0, 'Cnum_layers': 2.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.1093469078699354, 'Costhidden_dim': 188.0, 'Costnum_layers': 6.0, 'PPO_epochs': 50.0, 'alr': 0.005026871573910045, 'clr': 0.0005067721429633308, 'costlr': 0.0037648676279506553, 'ent_coeff': 0.026693278670735933, 'gamma': 0.9780876184665823, 'val_coeff': 0.7636126944750488}\n",
            "  0%|          | 0/50 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            "  0%|          | 0/50 [00:05<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:57: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  return torch.tensor(returns)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:872892.8324520792\n",
            "Sharpe: \n",
            "0.7625783125689682\n",
            "=================================\n",
            "hit end!\n",
            "[2.2621973e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.47292107748590106, 'Ahidden_dim': 38.0, 'Anum_layers': 6.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.3896814115962629, 'Chidden_dim': 133.0, 'Cnum_layers': 1.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.3379092619063623, 'Costhidden_dim': 19.0, 'Costnum_layers': 1.0, 'PPO_epochs': 40.0, 'alr': 0.3507324145972415, 'clr': 0.17687903765589538, 'costlr': 0.000641959962672039, 'ent_coeff': 0.08245241652106765, 'gamma': 0.9179059463981806, 'val_coeff': 0.5024142023580147}\n",
            "  2%|▏         | 1/50 [00:09<07:56,  9.72s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            "  2%|▏         | 1/50 [00:12<07:56,  9.72s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:838729.722590527\n",
            "Sharpe: \n",
            "0.518764460370446\n",
            "=================================\n",
            "hit end!\n",
            "[2.2113381e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.3234030607996087, 'Ahidden_dim': 148.0, 'Anum_layers': 6.0, 'Cact_fn': 'tanh', 'Cdr': 0.2911838674297453, 'Chidden_dim': 75.0, 'Cnum_layers': 8.0, 'Costact_fn': 'relu', 'Costdr': 0.18244681181102124, 'Costhidden_dim': 44.0, 'Costnum_layers': 5.0, 'PPO_epochs': 20.0, 'alr': 0.0005686430067617193, 'clr': 0.22096300881653866, 'costlr': 0.001734762117575035, 'ent_coeff': 0.039703334973830794, 'gamma': 0.9327859104728524, 'val_coeff': 0.767135163865454}\n",
            "  4%|▍         | 2/50 [00:15<06:02,  7.56s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            "  4%|▍         | 2/50 [00:20<06:02,  7.56s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:866355.0293069895\n",
            "Sharpe: \n",
            "0.6996872530359829\n",
            "=================================\n",
            "hit end!\n",
            "[2.2591979e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.37902554156694385, 'Ahidden_dim': 169.0, 'Anum_layers': 3.0, 'Cact_fn': 'relu', 'Cdr': 0.4110830217616581, 'Chidden_dim': 46.0, 'Cnum_layers': 4.0, 'Costact_fn': 'relu', 'Costdr': 0.31749413641819657, 'Costhidden_dim': 23.0, 'Costnum_layers': 1.0, 'PPO_epochs': 25.0, 'alr': 0.003528025475848866, 'clr': 0.006457868222046496, 'costlr': 0.008908896202075156, 'ent_coeff': 0.0494745397419007, 'gamma': 0.924097573805341, 'val_coeff': 0.5029076501000036}\n",
            "  6%|▌         | 3/50 [00:23<05:58,  7.63s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "  6%|▌         | 3/50 [00:26<05:58,  7.63s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:844602.5318569294\n",
            "Sharpe: \n",
            "0.5531667569629377\n",
            "=================================\n",
            "hit end!\n",
            "[2.22537e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.3653868423748056, 'Ahidden_dim': 81.0, 'Anum_layers': 4.0, 'Cact_fn': 'tanh', 'Cdr': 0.11378470370590793, 'Chidden_dim': 197.0, 'Cnum_layers': 3.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.07966431433596177, 'Costhidden_dim': 129.0, 'Costnum_layers': 3.0, 'PPO_epochs': 45.0, 'alr': 0.2255807538132718, 'clr': 0.07863940957968876, 'costlr': 0.05559443615301191, 'ent_coeff': 0.033614156145590934, 'gamma': 0.9590821028148496, 'val_coeff': 0.8469597189012572}\n",
            "  8%|▊         | 4/50 [00:29<05:18,  6.93s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            "  8%|▊         | 4/50 [00:33<05:18,  6.93s/trial, best loss: -0.7625783125689682]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:883138.8406473844\n",
            "Sharpe: \n",
            "0.8167760760814715\n",
            "=================================\n",
            "hit end!\n",
            "[2.276708e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.2645220560016892, 'Ahidden_dim': 5.0, 'Anum_layers': 5.0, 'Cact_fn': 'relu', 'Cdr': 0.46262060427535867, 'Chidden_dim': 236.0, 'Cnum_layers': 7.0, 'Costact_fn': 'relu', 'Costdr': 0.13215857778049772, 'Costhidden_dim': 64.0, 'Costnum_layers': 4.0, 'PPO_epochs': 25.0, 'alr': 0.004086145886087199, 'clr': 0.22069739893851711, 'costlr': 0.007186427413739048, 'ent_coeff': 0.09271603064682014, 'gamma': 0.9254829714214561, 'val_coeff': 0.6694191765815811}\n",
            " 10%|█         | 5/50 [00:37<05:27,  7.27s/trial, best loss: -0.8167760760814715]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 10%|█         | 5/50 [00:40<05:27,  7.27s/trial, best loss: -0.8167760760814715]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:841105.1456064438\n",
            "Sharpe: \n",
            "0.5260642561294967\n",
            "=================================\n",
            "hit end!\n",
            "[2.2273795e+08]\n",
            " 12%|█▏        | 6/50 [00:44<05:24,  7.38s/trial, best loss: -0.8167760760814715]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Aact_fn': 'relu', 'Adr': 0.43484798337181907, 'Ahidden_dim': 7.0, 'Anum_layers': 3.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.46511555605038307, 'Chidden_dim': 209.0, 'Cnum_layers': 4.0, 'Costact_fn': 'tanh', 'Costdr': 0.3485523460577522, 'Costhidden_dim': 128.0, 'Costnum_layers': 2.0, 'PPO_epochs': 30.0, 'alr': 0.0004958642091982442, 'clr': 0.11077945555113615, 'costlr': 0.03490359913593958, 'ent_coeff': 0.09395651655253555, 'gamma': 0.9644234749476328, 'val_coeff': 0.9112215655595758}\n",
            " violations ::: \n",
            "1\n",
            " 12%|█▏        | 6/50 [00:49<05:24,  7.38s/trial, best loss: -0.8167760760814715]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:877689.1922010196\n",
            "Sharpe: \n",
            "0.7898764242908118\n",
            "=================================\n",
            "hit end!\n",
            "[2.263475e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.40212401464374437, 'Ahidden_dim': 192.0, 'Anum_layers': 2.0, 'Cact_fn': 'tanh', 'Cdr': 0.16013884410623525, 'Chidden_dim': 9.0, 'Cnum_layers': 2.0, 'Costact_fn': 'tanh', 'Costdr': 0.24963176809250465, 'Costhidden_dim': 152.0, 'Costnum_layers': 8.0, 'PPO_epochs': 40.0, 'alr': 0.03910122988886434, 'clr': 0.236829954548374, 'costlr': 0.004732838621995647, 'ent_coeff': 0.022678650575779884, 'gamma': 0.9735582956783164, 'val_coeff': 0.7537551492083526}\n",
            " 14%|█▍        | 7/50 [00:52<05:26,  7.58s/trial, best loss: -0.8167760760814715]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:886703.6276943127\n",
            "Sharpe: \n",
            "0.8319072800469514\n",
            "=================================\n",
            "hit end!\n",
            "[2.2734424e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.09944732672715084, 'Ahidden_dim': 158.0, 'Anum_layers': 5.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.3043923363064086, 'Chidden_dim': 238.0, 'Cnum_layers': 5.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.28524656731664044, 'Costhidden_dim': 93.0, 'Costnum_layers': 4.0, 'PPO_epochs': 25.0, 'alr': 0.07710495429110925, 'clr': 0.1640003501626101, 'costlr': 0.010717412614178815, 'ent_coeff': 0.08160446621111962, 'gamma': 0.9635133870186947, 'val_coeff': 0.7252612526217972}\n",
            " 16%|█▌        | 8/50 [00:59<05:09,  7.36s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 16%|█▌        | 8/50 [01:03<05:09,  7.36s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:869854.5144190907\n",
            "Sharpe: \n",
            "0.7287326930753478\n",
            "=================================\n",
            "hit end!\n",
            "[2.2330966e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.3853113131523138, 'Ahidden_dim': 227.0, 'Anum_layers': 8.0, 'Cact_fn': 'tanh', 'Cdr': 0.2935937349912493, 'Chidden_dim': 41.0, 'Cnum_layers': 1.0, 'Costact_fn': 'tanh', 'Costdr': 0.08059992990822046, 'Costhidden_dim': 253.0, 'Costnum_layers': 1.0, 'PPO_epochs': 30.0, 'alr': 0.00818742007644044, 'clr': 0.03844438232877545, 'costlr': 0.10193514457530074, 'ent_coeff': 0.01722844927963187, 'gamma': 0.9181191153964339, 'val_coeff': 0.7185245099282742}\n",
            " 18%|█▊        | 9/50 [01:08<05:20,  7.83s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 18%|█▊        | 9/50 [01:13<05:20,  7.83s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:830519.5856554566\n",
            "Sharpe: \n",
            "0.45282482354811643\n",
            "=================================\n",
            "hit end!\n",
            "[2.2042571e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.1686570985793598, 'Ahidden_dim': 245.0, 'Anum_layers': 1.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.1474500688910822, 'Chidden_dim': 221.0, 'Cnum_layers': 4.0, 'Costact_fn': 'tanh', 'Costdr': 0.10057116797104282, 'Costhidden_dim': 106.0, 'Costnum_layers': 7.0, 'PPO_epochs': 15.0, 'alr': 0.016910619688876857, 'clr': 0.08980742439317468, 'costlr': 0.1271359202385507, 'ent_coeff': 0.09946501316678398, 'gamma': 0.957307212467019, 'val_coeff': 0.7708236835278963}\n",
            " 20%|██        | 10/50 [01:16<05:15,  7.88s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 20%|██        | 10/50 [01:19<05:15,  7.88s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:844372.9015653364\n",
            "Sharpe: \n",
            "0.5592247728040408\n",
            "=================================\n",
            "hit end!\n",
            "[2.2237547e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.21895554964119768, 'Ahidden_dim': 17.0, 'Anum_layers': 2.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.3301679655647624, 'Chidden_dim': 164.0, 'Cnum_layers': 2.0, 'Costact_fn': 'tanh', 'Costdr': 0.46090807889576824, 'Costhidden_dim': 81.0, 'Costnum_layers': 4.0, 'PPO_epochs': 50.0, 'alr': 0.10278711294478157, 'clr': 0.001554446330867912, 'costlr': 0.04378905474748026, 'ent_coeff': 0.03212478755802551, 'gamma': 0.9077026026696231, 'val_coeff': 0.9380078405738391}\n",
            " 22%|██▏       | 11/50 [01:25<05:24,  8.32s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 22%|██▏       | 11/50 [01:28<05:24,  8.32s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:839709.985312272\n",
            "Sharpe: \n",
            "0.5070745196966623\n",
            "=================================\n",
            "hit end!\n",
            "[2.198979e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.05319006904257745, 'Ahidden_dim': 156.0, 'Anum_layers': 7.0, 'Cact_fn': 'tanh', 'Cdr': 0.3784458257111509, 'Chidden_dim': 176.0, 'Cnum_layers': 7.0, 'Costact_fn': 'relu', 'Costdr': 0.13949881825878613, 'Costhidden_dim': 236.0, 'Costnum_layers': 1.0, 'PPO_epochs': 40.0, 'alr': 0.0007506952132429582, 'clr': 0.0033908999366316257, 'costlr': 0.006082079927628982, 'ent_coeff': 0.06341431693232702, 'gamma': 0.9576785540423449, 'val_coeff': 0.6825211075938309}\n",
            " 24%|██▍       | 12/50 [01:31<04:49,  7.61s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 24%|██▍       | 12/50 [01:36<04:49,  7.61s/trial, best loss: -0.8319072800469514]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:892507.9273144087\n",
            "Sharpe: \n",
            "0.8800923337843639\n",
            "=================================\n",
            "hit end!\n",
            "[2.2900838e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.34279097230586797, 'Ahidden_dim': 115.0, 'Anum_layers': 5.0, 'Cact_fn': 'tanh', 'Cdr': 0.08179257700211834, 'Chidden_dim': 139.0, 'Cnum_layers': 6.0, 'Costact_fn': 'relu', 'Costdr': 0.24808155760173445, 'Costhidden_dim': 212.0, 'Costnum_layers': 7.0, 'PPO_epochs': 15.0, 'alr': 0.013527243533873648, 'clr': 0.011187173205424684, 'costlr': 0.0018543399680713958, 'ent_coeff': 0.05518965833800499, 'gamma': 0.9383595093675922, 'val_coeff': 0.7501013357386768}\n",
            " 26%|██▌       | 13/50 [01:41<05:04,  8.24s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 26%|██▌       | 13/50 [01:45<05:04,  8.24s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:842224.835152609\n",
            "Sharpe: \n",
            "0.5291032932132562\n",
            "=================================\n",
            "hit end!\n",
            "[2.2343192e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.4168957607047693, 'Ahidden_dim': 246.0, 'Anum_layers': 6.0, 'Cact_fn': 'relu', 'Cdr': 0.2015377704095908, 'Chidden_dim': 176.0, 'Cnum_layers': 5.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.034135612418260686, 'Costhidden_dim': 135.0, 'Costnum_layers': 4.0, 'PPO_epochs': 20.0, 'alr': 0.006959120413873, 'clr': 0.02053534734292499, 'costlr': 0.004269184512209411, 'ent_coeff': 0.06704398887122226, 'gamma': 0.9469098322116992, 'val_coeff': 0.7193002801822872}\n",
            " 28%|██▊       | 14/50 [01:48<04:46,  7.97s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 28%|██▊       | 14/50 [01:53<04:46,  7.97s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:844778.3254287271\n",
            "Sharpe: \n",
            "0.5487484983210834\n",
            "=================================\n",
            "hit end!\n",
            "[2.2077726e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.27889880383226817, 'Ahidden_dim': 205.0, 'Anum_layers': 5.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.46764406020244476, 'Chidden_dim': 145.0, 'Cnum_layers': 4.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.1982502741428523, 'Costhidden_dim': 84.0, 'Costnum_layers': 2.0, 'PPO_epochs': 10.0, 'alr': 0.016806059629392855, 'clr': 0.22661229321752507, 'costlr': 0.001377384626091138, 'ent_coeff': 0.06880817250299527, 'gamma': 0.9201184546099339, 'val_coeff': 0.7706800931489128}\n",
            " 30%|███       | 15/50 [01:56<04:37,  7.94s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 30%|███       | 15/50 [02:00<04:37,  7.94s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:859770.4435624287\n",
            "Sharpe: \n",
            "0.6534910082014399\n",
            "=================================\n",
            "hit end!\n",
            "[2.2324542e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.2496018878861448, 'Ahidden_dim': 111.0, 'Anum_layers': 5.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.15803213039171066, 'Chidden_dim': 15.0, 'Cnum_layers': 2.0, 'Costact_fn': 'relu', 'Costdr': 0.039292815535570846, 'Costhidden_dim': 100.0, 'Costnum_layers': 7.0, 'PPO_epochs': 40.0, 'alr': 0.055208879690684894, 'clr': 0.0836998322355585, 'costlr': 0.01998298715034901, 'ent_coeff': 0.03909593488288565, 'gamma': 0.9670260423718355, 'val_coeff': 0.6965636370083746}\n",
            " 32%|███▏      | 16/50 [02:05<04:38,  8.20s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " 32%|███▏      | 16/50 [02:08<04:38,  8.20s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:856334.7200794902\n",
            "Sharpe: \n",
            "0.6200385441502504\n",
            "=================================\n",
            "hit end!\n",
            "[2.2224926e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.381489133220854, 'Ahidden_dim': 50.0, 'Anum_layers': 5.0, 'Cact_fn': 'relu', 'Cdr': 0.16554651132371645, 'Chidden_dim': 77.0, 'Cnum_layers': 2.0, 'Costact_fn': 'tanh', 'Costdr': 0.4954672921708609, 'Costhidden_dim': 171.0, 'Costnum_layers': 6.0, 'PPO_epochs': 40.0, 'alr': 0.0010909007867083295, 'clr': 0.021525634165090974, 'costlr': 0.02130606841327478, 'ent_coeff': 0.06014605236700256, 'gamma': 0.9773985793799449, 'val_coeff': 0.9119116772685536}\n",
            " 34%|███▍      | 17/50 [02:11<04:08,  7.52s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 34%|███▍      | 17/50 [02:15<04:08,  7.52s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:859349.1660851578\n",
            "Sharpe: \n",
            "0.6448798082759072\n",
            "=================================\n",
            "hit end!\n",
            "[2.251414e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.07412994955407687, 'Ahidden_dim': 11.0, 'Anum_layers': 8.0, 'Cact_fn': 'tanh', 'Cdr': 0.19749045864049003, 'Chidden_dim': 230.0, 'Cnum_layers': 2.0, 'Costact_fn': 'tanh', 'Costdr': 0.1204509894339148, 'Costhidden_dim': 111.0, 'Costnum_layers': 4.0, 'PPO_epochs': 20.0, 'alr': 0.0549790004328749, 'clr': 0.0016398434610126306, 'costlr': 0.01248817435009648, 'ent_coeff': 0.03429986875976132, 'gamma': 0.9525229328849771, 'val_coeff': 0.9055515128479272}\n",
            " 36%|███▌      | 18/50 [02:18<03:55,  7.37s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 36%|███▌      | 18/50 [02:22<03:55,  7.37s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:861874.855619494\n",
            "Sharpe: \n",
            "0.6713107071998771\n",
            "=================================\n",
            "hit end!\n",
            "[2.2485208e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.22111484401621145, 'Ahidden_dim': 64.0, 'Anum_layers': 7.0, 'Cact_fn': 'relu', 'Cdr': 0.14381631856749272, 'Chidden_dim': 170.0, 'Cnum_layers': 3.0, 'Costact_fn': 'relu', 'Costdr': 0.41102846626803974, 'Costhidden_dim': 162.0, 'Costnum_layers': 3.0, 'PPO_epochs': 35.0, 'alr': 0.003777586694306078, 'clr': 0.30642783058649076, 'costlr': 0.008529909864046538, 'ent_coeff': 0.028466499456428422, 'gamma': 0.9798241163777094, 'val_coeff': 0.8429605683583059}\n",
            " 38%|███▊      | 19/50 [02:25<03:41,  7.14s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 38%|███▊      | 19/50 [02:29<03:41,  7.14s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:887048.2137400723\n",
            "Sharpe: \n",
            "0.8394135358703833\n",
            "=================================\n",
            "hit end!\n",
            "[2.2618837e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.03829028094551842, 'Ahidden_dim': 85.0, 'Anum_layers': 7.0, 'Cact_fn': 'relu', 'Cdr': 0.040511625956086206, 'Chidden_dim': 105.0, 'Cnum_layers': 8.0, 'Costact_fn': 'relu', 'Costdr': 0.42022762973150113, 'Costhidden_dim': 248.0, 'Costnum_layers': 2.0, 'PPO_epochs': 35.0, 'alr': 0.0014656456402906877, 'clr': 0.0032987898469708705, 'costlr': 0.0011507816646184233, 'ent_coeff': 0.013834762489514124, 'gamma': 0.9880541343986962, 'val_coeff': 0.6192508097817462}\n",
            " 40%|████      | 20/50 [02:32<03:39,  7.32s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 40%|████      | 20/50 [02:36<03:39,  7.32s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:859674.20872132\n",
            "Sharpe: \n",
            "0.664308984999411\n",
            "=================================\n",
            "hit end!\n",
            "[2.2549907e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.13595656708544598, 'Ahidden_dim': 77.0, 'Anum_layers': 7.0, 'Cact_fn': 'relu', 'Cdr': 0.004502571874019312, 'Chidden_dim': 179.0, 'Cnum_layers': 7.0, 'Costact_fn': 'relu', 'Costdr': 0.3879549063448917, 'Costhidden_dim': 215.0, 'Costnum_layers': 3.0, 'PPO_epochs': 35.0, 'alr': 0.0023415298039192347, 'clr': 0.00044472025691256805, 'costlr': 0.000399545260137225, 'ent_coeff': 0.04665467176292072, 'gamma': 0.9887298415306042, 'val_coeff': 0.575658893273147}\n",
            " 42%|████▏     | 21/50 [02:41<03:44,  7.73s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 42%|████▏     | 21/50 [02:44<03:44,  7.73s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:880032.2286711881\n",
            "Sharpe: \n",
            "0.7969740466649389\n",
            "=================================\n",
            "hit end!\n",
            "[2.2733677e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.024154243059955866, 'Ahidden_dim': 182.0, 'Anum_layers': 8.0, 'Cact_fn': 'relu', 'Cdr': 0.23023541252719418, 'Chidden_dim': 106.0, 'Cnum_layers': 3.0, 'Costact_fn': 'relu', 'Costdr': 0.17935574580728603, 'Costhidden_dim': 226.0, 'Costnum_layers': 3.0, 'PPO_epochs': 45.0, 'alr': 0.0009652288698903267, 'clr': 0.001066942969962437, 'costlr': 0.28908707947593093, 'ent_coeff': 0.07711093626428767, 'gamma': 0.9824396590234076, 'val_coeff': 0.9953131166534643}\n",
            " 44%|████▍     | 22/50 [02:48<03:33,  7.62s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 44%|████▍     | 22/50 [02:52<03:33,  7.62s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:881586.1902649538\n",
            "Sharpe: \n",
            "0.811334676927172\n",
            "=================================\n",
            "hit end!\n",
            "[2.275127e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.18488789850347376, 'Ahidden_dim': 105.0, 'Anum_layers': 7.0, 'Cact_fn': 'tanh', 'Cdr': 0.3813000136511133, 'Chidden_dim': 254.0, 'Cnum_layers': 6.0, 'Costact_fn': 'relu', 'Costdr': 0.007179249883953381, 'Costhidden_dim': 187.0, 'Costnum_layers': 2.0, 'PPO_epochs': 35.0, 'alr': 0.00036839409816840886, 'clr': 0.004748613156939573, 'costlr': 0.002631748429646276, 'ent_coeff': 0.06341199714658041, 'gamma': 0.9462858527899447, 'val_coeff': 0.8376013230830308}\n",
            " 46%|████▌     | 23/50 [02:57<03:36,  8.00s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 46%|████▌     | 23/50 [03:01<03:36,  8.00s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:842592.232242696\n",
            "Sharpe: \n",
            "0.5312243558709604\n",
            "=================================\n",
            "hit end!\n",
            "[2.2187326e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.00448901488376427, 'Ahidden_dim': 53.0, 'Anum_layers': 6.0, 'Cact_fn': 'relu', 'Cdr': 0.3573644222724226, 'Chidden_dim': 195.0, 'Cnum_layers': 3.0, 'Costact_fn': 'relu', 'Costdr': 0.497421792463012, 'Costhidden_dim': 237.0, 'Costnum_layers': 3.0, 'PPO_epochs': 45.0, 'alr': 0.0017450410847565088, 'clr': 0.011385636690569443, 'costlr': 0.020821451960414485, 'ent_coeff': 0.047561986662818675, 'gamma': 0.97342264211318, 'val_coeff': 0.8357091658517036}\n",
            " 48%|████▊     | 24/50 [03:06<03:36,  8.34s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 48%|████▊     | 24/50 [03:10<03:36,  8.34s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:843029.2909780913\n",
            "Sharpe: \n",
            "0.5447650793485441\n",
            "=================================\n",
            "hit end!\n",
            "[2.2190493e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.11663387339529287, 'Ahidden_dim': 129.0, 'Anum_layers': 8.0, 'Cact_fn': 'tanh', 'Cdr': 0.2552610664240856, 'Chidden_dim': 163.0, 'Cnum_layers': 6.0, 'Costact_fn': 'relu', 'Costdr': 0.21038198017894025, 'Costhidden_dim': 194.0, 'Costnum_layers': 5.0, 'PPO_epochs': 30.0, 'alr': 0.0007677162542832253, 'clr': 0.0027477828445451285, 'costlr': 0.0007191678255160823, 'ent_coeff': 0.07277918143210255, 'gamma': 0.9392586191824127, 'val_coeff': 0.6331110590388895}\n",
            " 50%|█████     | 25/50 [03:14<03:19,  8.00s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 50%|█████     | 25/50 [03:18<03:19,  8.00s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:828084.047942271\n",
            "Sharpe: \n",
            "0.43042072293325817\n",
            "=================================\n",
            "hit end!\n",
            "[2.1931938e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.053963326512333404, 'Ahidden_dim': 215.0, 'Anum_layers': 7.0, 'Cact_fn': 'relu', 'Cdr': 0.0848096017298273, 'Chidden_dim': 106.0, 'Cnum_layers': 7.0, 'Costact_fn': 'relu', 'Costdr': 0.4154190998806205, 'Costhidden_dim': 160.0, 'Costnum_layers': 1.0, 'PPO_epochs': 35.0, 'alr': 0.0020106836786045468, 'clr': 0.0007021489516326697, 'costlr': 0.006116462381094554, 'ent_coeff': 0.05548931151640703, 'gamma': 0.9522502747143612, 'val_coeff': 0.5419255250736243}\n",
            " 52%|█████▏    | 26/50 [03:23<03:19,  8.32s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 52%|█████▏    | 26/50 [03:26<03:19,  8.32s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:845751.8865301943\n",
            "Sharpe: \n",
            "0.5635428146771769\n",
            "=================================\n",
            "hit end!\n",
            "[2.2304699e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.1644451602782674, 'Ahidden_dim': 65.0, 'Anum_layers': 4.0, 'Cact_fn': 'tanh', 'Cdr': 0.43706707250420124, 'Chidden_dim': 254.0, 'Cnum_layers': 5.0, 'Costact_fn': 'relu', 'Costdr': 0.1455131085626063, 'Costhidden_dim': 206.0, 'Costnum_layers': 2.0, 'PPO_epochs': 45.0, 'alr': 0.027473309726076766, 'clr': 0.006696477136603977, 'costlr': 0.013071386639800762, 'ent_coeff': 0.010129632202963743, 'gamma': 0.9851123014073374, 'val_coeff': 0.8094750030617207}\n",
            " 54%|█████▍    | 27/50 [03:32<03:19,  8.65s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 54%|█████▍    | 27/50 [03:36<03:19,  8.65s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:880253.2935837547\n",
            "Sharpe: \n",
            "0.7979909654877367\n",
            "=================================\n",
            "hit end!\n",
            "[2.2681674e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.30113856718732734, 'Ahidden_dim': 28.0, 'Anum_layers': 6.0, 'Cact_fn': 'relu', 'Cdr': 0.25974975787645116, 'Chidden_dim': 151.0, 'Cnum_layers': 3.0, 'Costact_fn': 'relu', 'Costdr': 0.2871941678699816, 'Costhidden_dim': 176.0, 'Costnum_layers': 5.0, 'PPO_epochs': 50.0, 'alr': 0.003670487454345124, 'clr': 0.04323675678213453, 'costlr': 0.0035737673422994057, 'ent_coeff': 0.02840293418609416, 'gamma': 0.9705327764993812, 'val_coeff': 0.9918330482964844}\n",
            " 56%|█████▌    | 28/50 [03:39<03:00,  8.22s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 56%|█████▌    | 28/50 [03:43<03:00,  8.22s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:850769.6690314991\n",
            "Sharpe: \n",
            "0.5995480768221556\n",
            "=================================\n",
            "hit end!\n",
            "[2.2363725e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.2166096159885391, 'Ahidden_dim': 141.0, 'Anum_layers': 7.0, 'Cact_fn': 'tanh', 'Cdr': 0.010466760479416304, 'Chidden_dim': 118.0, 'Cnum_layers': 8.0, 'Costact_fn': 'relu', 'Costdr': 0.37471129879334963, 'Costhidden_dim': 230.0, 'Costnum_layers': 3.0, 'PPO_epochs': 35.0, 'alr': 0.0003857567435374549, 'clr': 0.0007096657987156593, 'costlr': 0.0739548245791528, 'ent_coeff': 0.04108954241607278, 'gamma': 0.980782032590796, 'val_coeff': 0.6601211908996809}\n",
            " 58%|█████▊    | 29/50 [03:47<02:47,  7.97s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 58%|█████▊    | 29/50 [03:50<02:47,  7.97s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:869264.5053462073\n",
            "Sharpe: \n",
            "0.7263165474376765\n",
            "=================================\n",
            "hit end!\n",
            "[2.2587474e+08]\n",
            " 60%|██████    | 30/50 [03:56<02:45,  8.26s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Aact_fn': 'sigmoid', 'Adr': 0.4814644364473647, 'Ahidden_dim': 97.0, 'Anum_layers': 8.0, 'Cact_fn': 'tanh', 'Cdr': 0.3423356114570213, 'Chidden_dim': 180.0, 'Cnum_layers': 6.0, 'Costact_fn': 'relu', 'Costdr': 0.22060642071192244, 'Costhidden_dim': 147.0, 'Costnum_layers': 2.0, 'PPO_epochs': 40.0, 'alr': 0.007019343763931229, 'clr': 0.3491258138867833, 'costlr': 0.24278662948817303, 'ent_coeff': 0.022340236496607744, 'gamma': 0.9013501498911909, 'val_coeff': 0.800091429288754}\n",
            " violations ::: \n",
            "0\n",
            " 60%|██████    | 30/50 [04:00<02:45,  8.26s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:879037.5534858562\n",
            "Sharpe: \n",
            "0.7918805234565961\n",
            "=================================\n",
            "hit end!\n",
            "[2.2667301e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.21326682277810155, 'Ahidden_dim': 121.0, 'Anum_layers': 6.0, 'Cact_fn': 'relu', 'Cdr': 0.21667092473251512, 'Chidden_dim': 124.0, 'Cnum_layers': 1.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.15468127712000773, 'Costhidden_dim': 255.0, 'Costnum_layers': 1.0, 'PPO_epochs': 50.0, 'alr': 0.0025572342307846217, 'clr': 0.0025503719545758867, 'costlr': 0.002591138881068579, 'ent_coeff': 0.0884447620484409, 'gamma': 0.9581022342353276, 'val_coeff': 0.8748722584089157}\n",
            " 62%|██████▏   | 31/50 [04:04<02:34,  8.15s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 62%|██████▏   | 31/50 [04:07<02:34,  8.15s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:851785.5409905588\n",
            "Sharpe: \n",
            "0.5955249550459483\n",
            "=================================\n",
            "hit end!\n",
            "[2.2197306e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.08136929994816228, 'Ahidden_dim': 164.0, 'Anum_layers': 7.0, 'Cact_fn': 'tanh', 'Cdr': 0.4954358375440171, 'Chidden_dim': 81.0, 'Cnum_layers': 5.0, 'Costact_fn': 'relu', 'Costdr': 0.4563711257532941, 'Costhidden_dim': 3.0, 'Costnum_layers': 1.0, 'PPO_epochs': 30.0, 'alr': 0.0007755789744154422, 'clr': 0.019221567916872857, 'costlr': 0.0008363261027493654, 'ent_coeff': 0.06064355813562899, 'gamma': 0.9392065438162083, 'val_coeff': 0.9575189220227637}\n",
            " 64%|██████▍   | 32/50 [04:11<02:22,  7.92s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 64%|██████▍   | 32/50 [04:14<02:22,  7.92s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:880361.4098824718\n",
            "Sharpe: \n",
            "0.7902201514280235\n",
            "=================================\n",
            "hit end!\n",
            "[2.2745573e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.11912816078487788, 'Ahidden_dim': 144.0, 'Anum_layers': 4.0, 'Cact_fn': 'relu', 'Cdr': 0.10914297872004798, 'Chidden_dim': 203.0, 'Cnum_layers': 3.0, 'Costact_fn': 'relu', 'Costdr': 0.301244089290744, 'Costhidden_dim': 194.0, 'Costnum_layers': 6.0, 'PPO_epochs': 40.0, 'alr': 0.0013127811135331922, 'clr': 0.04704057280546318, 'costlr': 0.00044281775019075796, 'ent_coeff': 0.052186026200085375, 'gamma': 0.9785085389886231, 'val_coeff': 0.5876847810681975}\n",
            " 66%|██████▌   | 33/50 [04:19<02:16,  8.02s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 66%|██████▌   | 33/50 [04:24<02:16,  8.02s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:858795.5471070705\n",
            "Sharpe: \n",
            "0.6407608556985657\n",
            "=================================\n",
            "hit end!\n",
            "[2.2529792e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.0031727475322377297, 'Ahidden_dim': 39.0, 'Anum_layers': 6.0, 'Cact_fn': 'tanh', 'Cdr': 0.4054107209135403, 'Chidden_dim': 164.0, 'Cnum_layers': 1.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.3354388008084854, 'Costhidden_dim': 58.0, 'Costnum_layers': 5.0, 'PPO_epochs': 45.0, 'alr': 0.0051267049580492295, 'clr': 0.00663881047940142, 'costlr': 0.006413485908465571, 'ent_coeff': 0.04383294208069613, 'gamma': 0.9313202715195267, 'val_coeff': 0.8736524819081819}\n",
            " 68%|██████▊   | 34/50 [04:28<02:09,  8.09s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 68%|██████▊   | 34/50 [04:31<02:09,  8.09s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:875738.9789339314\n",
            "Sharpe: \n",
            "0.7809531978378624\n",
            "=================================\n",
            "hit end!\n",
            "[2.2652296e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.30682940421402033, 'Ahidden_dim': 96.0, 'Anum_layers': 3.0, 'Cact_fn': 'relu', 'Cdr': 0.049726389949970154, 'Chidden_dim': 193.0, 'Cnum_layers': 7.0, 'Costact_fn': 'relu', 'Costdr': 0.17124519679037073, 'Costhidden_dim': 33.0, 'Costnum_layers': 3.0, 'PPO_epochs': 25.0, 'alr': 0.0005158679640389777, 'clr': 0.0016690132533975928, 'costlr': 0.026083353929251814, 'ent_coeff': 0.07343079562086786, 'gamma': 0.9684597688516442, 'val_coeff': 0.8033154447782831}\n",
            " 70%|███████   | 35/50 [04:35<01:57,  7.86s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " 70%|███████   | 35/50 [04:38<01:57,  7.86s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:865209.0833034955\n",
            "Sharpe: \n",
            "0.6916657119846588\n",
            "=================================\n",
            "hit end!\n",
            "[2.2437237e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.45416712193190034, 'Ahidden_dim': 192.0, 'Anum_layers': 7.0, 'Cact_fn': 'tanh', 'Cdr': 0.2749272409237608, 'Chidden_dim': 210.0, 'Cnum_layers': 4.0, 'Costact_fn': 'relu', 'Costdr': 0.04615867284125548, 'Costhidden_dim': 165.0, 'Costnum_layers': 1.0, 'PPO_epochs': 5.0, 'alr': 0.246304749924112, 'clr': 0.015591634899443518, 'costlr': 0.014488714605481854, 'ent_coeff': 0.037728722227422046, 'gamma': 0.9522146923813087, 'val_coeff': 0.5276860162090399}\n",
            " 72%|███████▏  | 36/50 [04:41<01:44,  7.49s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations ::: \n",
            "1\n",
            " 72%|███████▏  | 36/50 [04:46<01:44,  7.49s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:853144.143537551\n",
            "Sharpe: \n",
            "0.601831306224786\n",
            "=================================\n",
            "hit end!\n",
            "[2.2242387e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.24022294740662517, 'Ahidden_dim': 175.0, 'Anum_layers': 8.0, 'Cact_fn': 'relu', 'Cdr': 0.3136306729510787, 'Chidden_dim': 90.0, 'Cnum_layers': 8.0, 'Costact_fn': 'relu', 'Costdr': 0.26773188335533543, 'Costhidden_dim': 141.0, 'Costnum_layers': 2.0, 'PPO_epochs': 30.0, 'alr': 0.0026693340355279957, 'clr': 0.004429127238702639, 'costlr': 0.0027650246756467834, 'ent_coeff': 0.0860780739658362, 'gamma': 0.9754712442824166, 'val_coeff': 0.6794064088949686}\n",
            " 74%|███████▍  | 37/50 [04:51<01:44,  8.08s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " 74%|███████▍  | 37/50 [04:55<01:44,  8.08s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:843176.0465954454\n",
            "Sharpe: \n",
            "0.5389320288968363\n",
            "=================================\n",
            "hit end!\n",
            "[2.2298925e+08]\n",
            " 76%|███████▌  | 38/50 [04:59<01:36,  8.06s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Aact_fn': 'relu', 'Adr': 0.14398784649310198, 'Ahidden_dim': 69.0, 'Anum_layers': 6.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.38017815223497764, 'Chidden_dim': 129.0, 'Cnum_layers': 3.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.0004171974985628657, 'Costhidden_dim': 120.0, 'Costnum_layers': 3.0, 'PPO_epochs': 45.0, 'alr': 0.009885397676250168, 'clr': 0.0003381082511567805, 'costlr': 0.007436935067782817, 'ent_coeff': 0.024008111363455938, 'gamma': 0.9655050437016424, 'val_coeff': 0.6313276082107493}\n",
            " violations ::: \n",
            "1\n",
            " 76%|███████▌  | 38/50 [05:02<01:36,  8.06s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:817905.8492271116\n",
            "Sharpe: \n",
            "0.36562986051671814\n",
            "=================================\n",
            "hit end!\n",
            "[2.1871003e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.33681504175407023, 'Ahidden_dim': 155.0, 'Anum_layers': 4.0, 'Cact_fn': 'tanh', 'Cdr': 0.4164586249563645, 'Chidden_dim': 223.0, 'Cnum_layers': 4.0, 'Costact_fn': 'relu', 'Costdr': 0.08831738947623452, 'Costhidden_dim': 181.0, 'Costnum_layers': 1.0, 'PPO_epochs': 40.0, 'alr': 0.0050855351658645066, 'clr': 0.3653309006905451, 'costlr': 0.03840688506696176, 'ent_coeff': 0.017613970243967533, 'gamma': 0.962317253929928, 'val_coeff': 0.8629570531713908}\n",
            " 78%|███████▊  | 39/50 [05:06<01:24,  7.67s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " 78%|███████▊  | 39/50 [05:09<01:24,  7.67s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:872428.4752400889\n",
            "Sharpe: \n",
            "0.7446823108109517\n",
            "=================================\n",
            "hit end!\n",
            "[2.2677456e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.1847753298173017, 'Ahidden_dim': 131.0, 'Anum_layers': 8.0, 'Cact_fn': 'relu', 'Cdr': 0.1827542891361897, 'Chidden_dim': 52.0, 'Cnum_layers': 7.0, 'Costact_fn': 'tanh', 'Costdr': 0.35882546933147574, 'Costhidden_dim': 204.0, 'Costnum_layers': 4.0, 'PPO_epochs': 25.0, 'alr': 0.026416465303715532, 'clr': 0.15215028370320235, 'costlr': 0.15878612568906228, 'ent_coeff': 0.0799264202153017, 'gamma': 0.9328900407545841, 'val_coeff': 0.6996599018909796}\n",
            " 80%|████████  | 40/50 [05:14<01:19,  7.91s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " 80%|████████  | 40/50 [05:18<01:19,  7.91s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:851255.5402360081\n",
            "Sharpe: \n",
            "0.6005967673806942\n",
            "=================================\n",
            "hit end!\n",
            "[2.233294e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.06480036563049023, 'Ahidden_dim': 26.0, 'Anum_layers': 2.0, 'Cact_fn': 'tanh', 'Cdr': 0.12936728648768828, 'Chidden_dim': 153.0, 'Cnum_layers': 5.0, 'Costact_fn': 'relu', 'Costdr': 0.22957793357377457, 'Costhidden_dim': 242.0, 'Costnum_layers': 2.0, 'PPO_epochs': 50.0, 'alr': 0.0031062145941959385, 'clr': 0.030659863088941804, 'costlr': 0.009214063892581122, 'ent_coeff': 0.052390944007989035, 'gamma': 0.9600950869204277, 'val_coeff': 0.7807850584774108}\n",
            " 82%|████████▏ | 41/50 [05:21<01:08,  7.65s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " 82%|████████▏ | 41/50 [05:25<01:08,  7.65s/trial, best loss: -0.8800923337843639]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:898420.6474906552\n",
            "Sharpe: \n",
            "0.9275925440937247\n",
            "=================================\n",
            "hit end!\n",
            "[2.3103158e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.06307886263543938, 'Ahidden_dim': 236.0, 'Anum_layers': 2.0, 'Cact_fn': 'tanh', 'Cdr': 0.49578220143364465, 'Chidden_dim': 243.0, 'Cnum_layers': 6.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.2328134778627613, 'Costhidden_dim': 240.0, 'Costnum_layers': 8.0, 'PPO_epochs': 50.0, 'alr': 0.00044589564678289376, 'clr': 0.033195284576825405, 'costlr': 0.0017160569440880153, 'ent_coeff': 0.06453685732586678, 'gamma': 0.955181407381568, 'val_coeff': 0.7366834833556547}\n",
            " 84%|████████▍ | 42/50 [05:29<01:00,  7.62s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " 84%|████████▍ | 42/50 [05:32<01:00,  7.62s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:877102.3433139422\n",
            "Sharpe: \n",
            "0.7659766452322465\n",
            "=================================\n",
            "hit end!\n",
            "[2.2520379e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.09167715237700624, 'Ahidden_dim': 209.0, 'Anum_layers': 1.0, 'Cact_fn': 'tanh', 'Cdr': 0.10366020507295554, 'Chidden_dim': 154.0, 'Cnum_layers': 5.0, 'Costact_fn': 'tanh', 'Costdr': 0.06417408738168762, 'Costhidden_dim': 221.0, 'Costnum_layers': 1.0, 'PPO_epochs': 45.0, 'alr': 0.0006307374557838481, 'clr': 0.009214955766907052, 'costlr': 0.005022049021160749, 'ent_coeff': 0.051912514030726234, 'gamma': 0.9420460149707713, 'val_coeff': 0.7851299120548124}\n",
            " 86%|████████▌ | 43/50 [05:39<00:57,  8.28s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " 86%|████████▌ | 43/50 [05:42<00:57,  8.28s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:894021.7654501856\n",
            "Sharpe: \n",
            "0.8700709129016648\n",
            "=================================\n",
            "hit end!\n",
            "[2.3007986e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.03389577239357504, 'Ahidden_dim': 255.0, 'Anum_layers': 3.0, 'Cact_fn': 'tanh', 'Cdr': 0.23224599740723187, 'Chidden_dim': 61.0, 'Cnum_layers': 7.0, 'Costact_fn': 'relu', 'Costdr': 0.11098588346723373, 'Costhidden_dim': 245.0, 'Costnum_layers': 2.0, 'PPO_epochs': 50.0, 'alr': 0.013117907356735558, 'clr': 0.06273254210826128, 'costlr': 0.05898007358521277, 'ent_coeff': 0.09447001017120288, 'gamma': 0.9259331580011981, 'val_coeff': 0.5993824189733821}\n",
            " 88%|████████▊ | 44/50 [05:45<00:47,  7.86s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " 88%|████████▊ | 44/50 [05:50<00:47,  7.86s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:852269.9489587676\n",
            "Sharpe: \n",
            "0.6003622095890317\n",
            "=================================\n",
            "hit end!\n",
            "[2.2421442e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.017787929038546993, 'Ahidden_dim': 192.0, 'Anum_layers': 3.0, 'Cact_fn': 'tanh', 'Cdr': 0.3593546679984997, 'Chidden_dim': 188.0, 'Cnum_layers': 8.0, 'Costact_fn': 'relu', 'Costdr': 0.31241345056951253, 'Costhidden_dim': 254.0, 'Costnum_layers': 2.0, 'PPO_epochs': 50.0, 'alr': 0.0011305309222913254, 'clr': 0.02933998613633101, 'costlr': 0.0035580657819749293, 'ent_coeff': 0.05832141636560958, 'gamma': 0.9612382159152294, 'val_coeff': 0.6544436401831679}\n",
            " 90%|█████████ | 45/50 [05:53<00:39,  7.86s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " 90%|█████████ | 45/50 [05:57<00:39,  7.86s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:877753.1889071495\n",
            "Sharpe: \n",
            "0.7858027555022303\n",
            "=================================\n",
            "hit end!\n",
            "[2.2663611e+08]\n",
            "                                                                                  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Aact_fn': 'sigmoid', 'Adr': 0.10598965419707754, 'Ahidden_dim': 151.0, 'Anum_layers': 2.0, 'Cact_fn': 'tanh', 'Cdr': 0.03984552564434608, 'Chidden_dim': 27.0, 'Cnum_layers': 6.0, 'Costact_fn': 'tanh', 'Costdr': 0.13952884473792337, 'Costhidden_dim': 231.0, 'Costnum_layers': 1.0, 'PPO_epochs': 15.0, 'alr': 0.0007918147406022531, 'clr': 0.12066742280611496, 'costlr': 0.015427269753709867, 'ent_coeff': 0.0711516469905413, 'gamma': 0.9087694525926583, 'val_coeff': 0.6947360062838909}\n",
            " violations ::: \n",
            "0\n",
            " 92%|█████████▏| 46/50 [06:05<00:31,  7.85s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:841695.0044823284\n",
            "Sharpe: \n",
            "0.5317358142773084\n",
            "=================================\n",
            "hit end!\n",
            "[2.2353965e+08]\n",
            "{'Aact_fn': 'tanh', 'Adr': 0.1622224066883894, 'Ahidden_dim': 26.0, 'Anum_layers': 1.0, 'Cact_fn': 'sigmoid', 'Cdr': 0.12530836443803742, 'Chidden_dim': 138.0, 'Cnum_layers': 5.0, 'Costact_fn': 'sigmoid', 'Costdr': 0.26519058859873856, 'Costhidden_dim': 200.0, 'Costnum_layers': 1.0, 'PPO_epochs': 45.0, 'alr': 0.0016147661161936655, 'clr': 0.05761074676270496, 'costlr': 0.009760988126160287, 'ent_coeff': 0.09809673414768885, 'gamma': 0.9485107942516954, 'val_coeff': 0.7441186921425519}\n",
            " 94%|█████████▍| 47/50 [06:09<00:23,  7.91s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " 94%|█████████▍| 47/50 [06:12<00:23,  7.91s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:837885.0967945751\n",
            "Sharpe: \n",
            "0.49896097612301626\n",
            "=================================\n",
            "hit end!\n",
            "[2.1974589e+08]\n",
            "{'Aact_fn': 'sigmoid', 'Adr': 0.13379860719986741, 'Ahidden_dim': 120.0, 'Anum_layers': 2.0, 'Cact_fn': 'tanh', 'Cdr': 0.4423151005009963, 'Chidden_dim': 211.0, 'Cnum_layers': 4.0, 'Costact_fn': 'relu', 'Costdr': 0.18888184681366904, 'Costhidden_dim': 124.0, 'Costnum_layers': 5.0, 'PPO_epochs': 40.0, 'alr': 0.12123420394587027, 'clr': 0.0257811152405657, 'costlr': 0.08485145332591788, 'ent_coeff': 0.08687266196653003, 'gamma': 0.9336714487567987, 'val_coeff': 0.5645870252713818}\n",
            " 96%|█████████▌| 48/50 [06:17<00:15,  7.80s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " 96%|█████████▌| 48/50 [06:20<00:15,  7.80s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            " violations ::: \n",
            "1\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:886016.776798709\n",
            "Sharpe: \n",
            "0.8337459999224861\n",
            "=================================\n",
            "hit end!\n",
            "[2.2886163e+08]\n",
            "{'Aact_fn': 'relu', 'Adr': 0.05649737481932736, 'Ahidden_dim': 2.0, 'Anum_layers': 4.0, 'Cact_fn': 'tanh', 'Cdr': 0.3179091385026155, 'Chidden_dim': 92.0, 'Cnum_layers': 7.0, 'Costact_fn': 'tanh', 'Costdr': 0.23107470496832477, 'Costhidden_dim': 69.0, 'Costnum_layers': 4.0, 'PPO_epochs': 5.0, 'alr': 0.02116783510994095, 'clr': 0.015742317903241945, 'costlr': 0.02744008021438653, 'ent_coeff': 0.0766420865197262, 'gamma': 0.9711755334766529, 'val_coeff': 0.7168914437962098}\n",
            " 98%|█████████▊| 49/50 [06:24<00:07,  7.61s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " 98%|█████████▊| 49/50 [06:28<00:07,  7.61s/trial, best loss: -0.9275925440937247]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            " violations ::: \n",
            "0\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:865212.2391142743\n",
            "Sharpe: \n",
            "0.6920900317004034\n",
            "=================================\n",
            "hit end!\n",
            "[2.2519674e+08]\n",
            "100%|██████████| 50/50 [06:31<00:00,  7.83s/trial, best loss: -0.9275925440937247]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n",
            "\n"
          ]
        }
      ],
      "source": [
        "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=50, trials=Trials())  #max_evals = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4I7TxxrmMT3g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bdd2e36-337a-491b-fc96-f093bd14bc5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Aact_fn': 'sigmoid',\n",
              " 'Adr': 0.06480036563049023,\n",
              " 'Ahidden_dim': 26.0,\n",
              " 'Anum_layers': 2.0,\n",
              " 'Cact_fn': 'tanh',\n",
              " 'Cdr': 0.12936728648768828,\n",
              " 'Chidden_dim': 153.0,\n",
              " 'Cnum_layers': 5.0,\n",
              " 'Costact_fn': 0,\n",
              " 'Costdr': 0.22957793357377457,\n",
              " 'Costhidden_dim': 242.0,\n",
              " 'Costnum_layers': 2.0,\n",
              " 'PPO_epochs': 50.0,\n",
              " 'alr': 0.0031062145941959385,\n",
              " 'clr': 0.030659863088941804,\n",
              " 'costlr': 0.009214063892581122,\n",
              " 'ent_coeff': 0.052390944007989035,\n",
              " 'gamma': 0.9600950869204277,\n",
              " 'val_coeff': 0.7807850584774108}"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best['Aact_fn'] = ['relu', 'tanh', 'sigmoid'][best['Aact_fn']]\n",
        "best['Cact_fn'] = ['relu', 'tanh', 'sigmoid'][best['Cact_fn']]\n",
        "best = {k: v.item() if isinstance(v, (np.floating, np.integer)) else v for k, v in best.items()}\n",
        "best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dUUYrYTDBoru"
      },
      "outputs": [],
      "source": [
        "# best = {'Aact_fn': 'tanh',\n",
        "#  'Adr': 0.005606730178782146,\n",
        "#  'Ahidden_dim': 110.0,\n",
        "#  'Anum_layers': 8.0,\n",
        "#  'Cact_fn': 'tanh',\n",
        "#  'Cdr': 0.19701572801150505,\n",
        "#  'Chidden_dim': 208.0,\n",
        "#  'Cnum_layers': 2.0,\n",
        "#  'Costact_fn': 2,\n",
        "#  'Costdr': 0.20250081379537282,\n",
        "#  'Costhidden_dim': 8.0,\n",
        "#  'Costnum_layers': 5.0,\n",
        "#  'PPO_epochs': 10.0,\n",
        "#  'alr': 0.0003383195571517458,\n",
        "#  'clr': 0.01752598526985451,\n",
        "#  'costlr': 0.015521085366598176,\n",
        "#  'ent_coeff': 0.07534438311556774,\n",
        "#  'gamma': 0.952657004986277,\n",
        "#  'val_coeff': 0.9939667210432088}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Rkg_HQ46MYt1"
      },
      "outputs": [],
      "source": [
        "agent = PPOagent(env_full_train, best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3xkcGuPF4cU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "164aa4d7-9ea4-4e7e-fc5b-62471dd47ea3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-33-97eed72f0eb9>:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  x = self.model(torch.tensor(state))\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:647872.6343169255\n",
            "Sharpe:  1.3588472142963606\n",
            "=================================\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-34-a974e389e65b>:103: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_cost = self.cost_target.forward(torch.tensor(next_states) ,torch.tensor(next_actions))  # c'_wv'(s', a')\n",
            "<ipython-input-34-a974e389e65b>:106: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  cost_target = self.VaR(torch.tensor(next_states) ,torch.tensor(next_actions) ) + self.gamma  * next_cost\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " violations :::  1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([2707, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "<ipython-input-34-a974e389e65b>:185: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  next_action_tensor = torch.tensor(next_actions, dtype=torch.float32).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 1, Episode Reward: [2.3982333e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:571516.4027879458\n",
            "Sharpe:  1.271902577900852\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 2, Episode Reward: [2.2693092e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:603028.4112971505\n",
            "Sharpe:  1.3078042499374052\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 3, Episode Reward: [2.2369224e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:647179.8457689072\n",
            "Sharpe:  1.3423864443613152\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 4, Episode Reward: [2.404741e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:641207.1080772659\n",
            "Sharpe:  1.334140022510816\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 5, Episode Reward: [2.3409518e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:571211.4374402519\n",
            "Sharpe:  1.2708213303605902\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 6, Episode Reward: [2.2070945e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:634249.4075777114\n",
            "Sharpe:  1.3281565178600758\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 7, Episode Reward: [2.3482762e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:564944.748483522\n",
            "Sharpe:  1.2576571575441227\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 8, Episode Reward: [2.2630623e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:576917.2832114649\n",
            "Sharpe:  1.2813547775180287\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 9, Episode Reward: [2.208498e+09]\n",
            "=================================\n",
            "begin_total_asset:1000000\n",
            "end_total_asset:693309.0889877393\n",
            "Sharpe:  1.3769704614263203\n",
            "=================================\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            " violations :::  1\n",
            "Episode: 10, Episode Reward: [2.394484e+09]\n"
          ]
        }
      ],
      "source": [
        "env = env_full_train\n",
        "Episode_rewards = []\n",
        "Avg_rewards = []\n",
        "num_episodes = 100\n",
        "\n",
        "for episode in range(num_episodes):\n",
        "  Actions = []\n",
        "  States = []\n",
        "  Rewards = []\n",
        "  Log_probs = []\n",
        "  Values = []\n",
        "\n",
        "  state = env.reset()\n",
        "  done = False\n",
        "  episode_reward = 0\n",
        "\n",
        "  while not done:\n",
        "    state_tensor = torch.FloatTensor(state).to(device)\n",
        "\n",
        "\n",
        "    action, logs_probs, entropy = agent.get_action(state_tensor)\n",
        "    state_value = agent.critic.forward(state_tensor, action).to(device)\n",
        "    States.append(state_tensor)\n",
        "    Values.append(state_value)\n",
        "    action = action.cpu()\n",
        "    next_state, reward, done, _ = env.step(action.detach().numpy())\n",
        "\n",
        "    Actions.append(action)\n",
        "    Rewards.append(reward)\n",
        "    Log_probs.append(logs_probs)\n",
        "\n",
        "    state = next_state\n",
        "    episode_reward += reward\n",
        "\n",
        "  actions = torch.cat(Actions).to(device)\n",
        "  states = torch.cat(States).to(device)\n",
        "  values = torch.cat(Values).to(device)   #.squeeze(-1)\n",
        "  log_prob_old = torch.cat(Log_probs).to(device)\n",
        "  returns = (agent.calculate_returns(Rewards, agent.gamma)).to(device)\n",
        "  advantages = (returns - values).to(device)\n",
        "  advantages = ((advantages - advantages.mean()) / (advantages.std() + 1e-5)).to(device)\n",
        "\n",
        "  agent.update_policy(states, actions, log_prob_old, advantages, returns)\n",
        "\n",
        "  ## update lambda and rho --\n",
        "  agent.lambda_ = agent.lambda_ + agent.rho * agent.cost_network.forward(\n",
        "        state_tensor,\n",
        "        action\n",
        "    ).mean().detach().to(device)\n",
        "\n",
        "  agent.rho= agent.rho * 1.008\n",
        "\n",
        "  Episode_rewards.append(episode_reward)\n",
        "  Avg_rewards.append(np.mean(Episode_rewards[-10:]))\n",
        "\n",
        "  print(f\"Episode: {episode+1}, Episode Reward: {episode_reward}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_O4Leqa8Mho_"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "plt.plot(Episode_rewards)\n",
        "plt.plot(Avg_rewards)\n",
        "plt.plot()\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Reward')\n",
        "plt.show();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Ma6YpTlnuZ"
      },
      "source": [
        "## Trading\n",
        "Assume that we have $1,000,000 initial capital at 2019-01-01. We use the A2C model to trade Dow jones 30 stocks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Utx9sg-Kv54"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockPortfolioEnv(df = trade, **trade_env_kwargs)\n",
        "test_env, test_obs = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqfAFtscOEE-"
      },
      "outputs": [],
      "source": [
        "account_memory, actions_memory, rewardd = agent.trade(env_trade, e_trade_gym, None)\n",
        "print(rewardd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp8FWh4q68LF"
      },
      "outputs": [],
      "source": [
        "calculate_sharpe(account_memory[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY_7t6B_68i9"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "account_memory[0].to_csv('df_daily_return_'+ Market +'_' + Reward +'.csv')\n",
        "files.download('df_daily_return_'+ Market +'_' + Reward +'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tByVcZ2L9TAJ"
      },
      "outputs": [],
      "source": [
        "actions_memory[0].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MVJaqIaF13Hw"
      },
      "outputs": [],
      "source": [
        "actions_memory[0].to_csv('df_actions_Trade_'+ Market +'_' + Reward +'.csv')\n",
        "files.download('df_actions_Trade_'+ Market +'_' + Reward +'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EoudukHdK3U-"
      },
      "outputs": [],
      "source": [
        "df_daily_return = account_memory[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tt7FlUQHKoMO"
      },
      "outputs": [],
      "source": [
        "e_trade_gym = StockPortfolioEnv(df = trade, **env_kwargs)\n",
        "test_env, test_obs = e_trade_gym.get_sb_env()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGzGF-WZKsqJ"
      },
      "outputs": [],
      "source": [
        "account_memory, actions_memory, rewardd = agent.trade(env_trade, e_trade_gym, None)\n",
        "print(rewardd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nuYo2gdsdAV"
      },
      "outputs": [],
      "source": [
        "df_daily_return_T = account_memory[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC1-n8gSm2yr"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "df_daily_return_T.to_csv('df_daily_return_WT '+ Market +'_' + Reward +'.csv')\n",
        "files.download('df_daily_return_WT '+ Market +'_' + Reward +'.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFO42LcomPUT"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAvxipWFmUe8"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n",
        "# Nifty 50 -- ^NSEI\n",
        "# Sensex 30 -- ^BSESN\n",
        "# Dow 30 -- ^DJI\n",
        "# DAX 40 -- ^GDAXI\n",
        "# HSI 30 -- ^HSI\n",
        "# TIRKEY -- XU100.IS\n",
        "# Nikeei -- ^N225\n",
        "# IBEX Spain -- ^IBEX\n",
        "# Tiwan -- ^TWII\n",
        "# Nifty 100 -- ^CNX100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pFuernJxLURD"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install numpy==1.26.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oGu3PCa8l6L"
      },
      "outputs": [],
      "source": [
        "from pyfolio import timeseries\n",
        "DRL_strat = convert_daily_return_to_pyfolio_ts(df_daily_return_T)\n",
        "perf_func = perf_stats\n",
        "perf_stats_all = perf_func( returns=DRL_strat,\n",
        "                              factor_returns=DRL_strat,\n",
        "                                positions=None, transactions=None, turnover_denom=\"AGB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqvwr6SY8l9A"
      },
      "outputs": [],
      "source": [
        "print(\"==============DRL Strategy Stats===========\")\n",
        "print(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcWzfa6UloDM"
      },
      "outputs": [],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "baseline_df = get_baseline(\n",
        "        ticker= BL,\n",
        "        start = df_daily_return.loc[0,'date'],\n",
        "        end = df_daily_return.loc[len(df_daily_return)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(baseline_df, value_col_name = 'close')\n",
        "print(stats)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVVCMVSAmcrI"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMDyd89wCQuE"
      },
      "outputs": [],
      "source": [
        "pip install empyrical==0.3.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fqSEF5PfjjT"
      },
      "outputs": [],
      "source": [
        "import pyfolio\n",
        "%matplotlib inline\n",
        "\n",
        "baseline_df = get_baseline(\n",
        "        ticker=BL, start=df_daily_return.loc[0,'date'], end='2025-02-28')\n",
        "\n",
        "baseline_returns = get_daily_return(baseline_df, value_col_name=\"close\")\n",
        "\n",
        "# with pyfolio.plotting.plotting_context(font_scale=1.1):\n",
        "#         pyfolio.create_full_tear_sheet(returns = DRL_strat,\n",
        "#                                        benchmark_rets=baseline_returns, set_context=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2F5HyduNW3Mr"
      },
      "outputs": [],
      "source": [
        "DRL_strat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOtZbwZbXB8B"
      },
      "outputs": [],
      "source": [
        "baseline_returns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Zg0EjrXyCT0"
      },
      "outputs": [],
      "source": [
        "baseline_returns.to_csv('Baseline_Daily_Return_'+ Market +'.csv')\n",
        "files.download('Baseline_Daily_Return_'+ Market +'.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "te3Ibcj5hUbz"
      },
      "source": [
        "## Min-Variance Portfolio Allocation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VE2eUEuhMKs"
      },
      "outputs": [],
      "source": [
        "%pip install PyPortfolioOpt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i0NiefM7hHn0"
      },
      "outputs": [],
      "source": [
        "from pypfopt.efficient_frontier import EfficientFrontier\n",
        "from pypfopt import risk_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDYDIBH9hcUP"
      },
      "outputs": [],
      "source": [
        "unique_tic = trade.tic.unique()\n",
        "unique_trade_date = trade.date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EICNukJZgnWl"
      },
      "outputs": [],
      "source": [
        "#calculate_portfolio_minimum_variance\n",
        "portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
        "initial_capital = 1000000\n",
        "portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
        "\n",
        "for i in range(len( unique_trade_date)-1):\n",
        "    df_temp = df[df.date==unique_trade_date[i]].reset_index(drop=True)\n",
        "    df_temp_next = df[df.date==unique_trade_date[i+1]].reset_index(drop=True)\n",
        "    #Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
        "    #calculate covariance matrix\n",
        "    Sigma = df_temp.return_list[0].cov()\n",
        "    #portfolio allocation\n",
        "    ef_min_var = EfficientFrontier(None, Sigma,weight_bounds=(0, 0.1))\n",
        "    #minimum variance\n",
        "    raw_weights_min_var = ef_min_var.min_volatility()\n",
        "    #get weights\n",
        "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
        "\n",
        "    #current capital\n",
        "    cap = portfolio.iloc[0, i]\n",
        "    #current cash invested for each stock\n",
        "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
        "    # current held shares\n",
        "    current_shares = list(np.array(current_cash)\n",
        "                                      / np.array(df_temp.close))\n",
        "    # next time period price\n",
        "    next_price = np.array(df_temp_next.close)\n",
        "    ##next_price * current share to calculate next total account value\n",
        "    portfolio.iloc[0, i+1] = np.dot(current_shares, next_price)\n",
        "\n",
        "portfolio=portfolio.T\n",
        "portfolio.columns = ['account_value']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I_gu9_edV724"
      },
      "source": [
        "# Markowitz's with Transection Cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EeCJGvoVQp6"
      },
      "outputs": [],
      "source": [
        "#calculate_portfolio_minimum_variance\n",
        "portfolio = pd.DataFrame(index = range(1), columns = unique_trade_date)\n",
        "initial_capital = 1000000\n",
        "portfolio.loc[0,unique_trade_date[0]] = initial_capital\n",
        "\n",
        "# Define transaction cost rate\n",
        "transaction_cost_rate = 0.005\n",
        "\n",
        "for i in range(len( unique_trade_date)-1):\n",
        "    df_temp = df[df.date==unique_trade_date[i]].reset_index(drop=True)\n",
        "    df_temp_next = df[df.date==unique_trade_date[i+1]].reset_index(drop=True)\n",
        "    #Sigma = risk_models.sample_cov(df_temp.return_list[0])\n",
        "    #calculate covariance matrix\n",
        "    Sigma = df_temp.return_list[0].cov()\n",
        "    #portfolio allocation\n",
        "    ef_min_var = EfficientFrontier(None, Sigma,weight_bounds=(0, 0.1))\n",
        "    #minimum variance\n",
        "    raw_weights_min_var = ef_min_var.min_volatility()\n",
        "    #get weights\n",
        "    cleaned_weights_min_var = ef_min_var.clean_weights()\n",
        "\n",
        "    #current capital\n",
        "    cap = portfolio.iloc[0, i]\n",
        "    #current cash invested for each stock\n",
        "    current_cash = [element * cap for element in list(cleaned_weights_min_var.values())]\n",
        "    # current held shares\n",
        "    current_shares = list(np.array(current_cash)\n",
        "                                      / np.array(df_temp.close))\n",
        "    # next time period price\n",
        "    next_price = np.array(df_temp_next.close)\n",
        "\n",
        "    # Calculate next portfolio value without transaction cost\n",
        "    next_value = np.dot(current_shares, next_price)\n",
        "\n",
        "    # Calculate transaction costs\n",
        "    new_shares = current_cash / next_price\n",
        "    share_differences = np.abs(new_shares - current_shares)\n",
        "    transaction_cost = np.sum(share_differences * next_price * transaction_cost_rate)\n",
        "\n",
        "    # Deduct transaction cost from portfolio value\n",
        "    portfolio.iloc[0, i + 1] = next_value - transaction_cost\n",
        "\n",
        "portfolio=portfolio.T\n",
        "portfolio.columns = ['account_value']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNk7BbVnyb1h"
      },
      "outputs": [],
      "source": [
        "def calculate_daily_return(current_value, previous_value):\n",
        "    return (current_value - previous_value) / previous_value\n",
        "\n",
        "# Calculate daily return and add it as a new column\n",
        "daily_returns = [0]  # Daily return for the first day is assumed to be 0\n",
        "for i in range(1, len(portfolio)):\n",
        "    current_value = portfolio['account_value'][i]\n",
        "    previous_value = portfolio['account_value'][i - 1]\n",
        "    daily_returns.append(calculate_daily_return(current_value, previous_value))\n",
        "\n",
        "portfolio['daily_return'] = daily_returns\n",
        "\n",
        "print(portfolio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S2zmv1ISkpXu"
      },
      "outputs": [],
      "source": [
        "portfolio.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5RmNa7m_f590"
      },
      "outputs": [],
      "source": [
        "Agent =(df_daily_return_T.daily_return+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y821cLKkhCn6"
      },
      "outputs": [],
      "source": [
        "min_var_cumpod =(portfolio.account_value.pct_change()+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-nS5eTu4G_C"
      },
      "outputs": [],
      "source": [
        "portfolio.drop(columns=['account_value'], inplace=True)\n",
        "portfolio.to_csv('Markowitz_Portfolio_Return_'+ Market +'.csv')\n",
        "files.download('Markowitz_Portfolio_Return_'+ Market +'.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5E1X9FFGgqeZ"
      },
      "outputs": [],
      "source": [
        "Baseline =(baseline_returns+1).cumprod()-1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ih6Jim-blNKY"
      },
      "source": [
        "## Plotly: DRL, Min-Variance, DJIA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CISw6s8rbnpZ"
      },
      "outputs": [],
      "source": [
        "%pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJRH-FX3hTRZ"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime as dt\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly\n",
        "import plotly.graph_objs as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpfgJcG5PInj"
      },
      "outputs": [],
      "source": [
        "time_ind = pd.Series(df_daily_return_T.date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM-NJKa8g7Jp"
      },
      "outputs": [],
      "source": [
        "trace0_portfolio = go.Scatter(x = time_ind, y = Agent, mode = 'lines', name = 'Agent (Portfolio Allocation)')\n",
        "\n",
        "trace1_portfolio = go.Scatter(x = time_ind, y = Baseline, mode = 'lines', name = 'Baseline')\n",
        "trace2_portfolio = go.Scatter(x = time_ind, y = min_var_cumpod, mode = 'lines', name = 'Min-Variance')\n",
        "#trace3_portfolio = go.Scatter(x = time_ind, y = a2c_cumpod_esg, mode = 'lines', name = 'ESG-A2C (Portfolio Allocation)')\n",
        "#trace3_portfolio = go.Scatter(x = time_ind, y = ddpg_cumpod, mode = 'lines', name = 'DDPG')\n",
        "#trace4_portfolio = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
        "#trace5_portfolio = go.Scatter(x = time_ind, y = min_cumpod, mode = 'lines', name = 'Min-Variance')\n",
        "\n",
        "#trace4 = go.Scatter(x = time_ind, y = addpg_cumpod, mode = 'lines', name = 'Adaptive-DDPG')\n",
        "\n",
        "#trace2 = go.Scatter(x = time_ind, y = portfolio_cost_minv, mode = 'lines', name = 'Min-Variance')\n",
        "#trace3 = go.Scatter(x = time_ind, y = spx_value, mode = 'lines', name = 'SPX')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35nVVmEuhGa1"
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\n",
        "fig.add_trace(trace0_portfolio)\n",
        "\n",
        "fig.add_trace(trace1_portfolio)\n",
        "\n",
        "fig.add_trace(trace2_portfolio)\n",
        "\n",
        "#fig.add_trace(trace3_portfolio)\n",
        "\n",
        "fig.update_layout(\n",
        "    legend=dict(\n",
        "        x=0,\n",
        "        y=1,\n",
        "        traceorder=\"normal\",\n",
        "        font=dict(\n",
        "            family=\"sans-serif\",\n",
        "            size=15,\n",
        "            color=\"black\"\n",
        "        ),\n",
        "        bgcolor=\"White\",\n",
        "        bordercolor=\"white\",\n",
        "        borderwidth=2\n",
        "\n",
        "    ),\n",
        ")\n",
        "#fig.update_layout(legend_orientation=\"h\")\n",
        "fig.update_layout(title={\n",
        "        #'text': \"Cumulative Return using FinRL\",\n",
        "        'y':0.85,\n",
        "        'x':0.5,\n",
        "        'xanchor': 'center',\n",
        "        'yanchor': 'top'})\n",
        "#with Transaction cost\n",
        "#fig.update_layout(title =  'Quarterly Trade Date')\n",
        "fig.update_layout(\n",
        "#    margin=dict(l=20, r=20, t=20, b=20),\n",
        "\n",
        "    paper_bgcolor='rgba(1,1,0,0)',\n",
        "    plot_bgcolor='rgba(1, 1, 0, 0)',\n",
        "    #xaxis_title=\"Date\",\n",
        "    yaxis_title=\"Cumulative Return\",\n",
        "xaxis={'type': 'date',\n",
        "       'tick0': time_ind[0],\n",
        "        'tickmode': 'linear',\n",
        "       'dtick': 86400000.0 *80}\n",
        "\n",
        ")\n",
        "fig.update_xaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(showline=True,linecolor='black',showgrid=True, gridwidth=1, gridcolor='LightSteelBlue',mirror=True)\n",
        "fig.update_yaxes(zeroline=True, zerolinewidth=1, zerolinecolor='LightSteelBlue')\n",
        "\n",
        "fig.show()\n",
        "\n",
        "fig.write_image(\"portfolio_return_plot.png\")\n",
        "\n",
        "# Download the file\n",
        "files.download(\"portfolio_return_plot.png\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "bNmvYN9YbU4B",
        "rsDbM5Ex5Z1f",
        "tFQZ_bX25BR_",
        "xtvHJlZ6Fqhn",
        "5mnKtEacCSiZ"
      ],
      "provenance": []
    },
    "interpreter": {
      "hash": "0cd912b5b8ef2e2cf6ba30a360471b623d2891ab42b88478be3d571482cb392e"
    },
    "kernelspec": {
      "display_name": "PyCharm (FinRL)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}